{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOyAMjnqM8UNfhrsfI8TINU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/0415_%E4%B8%8D%E5%90%8C%E6%96%87%E6%9C%AC%E7%BC%96%E7%A0%81%E5%99%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGJRWabJV_1u",
        "outputId": "19543f19-7e88-433e-83d1-ad97d87f3cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "加载编码模型...\n",
            "读取锚点文本数据: anchor_descriptions.csv\n",
            "处理 203 条锚点文本...\n",
            "正在使用 clip_vit_l 编码锚点文本...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [00:09<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_vit_l 锚点文本嵌入已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_emb_clip_vit_l.pt\n",
            "clip_vit_l 锚点文本ID已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_id_clip_vit_l.pt\n",
            "嵌入形状: torch.Size([203, 768])\n",
            "正在使用 clip_vit_b 编码锚点文本...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [00:05<00:00, 35.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_vit_b 锚点文本嵌入已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_emb_clip_vit_b.pt\n",
            "clip_vit_b 锚点文本ID已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_id_clip_vit_b.pt\n",
            "嵌入形状: torch.Size([203, 512])\n",
            "正在使用 bert 编码锚点文本...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [00:10<00:00, 19.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert 锚点文本嵌入已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_emb_bert.pt\n",
            "bert 锚点文本ID已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_id_bert.pt\n",
            "嵌入形状: torch.Size([203, 768])\n",
            "读取城市分类数据: urban_taxonomy.json\n",
            "正在使用 clip_vit_l 为所有城市对象类型生成嵌入...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing residential: 100%|██████████| 49/49 [00:03<00:00, 14.77it/s]\n",
            "Processing commercial: 100%|██████████| 78/78 [00:05<00:00, 15.22it/s]\n",
            "Processing hotel: 100%|██████████| 17/17 [00:01<00:00, 16.04it/s]\n",
            "Processing industrial: 100%|██████████| 22/22 [00:01<00:00, 15.72it/s]\n",
            "Processing education: 100%|██████████| 32/32 [00:02<00:00, 15.83it/s]\n",
            "Processing health care: 100%|██████████| 22/22 [00:01<00:00, 13.95it/s]\n",
            "Processing civic, governmental and cultural: 100%|██████████| 46/46 [00:03<00:00, 13.63it/s]\n",
            "Processing sports and recreation: 100%|██████████| 24/24 [00:01<00:00, 15.80it/s]\n",
            "Processing outdoors and natural: 100%|██████████| 38/38 [00:02<00:00, 15.39it/s]\n",
            "Processing transportation: 100%|██████████| 26/26 [00:01<00:00, 15.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_vit_l 待预测文本嵌入已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_emb_clip_vit_l.pt\n",
            "clip_vit_l 元数据已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_metadata_clip_vit_l.pt\n",
            "嵌入形状: torch.Size([354, 768])\n",
            "总计处理了 354 个城市对象类型\n",
            "正在使用 clip_vit_b 为所有城市对象类型生成嵌入...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing residential: 100%|██████████| 49/49 [00:01<00:00, 25.20it/s]\n",
            "Processing commercial: 100%|██████████| 78/78 [00:03<00:00, 23.71it/s]\n",
            "Processing hotel: 100%|██████████| 17/17 [00:00<00:00, 25.79it/s]\n",
            "Processing industrial: 100%|██████████| 22/22 [00:00<00:00, 27.92it/s]\n",
            "Processing education: 100%|██████████| 32/32 [00:01<00:00, 26.77it/s]\n",
            "Processing health care: 100%|██████████| 22/22 [00:00<00:00, 26.11it/s]\n",
            "Processing civic, governmental and cultural: 100%|██████████| 46/46 [00:01<00:00, 25.56it/s]\n",
            "Processing sports and recreation: 100%|██████████| 24/24 [00:00<00:00, 24.55it/s]\n",
            "Processing outdoors and natural: 100%|██████████| 38/38 [00:01<00:00, 24.43it/s]\n",
            "Processing transportation: 100%|██████████| 26/26 [00:01<00:00, 22.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_vit_b 待预测文本嵌入已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_emb_clip_vit_b.pt\n",
            "clip_vit_b 元数据已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_metadata_clip_vit_b.pt\n",
            "嵌入形状: torch.Size([354, 512])\n",
            "总计处理了 354 个城市对象类型\n",
            "正在使用 bert 为所有城市对象类型生成嵌入...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing residential: 100%|██████████| 49/49 [00:03<00:00, 15.29it/s]\n",
            "Processing commercial: 100%|██████████| 78/78 [00:04<00:00, 17.15it/s]\n",
            "Processing hotel: 100%|██████████| 17/17 [00:00<00:00, 17.49it/s]\n",
            "Processing industrial: 100%|██████████| 22/22 [00:01<00:00, 17.70it/s]\n",
            "Processing education: 100%|██████████| 32/32 [00:01<00:00, 16.04it/s]\n",
            "Processing health care: 100%|██████████| 22/22 [00:01<00:00, 14.39it/s]\n",
            "Processing civic, governmental and cultural: 100%|██████████| 46/46 [00:02<00:00, 15.83it/s]\n",
            "Processing sports and recreation: 100%|██████████| 24/24 [00:01<00:00, 16.65it/s]\n",
            "Processing outdoors and natural: 100%|██████████| 38/38 [00:02<00:00, 17.18it/s]\n",
            "Processing transportation: 100%|██████████| 26/26 [00:01<00:00, 17.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert 待预测文本嵌入已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_emb_bert.pt\n",
            "bert 元数据已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_metadata_bert.pt\n",
            "嵌入形状: torch.Size([354, 768])\n",
            "总计处理了 354 个城市对象类型\n",
            "所有文本编码完成!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import CLIPProcessor, CLIPModel, BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import normalize\n",
        "import re\n",
        "\n",
        "def setup_directories():\n",
        "    \"\"\"创建必要的文件夹\"\"\"\n",
        "    os.makedirs(\"vit_sentencetransformer/anchor_embeddings\", exist_ok=True)\n",
        "    os.makedirs(\"vit_sentencetransformer/candidate_embeddings\", exist_ok=True)\n",
        "\n",
        "def extract_id(id_str):\n",
        "    \"\"\"从ID字符串中提取数字ID\"\"\"\n",
        "    match = re.search(r'(\\d+)', str(id_str))\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return float('inf')  # 如果没有找到数字，返回无穷大使其排序在最后\n",
        "\n",
        "def load_models():\n",
        "    \"\"\"加载所有编码模型\"\"\"\n",
        "    print(\"加载编码模型...\")\n",
        "\n",
        "    # CLIP-ViT-L-14\n",
        "    clip_vit_l_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "    clip_vit_l_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "    # CLIP-ViT-B-32\n",
        "    clip_vit_b_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "    clip_vit_b_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "    # BERT\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    return {\n",
        "        \"clip_vit_l\": (clip_vit_l_model, clip_vit_l_processor),\n",
        "        \"clip_vit_b\": (clip_vit_b_model, clip_vit_b_processor),\n",
        "        \"bert\": (bert_model, bert_tokenizer)\n",
        "    }\n",
        "\n",
        "def encode_text_with_model(model_info, texts, model_name):\n",
        "    \"\"\"使用指定模型对文本进行编码\"\"\"\n",
        "    if model_name in [\"clip_vit_l\", \"clip_vit_b\"]:\n",
        "        model, processor = model_info\n",
        "        inputs = processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            embeddings = model.get_text_features(**inputs)\n",
        "        return embeddings.cpu().numpy()\n",
        "\n",
        "    elif model_name == \"bert\":\n",
        "        model, tokenizer = model_info\n",
        "        inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        # 使用[CLS] token的表示\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "        return embeddings.cpu().numpy()\n",
        "\n",
        "def encode_anchor_texts(models, csv_path, output_dir):\n",
        "    \"\"\"编码锚点文本并保存结果\"\"\"\n",
        "    print(f\"读取锚点文本数据: {csv_path}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        if 'description' not in df.columns:\n",
        "            print(\"错误: CSV文件中没有'description'列\")\n",
        "            return\n",
        "\n",
        "        if 'ID' not in df.columns:\n",
        "            print(\"错误: CSV文件中没有'ID'列\")\n",
        "            return\n",
        "\n",
        "        df['numeric_id'] = df['ID'].apply(extract_id)\n",
        "        df = df.sort_values('numeric_id').reset_index(drop=True)\n",
        "\n",
        "        print(f\"处理 {len(df)} 条锚点文本...\")\n",
        "\n",
        "        descriptions = df['description'].tolist()\n",
        "\n",
        "        for model_name, model_info in models.items():\n",
        "            print(f\"正在使用 {model_name} 编码锚点文本...\")\n",
        "            text_embeddings = []\n",
        "\n",
        "            for description in tqdm(descriptions):\n",
        "                description = \"\" if pd.isna(description) or not description else description\n",
        "                embedding = encode_text_with_model(model_info, [description], model_name)[0]\n",
        "                normalized_embedding = normalize([embedding])[0]\n",
        "                text_embeddings.append(torch.tensor(normalized_embedding, dtype=torch.float32))\n",
        "\n",
        "            text_embeddings_tensor = torch.stack(text_embeddings)\n",
        "\n",
        "            embedding_file = os.path.join(output_dir, f\"anchor_text_emb_{model_name}.pt\")\n",
        "            id_file = os.path.join(output_dir, f\"anchor_text_id_{model_name}.pt\")\n",
        "\n",
        "            torch.save(text_embeddings_tensor, embedding_file)\n",
        "            torch.save(df['ID'].tolist(), id_file)\n",
        "\n",
        "            print(f\"{model_name} 锚点文本嵌入已保存到 {embedding_file}\")\n",
        "            print(f\"{model_name} 锚点文本ID已保存到 {id_file}\")\n",
        "            print(f\"嵌入形状: {text_embeddings_tensor.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理锚点文本时出错: {e}\")\n",
        "\n",
        "def encode_predict_texts(models, json_path, output_dir):\n",
        "    \"\"\"编码待预测文本并保存结果\"\"\"\n",
        "    print(f\"读取城市分类数据: {json_path}\")\n",
        "\n",
        "    urbanclip_templates = [\n",
        "        \"{} area featuring {}.\",\n",
        "        \"{} area featuring {} with cars.\",\n",
        "        \"{} area featuring {} with parking lot.\",\n",
        "        \"{} area featuring {} on the road.\",\n",
        "        \"{} area featuring {} with many trees.\",\n",
        "        \"{} area featuring {} in city.\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            urban_taxonomy = json.load(f)\n",
        "\n",
        "        for model_name, model_info in models.items():\n",
        "            print(f\"正在使用 {model_name} 为所有城市对象类型生成嵌入...\")\n",
        "\n",
        "            embeddings = []\n",
        "            categories = []\n",
        "            uots = []\n",
        "\n",
        "            for category, category_uots in urban_taxonomy.items():\n",
        "                for uot in tqdm(category_uots, desc=f\"Processing {category}\"):\n",
        "                    sentences = [template.format(category, uot) for template in urbanclip_templates]\n",
        "                    sentence_embeddings = encode_text_with_model(model_info, sentences, model_name)\n",
        "                    normalized_embeddings = normalize(sentence_embeddings, axis=1)\n",
        "                    avg_embedding = np.mean(normalized_embeddings, axis=0)\n",
        "                    final_embedding = normalize([avg_embedding])[0]\n",
        "                    final_embedding_tensor = torch.tensor(final_embedding, dtype=torch.float32)\n",
        "\n",
        "                    embeddings.append(final_embedding_tensor)\n",
        "                    categories.append(category)\n",
        "                    uots.append(uot)\n",
        "\n",
        "            embeddings_tensor = torch.stack(embeddings)\n",
        "\n",
        "            embedding_file = os.path.join(output_dir, f\"candidate_text_emb_{model_name}.pt\")\n",
        "            metadata_file = os.path.join(output_dir, f\"candidate_text_metadata_{model_name}.pt\")\n",
        "\n",
        "            torch.save(embeddings_tensor, embedding_file)\n",
        "            torch.save({'categories': categories, 'uots': uots}, metadata_file)\n",
        "\n",
        "            print(f\"{model_name} 待预测文本嵌入已保存到 {embedding_file}\")\n",
        "            print(f\"{model_name} 元数据已保存到 {metadata_file}\")\n",
        "            print(f\"嵌入形状: {embeddings_tensor.shape}\")\n",
        "            print(f\"总计处理了 {len(embeddings)} 个城市对象类型\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理待预测文本时出错: {e}\")\n",
        "\n",
        "def main():\n",
        "    setup_directories()\n",
        "\n",
        "    parent_dir = os.path.dirname(os.getcwd())\n",
        "    images_dir = os.path.join(\"images\")\n",
        "\n",
        "    models = load_models()\n",
        "\n",
        "    anchor_csv_path = os.path.join(\"anchor_descriptions.csv\")\n",
        "    urban_taxonomy_path = os.path.join(\"urban_taxonomy.json\")\n",
        "\n",
        "    encode_anchor_texts(models, anchor_csv_path, \"vit_sentencetransformer/anchor_embeddings\")\n",
        "    encode_predict_texts(models, urban_taxonomy_path, \"vit_sentencetransformer/candidate_embeddings\")\n",
        "\n",
        "    print(\"所有文本编码完成!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.preprocessing import normalize\n",
        "import re\n",
        "\n",
        "def setup_directories():\n",
        "    \"\"\"创建必要的文件夹\"\"\"\n",
        "    os.makedirs(\"vit_sentencetransformer/anchor_embeddings\", exist_ok=True)\n",
        "    os.makedirs(\"vit_sentencetransformer/candidate_embeddings\", exist_ok=True)\n",
        "\n",
        "def extract_id(id_str):\n",
        "    \"\"\"从ID字符串中提取数字ID\"\"\"\n",
        "    match = re.search(r'(\\d+)', str(id_str))\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return float('inf')  # 如果没有找到数字，返回无穷大使其排序在最后\n",
        "\n",
        "def load_model():\n",
        "    \"\"\"加载USE模型\"\"\"\n",
        "    print(\"加载USE模型...\")\n",
        "    use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "    return use_model\n",
        "\n",
        "def encode_text_with_use(model, texts):\n",
        "    \"\"\"使用USE模型对文本进行编码\"\"\"\n",
        "    embeddings = model(texts)\n",
        "    return embeddings.numpy()\n",
        "\n",
        "def encode_anchor_texts(model, csv_path, output_dir):\n",
        "    \"\"\"编码锚点文本并保存结果\"\"\"\n",
        "    print(f\"读取锚点文本数据: {csv_path}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        if 'description' not in df.columns:\n",
        "            print(\"错误: CSV文件中没有'description'列\")\n",
        "            return\n",
        "\n",
        "        if 'ID' not in df.columns:\n",
        "            print(\"错误: CSV文件中没有'ID'列\")\n",
        "            return\n",
        "\n",
        "        df['numeric_id'] = df['ID'].apply(extract_id)\n",
        "        df = df.sort_values('numeric_id').reset_index(drop=True)\n",
        "\n",
        "        print(f\"处理 {len(df)} 条锚点文本...\")\n",
        "\n",
        "        descriptions = df['description'].tolist()\n",
        "\n",
        "        print(\"正在使用USE编码锚点文本...\")\n",
        "        text_embeddings = []\n",
        "\n",
        "        for description in tqdm(descriptions):\n",
        "            description = \"\" if pd.isna(description) or not description else description\n",
        "            embedding = encode_text_with_use(model, [description])[0]\n",
        "            normalized_embedding = normalize([embedding])[0]\n",
        "            # 转换为PyTorch tensor\n",
        "            text_embeddings.append(torch.tensor(normalized_embedding, dtype=torch.float32))\n",
        "\n",
        "        text_embeddings_tensor = torch.stack(text_embeddings)\n",
        "\n",
        "        embedding_file = os.path.join(output_dir, \"anchor_text_emb_use.pt\")\n",
        "        id_file = os.path.join(output_dir, \"anchor_text_id_use.pt\")\n",
        "\n",
        "        torch.save(text_embeddings_tensor, embedding_file)\n",
        "        torch.save(df['ID'].tolist(), id_file)\n",
        "\n",
        "        print(f\"USE锚点文本嵌入已保存到 {embedding_file}\")\n",
        "        print(f\"USE锚点文本ID已保存到 {id_file}\")\n",
        "        print(f\"嵌入形状: {text_embeddings_tensor.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理锚点文本时出错: {e}\")\n",
        "\n",
        "def encode_predict_texts(model, json_path, output_dir):\n",
        "    \"\"\"编码待预测文本并保存结果\"\"\"\n",
        "    print(f\"读取城市分类数据: {json_path}\")\n",
        "\n",
        "    urbanclip_templates = [\n",
        "        \"{} area featuring {}.\",\n",
        "        \"{} area featuring {} with cars.\",\n",
        "        \"{} area featuring {} with parking lot.\",\n",
        "        \"{} area featuring {} on the road.\",\n",
        "        \"{} area featuring {} with many trees.\",\n",
        "        \"{} area featuring {} in city.\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            urban_taxonomy = json.load(f)\n",
        "\n",
        "        print(\"正在使用USE为所有城市对象类型生成嵌入...\")\n",
        "\n",
        "        embeddings = []\n",
        "        categories = []\n",
        "        uots = []\n",
        "\n",
        "        for category, category_uots in urban_taxonomy.items():\n",
        "            for uot in tqdm(category_uots, desc=f\"Processing {category}\"):\n",
        "                sentences = [template.format(category, uot) for template in urbanclip_templates]\n",
        "                sentence_embeddings = encode_text_with_use(model, sentences)\n",
        "                normalized_embeddings = normalize(sentence_embeddings, axis=1)\n",
        "                avg_embedding = np.mean(normalized_embeddings, axis=0)\n",
        "                final_embedding = normalize([avg_embedding])[0]\n",
        "                # 转换为PyTorch tensor\n",
        "                final_embedding_tensor = torch.tensor(final_embedding, dtype=torch.float32)\n",
        "\n",
        "                embeddings.append(final_embedding_tensor)\n",
        "                categories.append(category)\n",
        "                uots.append(uot)\n",
        "\n",
        "        embeddings_tensor = torch.stack(embeddings)\n",
        "\n",
        "        embedding_file = os.path.join(output_dir, \"candidate_text_emb_use.pt\")\n",
        "        metadata_file = os.path.join(output_dir, \"candidate_text_metadata_use.pt\")\n",
        "\n",
        "        torch.save(embeddings_tensor, embedding_file)\n",
        "        torch.save({'categories': categories, 'uots': uots}, metadata_file)\n",
        "\n",
        "        print(f\"USE待预测文本嵌入已保存到 {embedding_file}\")\n",
        "        print(f\"USE元数据已保存到 {metadata_file}\")\n",
        "        print(f\"嵌入形状: {embeddings_tensor.shape}\")\n",
        "        print(f\"总计处理了 {len(embeddings)} 个城市对象类型\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理待预测文本时出错: {e}\")\n",
        "\n",
        "def convert_npy_to_pt(npy_file, pt_file):\n",
        "    \"\"\"将.npy文件转换为.pt文件\"\"\"\n",
        "    try:\n",
        "        data = np.load(npy_file)\n",
        "        tensor_data = torch.tensor(data, dtype=torch.float32)\n",
        "        torch.save(tensor_data, pt_file)\n",
        "        print(f\"已将 {npy_file} 转换为 {pt_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"转换 {npy_file} 时出错: {e}\")\n",
        "\n",
        "def main():\n",
        "    setup_directories()\n",
        "\n",
        "    parent_dir = os.path.dirname(os.getcwd())\n",
        "    images_dir = os.path.join(parent_dir, \"images\")\n",
        "\n",
        "    model = load_model()\n",
        "\n",
        "    anchor_csv_path = os.path.join(\"anchor_descriptions.csv\")\n",
        "    urban_taxonomy_path = os.path.join(\"urban_taxonomy.json\")\n",
        "\n",
        "    encode_anchor_texts(model, anchor_csv_path, \"vit_sentencetransformer/anchor_embeddings\")\n",
        "    encode_predict_texts(model, urban_taxonomy_path, \"vit_sentencetransformer/candidate_embeddings\")\n",
        "\n",
        "    # 可选：如果你有现有的.npy文件需要转换\n",
        "    # 示例：将现有的.npy文件转换为.pt\n",
        "    # npy_file = \"path/to/your/file.npy\"\n",
        "    # pt_file = \"path/to/your/file.pt\"\n",
        "    # convert_npy_to_pt(npy_file, pt_file)\n",
        "\n",
        "    print(\"所有文本编码完成!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7pwj35TkSdj",
        "outputId": "e1c3001b-9216-4c11-ff6a-8fbff046d409"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "加载USE模型...\n",
            "读取锚点文本数据: anchor_descriptions.csv\n",
            "处理 203 条锚点文本...\n",
            "正在使用USE编码锚点文本...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [00:01<00:00, 144.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE锚点文本嵌入已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_emb_use.pt\n",
            "USE锚点文本ID已保存到 vit_sentencetransformer/anchor_embeddings/anchor_text_id_use.pt\n",
            "嵌入形状: torch.Size([203, 512])\n",
            "读取城市分类数据: urban_taxonomy.json\n",
            "正在使用USE为所有城市对象类型生成嵌入...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing residential: 100%|██████████| 49/49 [00:00<00:00, 185.49it/s]\n",
            "Processing commercial: 100%|██████████| 78/78 [00:00<00:00, 186.50it/s]\n",
            "Processing hotel: 100%|██████████| 17/17 [00:00<00:00, 191.86it/s]\n",
            "Processing industrial: 100%|██████████| 22/22 [00:00<00:00, 187.25it/s]\n",
            "Processing education: 100%|██████████| 32/32 [00:00<00:00, 194.35it/s]\n",
            "Processing health care: 100%|██████████| 22/22 [00:00<00:00, 190.18it/s]\n",
            "Processing civic, governmental and cultural: 100%|██████████| 46/46 [00:00<00:00, 190.12it/s]\n",
            "Processing sports and recreation: 100%|██████████| 24/24 [00:00<00:00, 189.56it/s]\n",
            "Processing outdoors and natural: 100%|██████████| 38/38 [00:00<00:00, 192.68it/s]\n",
            "Processing transportation: 100%|██████████| 26/26 [00:00<00:00, 194.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE待预测文本嵌入已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_emb_use.pt\n",
            "USE元数据已保存到 vit_sentencetransformer/candidate_embeddings/candidate_text_metadata_use.pt\n",
            "嵌入形状: torch.Size([354, 512])\n",
            "总计处理了 354 个城市对象类型\n",
            "所有文本编码完成!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}