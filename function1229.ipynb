{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOVwJwbXmOwC0AZOhp7WQmd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/function1229.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF-4_K43mtF6",
        "outputId": "6b76efc1-813e-4dea-edc9-4f68fb501e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/CommonFeatures/correct_function.zip -d /content/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgNV_JHQm31v",
        "outputId": "deb7edf1-28ba-46d4-b02f-cca1ae465f44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/CommonFeatures/correct_function.zip\n",
            "   creating: /content/Data/civic, governmental and cultural/\n",
            "  inflating: /content/Data/civic, governmental and cultural/0.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1035.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1056.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1219.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1246.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1266.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1272.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1286.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1287.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1288.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1289.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1290.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1291.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1292.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1303.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1316.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1416.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1431.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1432.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1480.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/15.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1501.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1503.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1504.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1507.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1509.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1510.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1512.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1514.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/198.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/223.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/228.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/556.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/600.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/858.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/943.png  \n",
            "   creating: /content/Data/commercial/\n",
            "  inflating: /content/Data/commercial/100.png  \n",
            "  inflating: /content/Data/commercial/1002.png  \n",
            "  inflating: /content/Data/commercial/1006.png  \n",
            "  inflating: /content/Data/commercial/1007.png  \n",
            "  inflating: /content/Data/commercial/1010.png  \n",
            "  inflating: /content/Data/commercial/1014.png  \n",
            "  inflating: /content/Data/commercial/1016.png  \n",
            "  inflating: /content/Data/commercial/1019.png  \n",
            "  inflating: /content/Data/commercial/1025.png  \n",
            "  inflating: /content/Data/commercial/1028.png  \n",
            "  inflating: /content/Data/commercial/1032.png  \n",
            "  inflating: /content/Data/commercial/1034.png  \n",
            "  inflating: /content/Data/commercial/1043.png  \n",
            "  inflating: /content/Data/commercial/1049.png  \n",
            "  inflating: /content/Data/commercial/106.png  \n",
            "  inflating: /content/Data/commercial/1062.png  \n",
            "  inflating: /content/Data/commercial/108.png  \n",
            "  inflating: /content/Data/commercial/1080.png  \n",
            "  inflating: /content/Data/commercial/1083.png  \n",
            "  inflating: /content/Data/commercial/1086.png  \n",
            "  inflating: /content/Data/commercial/1094.png  \n",
            "  inflating: /content/Data/commercial/1116.png  \n",
            "  inflating: /content/Data/commercial/1122.png  \n",
            "  inflating: /content/Data/commercial/1125.png  \n",
            "  inflating: /content/Data/commercial/1134.png  \n",
            "  inflating: /content/Data/commercial/1135.png  \n",
            "  inflating: /content/Data/commercial/1140.png  \n",
            "  inflating: /content/Data/commercial/1146.png  \n",
            "  inflating: /content/Data/commercial/1153.png  \n",
            "  inflating: /content/Data/commercial/1158.png  \n",
            "  inflating: /content/Data/commercial/1161.png  \n",
            "  inflating: /content/Data/commercial/1169.png  \n",
            "  inflating: /content/Data/commercial/1175.png  \n",
            "  inflating: /content/Data/commercial/1176.png  \n",
            "  inflating: /content/Data/commercial/1178.png  \n",
            "  inflating: /content/Data/commercial/1179.png  \n",
            "  inflating: /content/Data/commercial/12.png  \n",
            "  inflating: /content/Data/commercial/1200.png  \n",
            "  inflating: /content/Data/commercial/1207.png  \n",
            "  inflating: /content/Data/commercial/1215.png  \n",
            "  inflating: /content/Data/commercial/1226.png  \n",
            "  inflating: /content/Data/commercial/1237.png  \n",
            "  inflating: /content/Data/commercial/1238.png  \n",
            "  inflating: /content/Data/commercial/126.png  \n",
            "  inflating: /content/Data/commercial/1264.png  \n",
            "  inflating: /content/Data/commercial/1267.png  \n",
            "  inflating: /content/Data/commercial/1269.png  \n",
            "  inflating: /content/Data/commercial/1270.png  \n",
            "  inflating: /content/Data/commercial/1274.png  \n",
            "  inflating: /content/Data/commercial/1285.png  \n",
            "  inflating: /content/Data/commercial/13.png  \n",
            "  inflating: /content/Data/commercial/141.png  \n",
            "  inflating: /content/Data/commercial/1474.png  \n",
            "  inflating: /content/Data/commercial/1488.png  \n",
            "  inflating: /content/Data/commercial/1499.png  \n",
            "  inflating: /content/Data/commercial/151.png  \n",
            "  inflating: /content/Data/commercial/1515.png  \n",
            "  inflating: /content/Data/commercial/1516.png  \n",
            "  inflating: /content/Data/commercial/152.png  \n",
            "  inflating: /content/Data/commercial/155.png  \n",
            "  inflating: /content/Data/commercial/157.png  \n",
            "  inflating: /content/Data/commercial/17.png  \n",
            "  inflating: /content/Data/commercial/195.png  \n",
            "  inflating: /content/Data/commercial/2.png  \n",
            "  inflating: /content/Data/commercial/238.png  \n",
            "  inflating: /content/Data/commercial/249.png  \n",
            "  inflating: /content/Data/commercial/259.png  \n",
            "  inflating: /content/Data/commercial/261.png  \n",
            "  inflating: /content/Data/commercial/280.png  \n",
            "  inflating: /content/Data/commercial/285.png  \n",
            "  inflating: /content/Data/commercial/288.png  \n",
            "  inflating: /content/Data/commercial/293.png  \n",
            "  inflating: /content/Data/commercial/294.png  \n",
            "  inflating: /content/Data/commercial/3.png  \n",
            "  inflating: /content/Data/commercial/301.png  \n",
            "  inflating: /content/Data/commercial/306.png  \n",
            "  inflating: /content/Data/commercial/33.png  \n",
            "  inflating: /content/Data/commercial/332.png  \n",
            "  inflating: /content/Data/commercial/350.png  \n",
            "  inflating: /content/Data/commercial/352.png  \n",
            "  inflating: /content/Data/commercial/355.png  \n",
            "  inflating: /content/Data/commercial/359.png  \n",
            "  inflating: /content/Data/commercial/371.png  \n",
            "  inflating: /content/Data/commercial/376.png  \n",
            "  inflating: /content/Data/commercial/377.png  \n",
            "  inflating: /content/Data/commercial/378.png  \n",
            "  inflating: /content/Data/commercial/38.png  \n",
            "  inflating: /content/Data/commercial/388.png  \n",
            "  inflating: /content/Data/commercial/392.png  \n",
            "  inflating: /content/Data/commercial/397.png  \n",
            "  inflating: /content/Data/commercial/402.png  \n",
            "  inflating: /content/Data/commercial/403.png  \n",
            "  inflating: /content/Data/commercial/406.png  \n",
            "  inflating: /content/Data/commercial/41.png  \n",
            "  inflating: /content/Data/commercial/410.png  \n",
            "  inflating: /content/Data/commercial/411.png  \n",
            "  inflating: /content/Data/commercial/414.png  \n",
            "  inflating: /content/Data/commercial/430.png  \n",
            "  inflating: /content/Data/commercial/434.png  \n",
            "  inflating: /content/Data/commercial/440.png  \n",
            "  inflating: /content/Data/commercial/441.png  \n",
            "  inflating: /content/Data/commercial/442.png  \n",
            "  inflating: /content/Data/commercial/451.png  \n",
            "  inflating: /content/Data/commercial/452.png  \n",
            "  inflating: /content/Data/commercial/455.png  \n",
            "  inflating: /content/Data/commercial/470.png  \n",
            "  inflating: /content/Data/commercial/471.png  \n",
            "  inflating: /content/Data/commercial/473.png  \n",
            "  inflating: /content/Data/commercial/478.png  \n",
            "  inflating: /content/Data/commercial/490.png  \n",
            "  inflating: /content/Data/commercial/496.png  \n",
            "  inflating: /content/Data/commercial/498.png  \n",
            "  inflating: /content/Data/commercial/499.png  \n",
            "  inflating: /content/Data/commercial/510.png  \n",
            "  inflating: /content/Data/commercial/511.png  \n",
            "  inflating: /content/Data/commercial/516.png  \n",
            "  inflating: /content/Data/commercial/524.png  \n",
            "  inflating: /content/Data/commercial/530.png  \n",
            "  inflating: /content/Data/commercial/535.png  \n",
            "  inflating: /content/Data/commercial/538.png  \n",
            "  inflating: /content/Data/commercial/540.png  \n",
            "  inflating: /content/Data/commercial/542.png  \n",
            "  inflating: /content/Data/commercial/548.png  \n",
            "  inflating: /content/Data/commercial/550.png  \n",
            "  inflating: /content/Data/commercial/555.png  \n",
            "  inflating: /content/Data/commercial/560.png  \n",
            "  inflating: /content/Data/commercial/568.png  \n",
            "  inflating: /content/Data/commercial/581.png  \n",
            "  inflating: /content/Data/commercial/582.png  \n",
            "  inflating: /content/Data/commercial/583.png  \n",
            "  inflating: /content/Data/commercial/589.png  \n",
            "  inflating: /content/Data/commercial/591.png  \n",
            "  inflating: /content/Data/commercial/595.png  \n",
            "  inflating: /content/Data/commercial/598.png  \n",
            "  inflating: /content/Data/commercial/602.png  \n",
            "  inflating: /content/Data/commercial/607.png  \n",
            "  inflating: /content/Data/commercial/608.png  \n",
            "  inflating: /content/Data/commercial/610.png  \n",
            "  inflating: /content/Data/commercial/616.png  \n",
            "  inflating: /content/Data/commercial/617.png  \n",
            "  inflating: /content/Data/commercial/627.png  \n",
            "  inflating: /content/Data/commercial/630.png  \n",
            "  inflating: /content/Data/commercial/644.png  \n",
            "  inflating: /content/Data/commercial/653.png  \n",
            "  inflating: /content/Data/commercial/654.png  \n",
            "  inflating: /content/Data/commercial/655.png  \n",
            "  inflating: /content/Data/commercial/659.png  \n",
            "  inflating: /content/Data/commercial/661.png  \n",
            "  inflating: /content/Data/commercial/67.png  \n",
            "  inflating: /content/Data/commercial/672.png  \n",
            "  inflating: /content/Data/commercial/681.png  \n",
            "  inflating: /content/Data/commercial/688.png  \n",
            "  inflating: /content/Data/commercial/699.png  \n",
            "  inflating: /content/Data/commercial/7.png  \n",
            "  inflating: /content/Data/commercial/714.png  \n",
            "  inflating: /content/Data/commercial/73.png  \n",
            "  inflating: /content/Data/commercial/739.png  \n",
            "  inflating: /content/Data/commercial/750.png  \n",
            "  inflating: /content/Data/commercial/751.png  \n",
            "  inflating: /content/Data/commercial/758.png  \n",
            "  inflating: /content/Data/commercial/76.png  \n",
            "  inflating: /content/Data/commercial/766.png  \n",
            "  inflating: /content/Data/commercial/77.png  \n",
            "  inflating: /content/Data/commercial/771.png  \n",
            "  inflating: /content/Data/commercial/775.png  \n",
            "  inflating: /content/Data/commercial/783.png  \n",
            "  inflating: /content/Data/commercial/785.png  \n",
            "  inflating: /content/Data/commercial/794.png  \n",
            "  inflating: /content/Data/commercial/80.png  \n",
            "  inflating: /content/Data/commercial/804.png  \n",
            "  inflating: /content/Data/commercial/807.png  \n",
            "  inflating: /content/Data/commercial/810.png  \n",
            "  inflating: /content/Data/commercial/812.png  \n",
            "  inflating: /content/Data/commercial/819.png  \n",
            "  inflating: /content/Data/commercial/820.png  \n",
            "  inflating: /content/Data/commercial/823.png  \n",
            "  inflating: /content/Data/commercial/838.png  \n",
            "  inflating: /content/Data/commercial/854.png  \n",
            "  inflating: /content/Data/commercial/856.png  \n",
            "  inflating: /content/Data/commercial/864.png  \n",
            "  inflating: /content/Data/commercial/868.png  \n",
            "  inflating: /content/Data/commercial/874.png  \n",
            "  inflating: /content/Data/commercial/875.png  \n",
            "  inflating: /content/Data/commercial/893.png  \n",
            "  inflating: /content/Data/commercial/894.png  \n",
            "  inflating: /content/Data/commercial/896.png  \n",
            "  inflating: /content/Data/commercial/903.png  \n",
            "  inflating: /content/Data/commercial/905.png  \n",
            "  inflating: /content/Data/commercial/908.png  \n",
            "  inflating: /content/Data/commercial/913.png  \n",
            "  inflating: /content/Data/commercial/919.png  \n",
            "  inflating: /content/Data/commercial/921.png  \n",
            "  inflating: /content/Data/commercial/923.png  \n",
            "  inflating: /content/Data/commercial/935.png  \n",
            "  inflating: /content/Data/commercial/940.png  \n",
            "  inflating: /content/Data/commercial/946.png  \n",
            "  inflating: /content/Data/commercial/951.png  \n",
            "  inflating: /content/Data/commercial/952.png  \n",
            "  inflating: /content/Data/commercial/953.png  \n",
            "  inflating: /content/Data/commercial/957.png  \n",
            "  inflating: /content/Data/commercial/966.png  \n",
            "  inflating: /content/Data/commercial/969.png  \n",
            "  inflating: /content/Data/commercial/98.png  \n",
            "  inflating: /content/Data/commercial/982.png  \n",
            "  inflating: /content/Data/commercial/983.png  \n",
            "  inflating: /content/Data/commercial/986.png  \n",
            "  inflating: /content/Data/commercial/993.png  \n",
            "  inflating: /content/Data/commercial/997.png  \n",
            "  inflating: /content/Data/correct_function.py  \n",
            "   creating: /content/Data/education/\n",
            "  inflating: /content/Data/education/1050.png  \n",
            "  inflating: /content/Data/education/1072.png  \n",
            "  inflating: /content/Data/education/1087.png  \n",
            "  inflating: /content/Data/education/1109.png  \n",
            "  inflating: /content/Data/education/1110.png  \n",
            "  inflating: /content/Data/education/1111.png  \n",
            "  inflating: /content/Data/education/1112.png  \n",
            "  inflating: /content/Data/education/1197.png  \n",
            "  inflating: /content/Data/education/1213.png  \n",
            "  inflating: /content/Data/education/123.png  \n",
            "  inflating: /content/Data/education/1279.png  \n",
            "  inflating: /content/Data/education/1280.png  \n",
            "  inflating: /content/Data/education/1300.png  \n",
            "  inflating: /content/Data/education/1312.png  \n",
            "  inflating: /content/Data/education/1314.png  \n",
            "  inflating: /content/Data/education/1315.png  \n",
            "  inflating: /content/Data/education/1319.png  \n",
            "  inflating: /content/Data/education/1322.png  \n",
            "  inflating: /content/Data/education/1330.png  \n",
            "  inflating: /content/Data/education/1332.png  \n",
            "  inflating: /content/Data/education/1337.png  \n",
            "  inflating: /content/Data/education/1338.png  \n",
            "  inflating: /content/Data/education/1339.png  \n",
            "  inflating: /content/Data/education/1342.png  \n",
            "  inflating: /content/Data/education/1346.png  \n",
            "  inflating: /content/Data/education/1349.png  \n",
            "  inflating: /content/Data/education/1356.png  \n",
            "  inflating: /content/Data/education/1357.png  \n",
            "  inflating: /content/Data/education/1371.png  \n",
            "  inflating: /content/Data/education/1374.png  \n",
            "  inflating: /content/Data/education/1375.png  \n",
            "  inflating: /content/Data/education/1382.png  \n",
            "  inflating: /content/Data/education/1383.png  \n",
            "  inflating: /content/Data/education/1385.png  \n",
            "  inflating: /content/Data/education/1387.png  \n",
            "  inflating: /content/Data/education/1388.png  \n",
            "  inflating: /content/Data/education/1391.png  \n",
            "  inflating: /content/Data/education/1392.png  \n",
            "  inflating: /content/Data/education/1394.png  \n",
            "  inflating: /content/Data/education/1395.png  \n",
            "  inflating: /content/Data/education/1396.png  \n",
            "  inflating: /content/Data/education/1399.png  \n",
            "  inflating: /content/Data/education/1400.png  \n",
            "  inflating: /content/Data/education/1405.png  \n",
            "  inflating: /content/Data/education/1414.png  \n",
            "  inflating: /content/Data/education/1420.png  \n",
            "  inflating: /content/Data/education/1421.png  \n",
            "  inflating: /content/Data/education/1425.png  \n",
            "  inflating: /content/Data/education/1428.png  \n",
            "  inflating: /content/Data/education/143.png  \n",
            "  inflating: /content/Data/education/1435.png  \n",
            "  inflating: /content/Data/education/1437.png  \n",
            "  inflating: /content/Data/education/1446.png  \n",
            "  inflating: /content/Data/education/1447.png  \n",
            "  inflating: /content/Data/education/1448.png  \n",
            "  inflating: /content/Data/education/1457.png  \n",
            "  inflating: /content/Data/education/1461.png  \n",
            "  inflating: /content/Data/education/1462.png  \n",
            "  inflating: /content/Data/education/1465.png  \n",
            "  inflating: /content/Data/education/1467.png  \n",
            "  inflating: /content/Data/education/1471.png  \n",
            "  inflating: /content/Data/education/1472.png  \n",
            "  inflating: /content/Data/education/1473.png  \n",
            "  inflating: /content/Data/education/1477.png  \n",
            "  inflating: /content/Data/education/1478.png  \n",
            "  inflating: /content/Data/education/1485.png  \n",
            "  inflating: /content/Data/education/174.png  \n",
            "  inflating: /content/Data/education/184.png  \n",
            "  inflating: /content/Data/education/240.png  \n",
            "  inflating: /content/Data/education/262.png  \n",
            "  inflating: /content/Data/education/284.png  \n",
            "  inflating: /content/Data/education/291.png  \n",
            "  inflating: /content/Data/education/316.png  \n",
            "  inflating: /content/Data/education/330.png  \n",
            "  inflating: /content/Data/education/43.png  \n",
            "  inflating: /content/Data/education/432.png  \n",
            "  inflating: /content/Data/education/468.png  \n",
            "  inflating: /content/Data/education/525.png  \n",
            "  inflating: /content/Data/education/543.png  \n",
            "  inflating: /content/Data/education/576.png  \n",
            "  inflating: /content/Data/education/620.png  \n",
            "  inflating: /content/Data/education/621.png  \n",
            "  inflating: /content/Data/education/631.png  \n",
            "  inflating: /content/Data/education/65.png  \n",
            "  inflating: /content/Data/education/664.png  \n",
            "  inflating: /content/Data/education/682.png  \n",
            "  inflating: /content/Data/education/695.png  \n",
            "  inflating: /content/Data/education/705.png  \n",
            "  inflating: /content/Data/education/709.png  \n",
            "  inflating: /content/Data/education/724.png  \n",
            "  inflating: /content/Data/education/764.png  \n",
            "  inflating: /content/Data/education/798.png  \n",
            "  inflating: /content/Data/education/8.png  \n",
            "  inflating: /content/Data/education/802.png  \n",
            "  inflating: /content/Data/education/865.png  \n",
            "  inflating: /content/Data/education/882.png  \n",
            "  inflating: /content/Data/education/941.png  \n",
            "  inflating: /content/Data/education/956.png  \n",
            "  inflating: /content/Data/education/973.png  \n",
            "   creating: /content/Data/health care/\n",
            "  inflating: /content/Data/health care/1244.png  \n",
            "  inflating: /content/Data/health care/1276.png  \n",
            "  inflating: /content/Data/health care/1278.png  \n",
            "  inflating: /content/Data/health care/1298.png  \n",
            "  inflating: /content/Data/health care/1299.png  \n",
            "  inflating: /content/Data/health care/1308.png  \n",
            "  inflating: /content/Data/health care/1311.png  \n",
            "  inflating: /content/Data/health care/1320.png  \n",
            "  inflating: /content/Data/health care/1321.png  \n",
            "  inflating: /content/Data/health care/1326.png  \n",
            "  inflating: /content/Data/health care/1327.png  \n",
            "  inflating: /content/Data/health care/1344.png  \n",
            "  inflating: /content/Data/health care/1361.png  \n",
            "  inflating: /content/Data/health care/1362.png  \n",
            "  inflating: /content/Data/health care/1370.png  \n",
            "  inflating: /content/Data/health care/1372.png  \n",
            "  inflating: /content/Data/health care/1404.png  \n",
            "  inflating: /content/Data/health care/1409.png  \n",
            "  inflating: /content/Data/health care/1505.png  \n",
            "  inflating: /content/Data/health care/200.png  \n",
            "  inflating: /content/Data/health care/333.png  \n",
            "  inflating: /content/Data/health care/454.png  \n",
            "  inflating: /content/Data/health care/483.png  \n",
            "  inflating: /content/Data/health care/575.png  \n",
            "  inflating: /content/Data/health care/70.png  \n",
            "  inflating: /content/Data/health care/86.png  \n",
            "  inflating: /content/Data/health care/890.png  \n",
            "   creating: /content/Data/hotel/\n",
            "  inflating: /content/Data/hotel/1123.png  \n",
            "  inflating: /content/Data/hotel/1127.png  \n",
            "  inflating: /content/Data/hotel/1128.png  \n",
            "  inflating: /content/Data/hotel/1191.png  \n",
            "  inflating: /content/Data/hotel/121.png  \n",
            "  inflating: /content/Data/hotel/1263.png  \n",
            "  inflating: /content/Data/hotel/1306.png  \n",
            "  inflating: /content/Data/hotel/1487.png  \n",
            "  inflating: /content/Data/hotel/179.png  \n",
            "  inflating: /content/Data/hotel/203.png  \n",
            "  inflating: /content/Data/hotel/204.png  \n",
            "  inflating: /content/Data/hotel/206.png  \n",
            "  inflating: /content/Data/hotel/23.png  \n",
            "  inflating: /content/Data/hotel/272.png  \n",
            "  inflating: /content/Data/hotel/327.png  \n",
            "  inflating: /content/Data/hotel/365.png  \n",
            "  inflating: /content/Data/hotel/431.png  \n",
            "  inflating: /content/Data/hotel/526.png  \n",
            "  inflating: /content/Data/hotel/622.png  \n",
            "  inflating: /content/Data/hotel/623.png  \n",
            "  inflating: /content/Data/hotel/625.png  \n",
            "  inflating: /content/Data/hotel/69.png  \n",
            "  inflating: /content/Data/hotel/71.png  \n",
            "  inflating: /content/Data/hotel/718.png  \n",
            "  inflating: /content/Data/hotel/829.png  \n",
            "  inflating: /content/Data/hotel/870.png  \n",
            "  inflating: /content/Data/hotel/873.png  \n",
            "  inflating: /content/Data/hotel/878.png  \n",
            "  inflating: /content/Data/hotel/884.png  \n",
            "  inflating: /content/Data/hotel/948.png  \n",
            "   creating: /content/Data/industrial/\n",
            "  inflating: /content/Data/industrial/1001.png  \n",
            "  inflating: /content/Data/industrial/1004.png  \n",
            "  inflating: /content/Data/industrial/1008.png  \n",
            "  inflating: /content/Data/industrial/1009.png  \n",
            "  inflating: /content/Data/industrial/1013.png  \n",
            "  inflating: /content/Data/industrial/1017.png  \n",
            "  inflating: /content/Data/industrial/1020.png  \n",
            "  inflating: /content/Data/industrial/1026.png  \n",
            "  inflating: /content/Data/industrial/1033.png  \n",
            "  inflating: /content/Data/industrial/1054.png  \n",
            "  inflating: /content/Data/industrial/1055.png  \n",
            "  inflating: /content/Data/industrial/1059.png  \n",
            "  inflating: /content/Data/industrial/1063.png  \n",
            "  inflating: /content/Data/industrial/1067.png  \n",
            "  inflating: /content/Data/industrial/107.png  \n",
            "  inflating: /content/Data/industrial/1071.png  \n",
            "  inflating: /content/Data/industrial/1074.png  \n",
            "  inflating: /content/Data/industrial/1078.png  \n",
            "  inflating: /content/Data/industrial/1085.png  \n",
            "  inflating: /content/Data/industrial/1101.png  \n",
            "  inflating: /content/Data/industrial/1104.png  \n",
            "  inflating: /content/Data/industrial/1105.png  \n",
            "  inflating: /content/Data/industrial/1107.png  \n",
            "  inflating: /content/Data/industrial/1108.png  \n",
            "  inflating: /content/Data/industrial/1113.png  \n",
            "  inflating: /content/Data/industrial/1114.png  \n",
            "  inflating: /content/Data/industrial/1119.png  \n",
            "  inflating: /content/Data/industrial/1121.png  \n",
            "  inflating: /content/Data/industrial/1129.png  \n",
            "  inflating: /content/Data/industrial/1131.png  \n",
            "  inflating: /content/Data/industrial/1133.png  \n",
            "  inflating: /content/Data/industrial/1137.png  \n",
            "  inflating: /content/Data/industrial/1148.png  \n",
            "  inflating: /content/Data/industrial/1157.png  \n",
            "  inflating: /content/Data/industrial/1164.png  \n",
            "  inflating: /content/Data/industrial/1165.png  \n",
            "  inflating: /content/Data/industrial/1182.png  \n",
            "  inflating: /content/Data/industrial/1184.png  \n",
            "  inflating: /content/Data/industrial/1188.png  \n",
            "  inflating: /content/Data/industrial/1195.png  \n",
            "  inflating: /content/Data/industrial/1199.png  \n",
            "  inflating: /content/Data/industrial/1217.png  \n",
            "  inflating: /content/Data/industrial/1224.png  \n",
            "  inflating: /content/Data/industrial/1239.png  \n",
            "  inflating: /content/Data/industrial/1243.png  \n",
            "  inflating: /content/Data/industrial/1250.png  \n",
            "  inflating: /content/Data/industrial/1251.png  \n",
            "  inflating: /content/Data/industrial/1259.png  \n",
            "  inflating: /content/Data/industrial/1260.png  \n",
            "  inflating: /content/Data/industrial/14.png  \n",
            "  inflating: /content/Data/industrial/142.png  \n",
            "  inflating: /content/Data/industrial/1445.png  \n",
            "  inflating: /content/Data/industrial/1453.png  \n",
            "  inflating: /content/Data/industrial/1455.png  \n",
            "  inflating: /content/Data/industrial/1456.png  \n",
            "  inflating: /content/Data/industrial/166.png  \n",
            "  inflating: /content/Data/industrial/167.png  \n",
            "  inflating: /content/Data/industrial/253.png  \n",
            "  inflating: /content/Data/industrial/256.png  \n",
            "  inflating: /content/Data/industrial/268.png  \n",
            "  inflating: /content/Data/industrial/273.png  \n",
            "  inflating: /content/Data/industrial/339.png  \n",
            "  inflating: /content/Data/industrial/340.png  \n",
            "  inflating: /content/Data/industrial/342.png  \n",
            "  inflating: /content/Data/industrial/360.png  \n",
            "  inflating: /content/Data/industrial/361.png  \n",
            "  inflating: /content/Data/industrial/367.png  \n",
            "  inflating: /content/Data/industrial/370.png  \n",
            "  inflating: /content/Data/industrial/396.png  \n",
            "  inflating: /content/Data/industrial/400.png  \n",
            "  inflating: /content/Data/industrial/436.png  \n",
            "  inflating: /content/Data/industrial/437.png  \n",
            "  inflating: /content/Data/industrial/438.png  \n",
            "  inflating: /content/Data/industrial/486.png  \n",
            "  inflating: /content/Data/industrial/488.png  \n",
            "  inflating: /content/Data/industrial/494.png  \n",
            "  inflating: /content/Data/industrial/500.png  \n",
            "  inflating: /content/Data/industrial/503.png  \n",
            "  inflating: /content/Data/industrial/504.png  \n",
            "  inflating: /content/Data/industrial/514.png  \n",
            "  inflating: /content/Data/industrial/521.png  \n",
            "  inflating: /content/Data/industrial/533.png  \n",
            "  inflating: /content/Data/industrial/537.png  \n",
            "  inflating: /content/Data/industrial/54.png  \n",
            "  inflating: /content/Data/industrial/545.png  \n",
            "  inflating: /content/Data/industrial/553.png  \n",
            "  inflating: /content/Data/industrial/567.png  \n",
            "  inflating: /content/Data/industrial/580.png  \n",
            "  inflating: /content/Data/industrial/585.png  \n",
            "  inflating: /content/Data/industrial/590.png  \n",
            "  inflating: /content/Data/industrial/599.png  \n",
            "  inflating: /content/Data/industrial/614.png  \n",
            "  inflating: /content/Data/industrial/618.png  \n",
            "  inflating: /content/Data/industrial/647.png  \n",
            "  inflating: /content/Data/industrial/671.png  \n",
            "  inflating: /content/Data/industrial/676.png  \n",
            "  inflating: /content/Data/industrial/693.png  \n",
            "  inflating: /content/Data/industrial/701.png  \n",
            "  inflating: /content/Data/industrial/703.png  \n",
            "  inflating: /content/Data/industrial/712.png  \n",
            "  inflating: /content/Data/industrial/716.png  \n",
            "  inflating: /content/Data/industrial/723.png  \n",
            "  inflating: /content/Data/industrial/726.png  \n",
            "  inflating: /content/Data/industrial/734.png  \n",
            "  inflating: /content/Data/industrial/737.png  \n",
            "  inflating: /content/Data/industrial/738.png  \n",
            "  inflating: /content/Data/industrial/743.png  \n",
            "  inflating: /content/Data/industrial/744.png  \n",
            "  inflating: /content/Data/industrial/748.png  \n",
            "  inflating: /content/Data/industrial/75.png  \n",
            "  inflating: /content/Data/industrial/753.png  \n",
            "  inflating: /content/Data/industrial/757.png  \n",
            "  inflating: /content/Data/industrial/761.png  \n",
            "  inflating: /content/Data/industrial/768.png  \n",
            "  inflating: /content/Data/industrial/769.png  \n",
            "  inflating: /content/Data/industrial/773.png  \n",
            "  inflating: /content/Data/industrial/774.png  \n",
            "  inflating: /content/Data/industrial/777.png  \n",
            "  inflating: /content/Data/industrial/778.png  \n",
            "  inflating: /content/Data/industrial/779.png  \n",
            "  inflating: /content/Data/industrial/781.png  \n",
            "  inflating: /content/Data/industrial/787.png  \n",
            "  inflating: /content/Data/industrial/791.png  \n",
            "  inflating: /content/Data/industrial/792.png  \n",
            "  inflating: /content/Data/industrial/796.png  \n",
            "  inflating: /content/Data/industrial/801.png  \n",
            "  inflating: /content/Data/industrial/813.png  \n",
            "  inflating: /content/Data/industrial/827.png  \n",
            "  inflating: /content/Data/industrial/828.png  \n",
            "  inflating: /content/Data/industrial/839.png  \n",
            "  inflating: /content/Data/industrial/840.png  \n",
            "  inflating: /content/Data/industrial/850.png  \n",
            "  inflating: /content/Data/industrial/852.png  \n",
            "  inflating: /content/Data/industrial/853.png  \n",
            "  inflating: /content/Data/industrial/881.png  \n",
            "  inflating: /content/Data/industrial/898.png  \n",
            "  inflating: /content/Data/industrial/899.png  \n",
            "  inflating: /content/Data/industrial/901.png  \n",
            "  inflating: /content/Data/industrial/910.png  \n",
            "  inflating: /content/Data/industrial/911.png  \n",
            "  inflating: /content/Data/industrial/95.png  \n",
            "  inflating: /content/Data/industrial/96.png  \n",
            "  inflating: /content/Data/industrial/963.png  \n",
            "  inflating: /content/Data/industrial/996.png  \n",
            "  inflating: /content/Data/industrial/999.png  \n",
            "   creating: /content/Data/outdoors and natural/\n",
            "  inflating: /content/Data/outdoors and natural/1011.png  \n",
            "  inflating: /content/Data/outdoors and natural/1115.png  \n",
            "  inflating: /content/Data/outdoors and natural/1136.png  \n",
            "  inflating: /content/Data/outdoors and natural/1154.png  \n",
            "  inflating: /content/Data/outdoors and natural/1172.png  \n",
            "  inflating: /content/Data/outdoors and natural/119.png  \n",
            "  inflating: /content/Data/outdoors and natural/1198.png  \n",
            "  inflating: /content/Data/outdoors and natural/1203.png  \n",
            "  inflating: /content/Data/outdoors and natural/1247.png  \n",
            "  inflating: /content/Data/outdoors and natural/1248.png  \n",
            "  inflating: /content/Data/outdoors and natural/1253.png  \n",
            "  inflating: /content/Data/outdoors and natural/1265.png  \n",
            "  inflating: /content/Data/outdoors and natural/1301.png  \n",
            "  inflating: /content/Data/outdoors and natural/132.png  \n",
            "  inflating: /content/Data/outdoors and natural/1490.png  \n",
            "  inflating: /content/Data/outdoors and natural/205.png  \n",
            "  inflating: /content/Data/outdoors and natural/237.png  \n",
            "  inflating: /content/Data/outdoors and natural/258.png  \n",
            "  inflating: /content/Data/outdoors and natural/422.png  \n",
            "  inflating: /content/Data/outdoors and natural/466.png  \n",
            "  inflating: /content/Data/outdoors and natural/476.png  \n",
            "  inflating: /content/Data/outdoors and natural/577.png  \n",
            "  inflating: /content/Data/outdoors and natural/593.png  \n",
            "  inflating: /content/Data/outdoors and natural/613.png  \n",
            "  inflating: /content/Data/outdoors and natural/637.png  \n",
            "  inflating: /content/Data/outdoors and natural/641.png  \n",
            "  inflating: /content/Data/outdoors and natural/646.png  \n",
            "  inflating: /content/Data/outdoors and natural/652.png  \n",
            "  inflating: /content/Data/outdoors and natural/657.png  \n",
            "  inflating: /content/Data/outdoors and natural/719.png  \n",
            "  inflating: /content/Data/outdoors and natural/722.png  \n",
            "  inflating: /content/Data/outdoors and natural/825.png  \n",
            "  inflating: /content/Data/outdoors and natural/915.png  \n",
            "  inflating: /content/Data/outdoors and natural/964.png  \n",
            "  inflating: /content/Data/outdoors and natural/965.png  \n",
            "  inflating: /content/Data/outdoors and natural/972.png  \n",
            "  inflating: /content/Data/outdoors and natural/990.png  \n",
            "  inflating: /content/Data/outdoors and natural/991.png  \n",
            "   creating: /content/Data/residential/\n",
            "  inflating: /content/Data/residential/1012.png  \n",
            "  inflating: /content/Data/residential/1018.png  \n",
            "  inflating: /content/Data/residential/102.png  \n",
            "  inflating: /content/Data/residential/1023.png  \n",
            "  inflating: /content/Data/residential/1024.png  \n",
            "  inflating: /content/Data/residential/103.png  \n",
            "  inflating: /content/Data/residential/1030.png  \n",
            "  inflating: /content/Data/residential/1031.png  \n",
            "  inflating: /content/Data/residential/1036.png  \n",
            "  inflating: /content/Data/residential/1041.png  \n",
            "  inflating: /content/Data/residential/1042.png  \n",
            "  inflating: /content/Data/residential/1044.png  \n",
            "  inflating: /content/Data/residential/1045.png  \n",
            "  inflating: /content/Data/residential/1046.png  \n",
            "  inflating: /content/Data/residential/1048.png  \n",
            "  inflating: /content/Data/residential/105.png  \n",
            "  inflating: /content/Data/residential/1052.png  \n",
            "  inflating: /content/Data/residential/1053.png  \n",
            "  inflating: /content/Data/residential/1057.png  \n",
            "  inflating: /content/Data/residential/1058.png  \n",
            "  inflating: /content/Data/residential/1060.png  \n",
            "  inflating: /content/Data/residential/1061.png  \n",
            "  inflating: /content/Data/residential/1066.png  \n",
            "  inflating: /content/Data/residential/1068.png  \n",
            "  inflating: /content/Data/residential/1070.png  \n",
            "  inflating: /content/Data/residential/1073.png  \n",
            "  inflating: /content/Data/residential/1075.png  \n",
            "  inflating: /content/Data/residential/1079.png  \n",
            "  inflating: /content/Data/residential/1084.png  \n",
            "  inflating: /content/Data/residential/1088.png  \n",
            "  inflating: /content/Data/residential/1089.png  \n",
            "  inflating: /content/Data/residential/1090.png  \n",
            "  inflating: /content/Data/residential/1091.png  \n",
            "  inflating: /content/Data/residential/1095.png  \n",
            "  inflating: /content/Data/residential/1103.png  \n",
            "  inflating: /content/Data/residential/1106.png  \n",
            "  inflating: /content/Data/residential/1118.png  \n",
            "  inflating: /content/Data/residential/1126.png  \n",
            "  inflating: /content/Data/residential/1132.png  \n",
            "  inflating: /content/Data/residential/114.png  \n",
            "  inflating: /content/Data/residential/1141.png  \n",
            "  inflating: /content/Data/residential/1145.png  \n",
            "  inflating: /content/Data/residential/1149.png  \n",
            "  inflating: /content/Data/residential/1155.png  \n",
            "  inflating: /content/Data/residential/1156.png  \n",
            "  inflating: /content/Data/residential/1159.png  \n",
            "  inflating: /content/Data/residential/1160.png  \n",
            "  inflating: /content/Data/residential/1163.png  \n",
            "  inflating: /content/Data/residential/1166.png  \n",
            "  inflating: /content/Data/residential/1167.png  \n",
            "  inflating: /content/Data/residential/1168.png  \n",
            "  inflating: /content/Data/residential/1177.png  \n",
            "  inflating: /content/Data/residential/118.png  \n",
            "  inflating: /content/Data/residential/1180.png  \n",
            "  inflating: /content/Data/residential/1186.png  \n",
            "  inflating: /content/Data/residential/1187.png  \n",
            "  inflating: /content/Data/residential/1190.png  \n",
            "  inflating: /content/Data/residential/1192.png  \n",
            "  inflating: /content/Data/residential/1204.png  \n",
            "  inflating: /content/Data/residential/1205.png  \n",
            "  inflating: /content/Data/residential/1209.png  \n",
            "  inflating: /content/Data/residential/1210.png  \n",
            "  inflating: /content/Data/residential/1216.png  \n",
            "  inflating: /content/Data/residential/1222.png  \n",
            "  inflating: /content/Data/residential/1233.png  \n",
            "  inflating: /content/Data/residential/124.png  \n",
            "  inflating: /content/Data/residential/1240.png  \n",
            "  inflating: /content/Data/residential/1241.png  \n",
            "  inflating: /content/Data/residential/1249.png  \n",
            "  inflating: /content/Data/residential/1252.png  \n",
            "  inflating: /content/Data/residential/1254.png  \n",
            "  inflating: /content/Data/residential/1255.png  \n",
            "  inflating: /content/Data/residential/1256.png  \n",
            "  inflating: /content/Data/residential/133.png  \n",
            "  inflating: /content/Data/residential/134.png  \n",
            "  inflating: /content/Data/residential/135.png  \n",
            "  inflating: /content/Data/residential/137.png  \n",
            "  inflating: /content/Data/residential/145.png  \n",
            "  inflating: /content/Data/residential/1468.png  \n",
            "  inflating: /content/Data/residential/149.png  \n",
            "  inflating: /content/Data/residential/150.png  \n",
            "  inflating: /content/Data/residential/154.png  \n",
            "  inflating: /content/Data/residential/158.png  \n",
            "  inflating: /content/Data/residential/159.png  \n",
            "  inflating: /content/Data/residential/160.png  \n",
            "  inflating: /content/Data/residential/161.png  \n",
            "  inflating: /content/Data/residential/163.png  \n",
            "  inflating: /content/Data/residential/165.png  \n",
            "  inflating: /content/Data/residential/170.png  \n",
            "  inflating: /content/Data/residential/172.png  \n",
            "  inflating: /content/Data/residential/173.png  \n",
            "  inflating: /content/Data/residential/18.png  \n",
            "  inflating: /content/Data/residential/186.png  \n",
            "  inflating: /content/Data/residential/187.png  \n",
            "  inflating: /content/Data/residential/194.png  \n",
            "  inflating: /content/Data/residential/208.png  \n",
            "  inflating: /content/Data/residential/21.png  \n",
            "  inflating: /content/Data/residential/210.png  \n",
            "  inflating: /content/Data/residential/211.png  \n",
            "  inflating: /content/Data/residential/214.png  \n",
            "  inflating: /content/Data/residential/217.png  \n",
            "  inflating: /content/Data/residential/219.png  \n",
            "  inflating: /content/Data/residential/22.png  \n",
            "  inflating: /content/Data/residential/222.png  \n",
            "  inflating: /content/Data/residential/226.png  \n",
            "  inflating: /content/Data/residential/227.png  \n",
            "  inflating: /content/Data/residential/231.png  \n",
            "  inflating: /content/Data/residential/232.png  \n",
            "  inflating: /content/Data/residential/242.png  \n",
            "  inflating: /content/Data/residential/243.png  \n",
            "  inflating: /content/Data/residential/246.png  \n",
            "  inflating: /content/Data/residential/247.png  \n",
            "  inflating: /content/Data/residential/248.png  \n",
            "  inflating: /content/Data/residential/252.png  \n",
            "  inflating: /content/Data/residential/26.png  \n",
            "  inflating: /content/Data/residential/260.png  \n",
            "  inflating: /content/Data/residential/266.png  \n",
            "  inflating: /content/Data/residential/269.png  \n",
            "  inflating: /content/Data/residential/270.png  \n",
            "  inflating: /content/Data/residential/274.png  \n",
            "  inflating: /content/Data/residential/277.png  \n",
            "  inflating: /content/Data/residential/279.png  \n",
            "  inflating: /content/Data/residential/286.png  \n",
            "  inflating: /content/Data/residential/287.png  \n",
            "  inflating: /content/Data/residential/289.png  \n",
            "  inflating: /content/Data/residential/295.png  \n",
            "  inflating: /content/Data/residential/296.png  \n",
            "  inflating: /content/Data/residential/297.png  \n",
            "  inflating: /content/Data/residential/298.png  \n",
            "  inflating: /content/Data/residential/299.png  \n",
            "  inflating: /content/Data/residential/303.png  \n",
            "  inflating: /content/Data/residential/307.png  \n",
            "  inflating: /content/Data/residential/308.png  \n",
            "  inflating: /content/Data/residential/310.png  \n",
            "  inflating: /content/Data/residential/314.png  \n",
            "  inflating: /content/Data/residential/315.png  \n",
            "  inflating: /content/Data/residential/317.png  \n",
            "  inflating: /content/Data/residential/32.png  \n",
            "  inflating: /content/Data/residential/329.png  \n",
            "  inflating: /content/Data/residential/331.png  \n",
            "  inflating: /content/Data/residential/334.png  \n",
            "  inflating: /content/Data/residential/335.png  \n",
            "  inflating: /content/Data/residential/336.png  \n",
            "  inflating: /content/Data/residential/341.png  \n",
            "  inflating: /content/Data/residential/343.png  \n",
            "  inflating: /content/Data/residential/344.png  \n",
            "  inflating: /content/Data/residential/346.png  \n",
            "  inflating: /content/Data/residential/349.png  \n",
            "  inflating: /content/Data/residential/35.png  \n",
            "  inflating: /content/Data/residential/357.png  \n",
            "  inflating: /content/Data/residential/36.png  \n",
            "  inflating: /content/Data/residential/37.png  \n",
            "  inflating: /content/Data/residential/372.png  \n",
            "  inflating: /content/Data/residential/375.png  \n",
            "  inflating: /content/Data/residential/381.png  \n",
            "  inflating: /content/Data/residential/386.png  \n",
            "  inflating: /content/Data/residential/394.png  \n",
            "  inflating: /content/Data/residential/398.png  \n",
            "  inflating: /content/Data/residential/4.png  \n",
            "  inflating: /content/Data/residential/40.png  \n",
            "  inflating: /content/Data/residential/405.png  \n",
            "  inflating: /content/Data/residential/412.png  \n",
            "  inflating: /content/Data/residential/42.png  \n",
            "  inflating: /content/Data/residential/427.png  \n",
            "  inflating: /content/Data/residential/433.png  \n",
            "  inflating: /content/Data/residential/443.png  \n",
            "  inflating: /content/Data/residential/448.png  \n",
            "  inflating: /content/Data/residential/449.png  \n",
            "  inflating: /content/Data/residential/456.png  \n",
            "  inflating: /content/Data/residential/458.png  \n",
            "  inflating: /content/Data/residential/459.png  \n",
            "  inflating: /content/Data/residential/463.png  \n",
            "  inflating: /content/Data/residential/464.png  \n",
            "  inflating: /content/Data/residential/467.png  \n",
            "  inflating: /content/Data/residential/47.png  \n",
            "  inflating: /content/Data/residential/474.png  \n",
            "  inflating: /content/Data/residential/475.png  \n",
            "  inflating: /content/Data/residential/477.png  \n",
            "  inflating: /content/Data/residential/480.png  \n",
            "  inflating: /content/Data/residential/481.png  \n",
            "  inflating: /content/Data/residential/482.png  \n",
            "  inflating: /content/Data/residential/484.png  \n",
            "  inflating: /content/Data/residential/485.png  \n",
            "  inflating: /content/Data/residential/487.png  \n",
            "  inflating: /content/Data/residential/49.png  \n",
            "  inflating: /content/Data/residential/493.png  \n",
            "  inflating: /content/Data/residential/495.png  \n",
            "  inflating: /content/Data/residential/50.png  \n",
            "  inflating: /content/Data/residential/501.png  \n",
            "  inflating: /content/Data/residential/505.png  \n",
            "  inflating: /content/Data/residential/506.png  \n",
            "  inflating: /content/Data/residential/507.png  \n",
            "  inflating: /content/Data/residential/508.png  \n",
            "  inflating: /content/Data/residential/509.png  \n",
            "  inflating: /content/Data/residential/51.png  \n",
            "  inflating: /content/Data/residential/512.png  \n",
            "  inflating: /content/Data/residential/513.png  \n",
            "  inflating: /content/Data/residential/519.png  \n",
            "  inflating: /content/Data/residential/523.png  \n",
            "  inflating: /content/Data/residential/536.png  \n",
            "  inflating: /content/Data/residential/539.png  \n",
            "  inflating: /content/Data/residential/546.png  \n",
            "  inflating: /content/Data/residential/554.png  \n",
            "  inflating: /content/Data/residential/559.png  \n",
            "  inflating: /content/Data/residential/561.png  \n",
            "  inflating: /content/Data/residential/563.png  \n",
            "  inflating: /content/Data/residential/564.png  \n",
            "  inflating: /content/Data/residential/570.png  \n",
            "  inflating: /content/Data/residential/572.png  \n",
            "  inflating: /content/Data/residential/573.png  \n",
            "  inflating: /content/Data/residential/578.png  \n",
            "  inflating: /content/Data/residential/579.png  \n",
            "  inflating: /content/Data/residential/586.png  \n",
            "  inflating: /content/Data/residential/588.png  \n",
            "  inflating: /content/Data/residential/594.png  \n",
            "  inflating: /content/Data/residential/6.png  \n",
            "  inflating: /content/Data/residential/61.png  \n",
            "  inflating: /content/Data/residential/612.png  \n",
            "  inflating: /content/Data/residential/619.png  \n",
            "  inflating: /content/Data/residential/629.png  \n",
            "  inflating: /content/Data/residential/636.png  \n",
            "  inflating: /content/Data/residential/638.png  \n",
            "  inflating: /content/Data/residential/643.png  \n",
            "  inflating: /content/Data/residential/650.png  \n",
            "  inflating: /content/Data/residential/656.png  \n",
            "  inflating: /content/Data/residential/658.png  \n",
            "  inflating: /content/Data/residential/662.png  \n",
            "  inflating: /content/Data/residential/663.png  \n",
            "  inflating: /content/Data/residential/667.png  \n",
            "  inflating: /content/Data/residential/669.png  \n",
            "  inflating: /content/Data/residential/670.png  \n",
            "  inflating: /content/Data/residential/673.png  \n",
            "  inflating: /content/Data/residential/675.png  \n",
            "  inflating: /content/Data/residential/677.png  \n",
            "  inflating: /content/Data/residential/678.png  \n",
            "  inflating: /content/Data/residential/68.png  \n",
            "  inflating: /content/Data/residential/686.png  \n",
            "  inflating: /content/Data/residential/687.png  \n",
            "  inflating: /content/Data/residential/692.png  \n",
            "  inflating: /content/Data/residential/698.png  \n",
            "  inflating: /content/Data/residential/702.png  \n",
            "  inflating: /content/Data/residential/710.png  \n",
            "  inflating: /content/Data/residential/715.png  \n",
            "  inflating: /content/Data/residential/729.png  \n",
            "  inflating: /content/Data/residential/731.png  \n",
            "  inflating: /content/Data/residential/735.png  \n",
            "  inflating: /content/Data/residential/736.png  \n",
            "  inflating: /content/Data/residential/740.png  \n",
            "  inflating: /content/Data/residential/741.png  \n",
            "  inflating: /content/Data/residential/742.png  \n",
            "  inflating: /content/Data/residential/752.png  \n",
            "  inflating: /content/Data/residential/756.png  \n",
            "  inflating: /content/Data/residential/759.png  \n",
            "  inflating: /content/Data/residential/762.png  \n",
            "  inflating: /content/Data/residential/765.png  \n",
            "  inflating: /content/Data/residential/767.png  \n",
            "  inflating: /content/Data/residential/770.png  \n",
            "  inflating: /content/Data/residential/776.png  \n",
            "  inflating: /content/Data/residential/78.png  \n",
            "  inflating: /content/Data/residential/780.png  \n",
            "  inflating: /content/Data/residential/782.png  \n",
            "  inflating: /content/Data/residential/786.png  \n",
            "  inflating: /content/Data/residential/788.png  \n",
            "  inflating: /content/Data/residential/789.png  \n",
            "  inflating: /content/Data/residential/790.png  \n",
            "  inflating: /content/Data/residential/793.png  \n",
            "  inflating: /content/Data/residential/795.png  \n",
            "  inflating: /content/Data/residential/797.png  \n",
            "  inflating: /content/Data/residential/803.png  \n",
            "  inflating: /content/Data/residential/806.png  \n",
            "  inflating: /content/Data/residential/811.png  \n",
            "  inflating: /content/Data/residential/814.png  \n",
            "  inflating: /content/Data/residential/818.png  \n",
            "  inflating: /content/Data/residential/822.png  \n",
            "  inflating: /content/Data/residential/824.png  \n",
            "  inflating: /content/Data/residential/83.png  \n",
            "  inflating: /content/Data/residential/830.png  \n",
            "  inflating: /content/Data/residential/833.png  \n",
            "  inflating: /content/Data/residential/834.png  \n",
            "  inflating: /content/Data/residential/836.png  \n",
            "  inflating: /content/Data/residential/842.png  \n",
            "  inflating: /content/Data/residential/844.png  \n",
            "  inflating: /content/Data/residential/845.png  \n",
            "  inflating: /content/Data/residential/846.png  \n",
            "  inflating: /content/Data/residential/847.png  \n",
            "  inflating: /content/Data/residential/849.png  \n",
            "  inflating: /content/Data/residential/851.png  \n",
            "  inflating: /content/Data/residential/857.png  \n",
            "  inflating: /content/Data/residential/863.png  \n",
            "  inflating: /content/Data/residential/867.png  \n",
            "  inflating: /content/Data/residential/871.png  \n",
            "  inflating: /content/Data/residential/879.png  \n",
            "  inflating: /content/Data/residential/88.png  \n",
            "  inflating: /content/Data/residential/887.png  \n",
            "  inflating: /content/Data/residential/888.png  \n",
            "  inflating: /content/Data/residential/889.png  \n",
            "  inflating: /content/Data/residential/891.png  \n",
            "  inflating: /content/Data/residential/892.png  \n",
            "  inflating: /content/Data/residential/897.png  \n",
            "  inflating: /content/Data/residential/9.png  \n",
            "  inflating: /content/Data/residential/902.png  \n",
            "  inflating: /content/Data/residential/906.png  \n",
            "  inflating: /content/Data/residential/907.png  \n",
            "  inflating: /content/Data/residential/912.png  \n",
            "  inflating: /content/Data/residential/914.png  \n",
            "  inflating: /content/Data/residential/918.png  \n",
            "  inflating: /content/Data/residential/922.png  \n",
            "  inflating: /content/Data/residential/925.png  \n",
            "  inflating: /content/Data/residential/927.png  \n",
            "  inflating: /content/Data/residential/928.png  \n",
            "  inflating: /content/Data/residential/93.png  \n",
            "  inflating: /content/Data/residential/930.png  \n",
            "  inflating: /content/Data/residential/931.png  \n",
            "  inflating: /content/Data/residential/933.png  \n",
            "  inflating: /content/Data/residential/936.png  \n",
            "  inflating: /content/Data/residential/938.png  \n",
            "  inflating: /content/Data/residential/939.png  \n",
            "  inflating: /content/Data/residential/942.png  \n",
            "  inflating: /content/Data/residential/944.png  \n",
            "  inflating: /content/Data/residential/945.png  \n",
            "  inflating: /content/Data/residential/947.png  \n",
            "  inflating: /content/Data/residential/949.png  \n",
            "  inflating: /content/Data/residential/955.png  \n",
            "  inflating: /content/Data/residential/959.png  \n",
            "  inflating: /content/Data/residential/961.png  \n",
            "  inflating: /content/Data/residential/968.png  \n",
            "  inflating: /content/Data/residential/970.png  \n",
            "  inflating: /content/Data/residential/974.png  \n",
            "  inflating: /content/Data/residential/975.png  \n",
            "  inflating: /content/Data/residential/979.png  \n",
            "  inflating: /content/Data/residential/988.png  \n",
            "  inflating: /content/Data/residential/989.png  \n",
            "  inflating: /content/Data/residential/992.png  \n",
            "  inflating: /content/Data/residential/995.png  \n",
            "  inflating: /content/Data/residential/998.png  \n",
            "   creating: /content/Data/sports and recreation/\n",
            "  inflating: /content/Data/sports and recreation/1098.png  \n",
            "  inflating: /content/Data/sports and recreation/130.png  \n",
            "  inflating: /content/Data/sports and recreation/1341.png  \n",
            "  inflating: /content/Data/sports and recreation/1366.png  \n",
            "  inflating: /content/Data/sports and recreation/1376.png  \n",
            "  inflating: /content/Data/sports and recreation/1377.png  \n",
            "  inflating: /content/Data/sports and recreation/138.png  \n",
            "  inflating: /content/Data/sports and recreation/1381.png  \n",
            "  inflating: /content/Data/sports and recreation/1389.png  \n",
            "  inflating: /content/Data/sports and recreation/1410.png  \n",
            "  inflating: /content/Data/sports and recreation/1486.png  \n",
            "  inflating: /content/Data/sports and recreation/1495.png  \n",
            "  inflating: /content/Data/sports and recreation/182.png  \n",
            "  inflating: /content/Data/sports and recreation/185.png  \n",
            "  inflating: /content/Data/sports and recreation/196.png  \n",
            "  inflating: /content/Data/sports and recreation/220.png  \n",
            "  inflating: /content/Data/sports and recreation/25.png  \n",
            "  inflating: /content/Data/sports and recreation/31.png  \n",
            "  inflating: /content/Data/sports and recreation/55.png  \n",
            "  inflating: /content/Data/sports and recreation/571.png  \n",
            "  inflating: /content/Data/sports and recreation/574.png  \n",
            "  inflating: /content/Data/sports and recreation/604.png  \n",
            "  inflating: /content/Data/sports and recreation/680.png  \n",
            "  inflating: /content/Data/sports and recreation/691.png  \n",
            "  inflating: /content/Data/sports and recreation/704.png  \n",
            "  inflating: /content/Data/sports and recreation/717.png  \n",
            "  inflating: /content/Data/sports and recreation/746.png  \n",
            "  inflating: /content/Data/sports and recreation/920.png  \n",
            "   creating: /content/Data/transportation/\n",
            "  inflating: /content/Data/transportation/1.png  \n",
            "  inflating: /content/Data/transportation/1005.png  \n",
            "  inflating: /content/Data/transportation/1021.png  \n",
            "  inflating: /content/Data/transportation/1069.png  \n",
            "  inflating: /content/Data/transportation/1232.png  \n",
            "  inflating: /content/Data/transportation/1234.png  \n",
            "  inflating: /content/Data/transportation/125.png  \n",
            "  inflating: /content/Data/transportation/144.png  \n",
            "  inflating: /content/Data/transportation/147.png  \n",
            "  inflating: /content/Data/transportation/164.png  \n",
            "  inflating: /content/Data/transportation/171.png  \n",
            "  inflating: /content/Data/transportation/190.png  \n",
            "  inflating: /content/Data/transportation/192.png  \n",
            "  inflating: /content/Data/transportation/193.png  \n",
            "  inflating: /content/Data/transportation/221.png  \n",
            "  inflating: /content/Data/transportation/235.png  \n",
            "  inflating: /content/Data/transportation/236.png  \n",
            "  inflating: /content/Data/transportation/251.png  \n",
            "  inflating: /content/Data/transportation/254.png  \n",
            "  inflating: /content/Data/transportation/263.png  \n",
            "  inflating: /content/Data/transportation/304.png  \n",
            "  inflating: /content/Data/transportation/318.png  \n",
            "  inflating: /content/Data/transportation/319.png  \n",
            "  inflating: /content/Data/transportation/320.png  \n",
            "  inflating: /content/Data/transportation/321.png  \n",
            "  inflating: /content/Data/transportation/323.png  \n",
            "  inflating: /content/Data/transportation/328.png  \n",
            "  inflating: /content/Data/transportation/45.png  \n",
            "  inflating: /content/Data/transportation/457.png  \n",
            "  inflating: /content/Data/transportation/460.png  \n",
            "  inflating: /content/Data/transportation/479.png  \n",
            "  inflating: /content/Data/transportation/48.png  \n",
            "  inflating: /content/Data/transportation/489.png  \n",
            "  inflating: /content/Data/transportation/491.png  \n",
            "  inflating: /content/Data/transportation/517.png  \n",
            "  inflating: /content/Data/transportation/528.png  \n",
            "  inflating: /content/Data/transportation/57.png  \n",
            "  inflating: /content/Data/transportation/615.png  \n",
            "  inflating: /content/Data/transportation/626.png  \n",
            "  inflating: /content/Data/transportation/685.png  \n",
            "  inflating: /content/Data/transportation/72.png  \n",
            "  inflating: /content/Data/transportation/720.png  \n",
            "  inflating: /content/Data/transportation/860.png  \n",
            "  inflating: /content/Data/transportation/87.png  \n",
            "  inflating: /content/Data/transportation/900.png  \n",
            "  inflating: /content/Data/transportation/937.png  \n",
            "  inflating: /content/Data/transportation/99.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfAYmgUKHqSA",
        "outputId": "6961a9db-2e8b-4006-f097-8798c4cf9584"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'civic, governmental and cultural'   education\t    industrial\t\t   'sports and recreation'\n",
            " commercial\t\t\t    'health care'  'outdoors and natural'   transportation\n",
            " correct_function.py\t\t     hotel\t    residential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoFeatureExtractor, AutoModel\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "#  GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#  facebook/vit-large-patch14-336 \n",
        "model_name = \"facebook/vit-large-patch14-336\"\n",
        "print(f\"Loading model and feature extractor for {model_name}...\")\n",
        "model = AutoModel.from_pretrained(model_name).to(device)\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "model.eval()  # \n",
        "\n",
        "# \n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # \n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\"Found {len(image_paths)} images in {image_folder}.\")\n",
        "\n",
        "    # \n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            #  RGB \n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            # \n",
        "            inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "            # \n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "                #  [CLS] token \n",
        "                image_features = outputs.last_hidden_state[:, 0]\n",
        "\n",
        "                # \n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                #  CPU \n",
        "                image_features_list.append(image_features.cpu())\n",
        "                image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" {image_path} : {e}\")\n",
        "\n",
        "    # \n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\" {output_file}\")\n",
        "    else:\n",
        "        print(f\" {image_folder} \")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "#  CSV \n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"\")\n",
        "        return\n",
        "\n",
        "    print(\"...\")\n",
        "\n",
        "    # \n",
        "    # \n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()\n",
        "\n",
        "    print(f\": {similarity_matrix.shape}\")\n",
        "\n",
        "    #  DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    #  CSV \n",
        "    df.to_csv(csv_output)\n",
        "    print(f\" {csv_output}\")\n",
        "\n",
        "# \n",
        "if __name__ == \"__main__\":\n",
        "    # \n",
        "    image_folder = './Data/civic, governmental and cultural'\n",
        "    feature_output = './imgs_vit_1.pt'\n",
        "    csv_output = './cosine_similarity_matrix.csv'\n",
        "\n",
        "    # \n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    #  CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nmSSOt2KnScB",
        "outputId": "6c843d9e-2b81-45f0-a8be-9508e982991b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading model and feature extractor for facebook/vit-large-patch14-336...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "facebook/vit-large-patch14-336 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/facebook/vit-large-patch14-336/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-677007cb-6049569f32f3bb840d2568c5;d3013012-13a7-4677-b684-be550afda868)\n\nRepository Not Found for url: https://huggingface.co/facebook/vit-large-patch14-336/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7734868a636d>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/vit-large-patch14-336\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading model and feature extractor for {model_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoFeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# \u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: facebook/vit-large-patch14-336 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j6zfMt-r4lS",
        "outputId": "2c52b717-fcc3-40a3-f657-2dc87dc8e63d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-kw85g05g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-kw85g05g\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=60fb964f90981a8aff8ff3b55aff3f4becbdcfaaa49f1520189692a3f450eea0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m0mu_3n7/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "#  CLIP \n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "#  GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#  CLIP \n",
        "model_name = \"ViT-L/14@336px\"  #  CLIP \n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # \n",
        "print(\"CLIP \")\n",
        "\n",
        "# \n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # \n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\" {image_folder}  {len(image_paths)} \")\n",
        "\n",
        "    # \n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # \n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # \n",
        "\n",
        "            # \n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # \n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # \n",
        "\n",
        "            #  CPU \n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" {image_path} : {e}\")\n",
        "\n",
        "    # \n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\" {output_file}\")\n",
        "    else:\n",
        "        print(f\" {image_folder} \")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "#  CSV \n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"\")\n",
        "        return\n",
        "\n",
        "    print(\"...\")\n",
        "\n",
        "    # \n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\": {similarity_matrix.shape}\")\n",
        "\n",
        "    #  DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    #  CSV \n",
        "    df.to_csv(csv_output)\n",
        "    print(f\" {csv_output}\")\n",
        "\n",
        "# \n",
        "if __name__ == \"__main__\":\n",
        "    # \n",
        "    image_folder = './Data/commercial'\n",
        "    feature_output = './imgs_vit_commercial.pt'\n",
        "    csv_output = './cosine_similarity_matrix_commercial.csv'\n",
        "\n",
        "    # \n",
        "    os.makedirs(os.path.dirname(feature_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(csv_output), exist_ok=True)\n",
        "\n",
        "    # \n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    #  CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s-jv9yIqs8S",
        "outputId": "f24c5765-6e7b-4bf9-af9a-5ff21cf7f844"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 891M/891M [00:09<00:00, 95.6MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP \n",
            " ./Data/commercial  208 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/commercial: 100%|| 208/208 [00:06<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ./imgs_vit_commercial.pt\n",
            "...\n",
            ": (208, 208)\n",
            " ./cosine_similarity_matrix_commercial.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "#  CLIP \n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "#  GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#  CLIP \n",
        "model_name = \"ViT-L/14@336px\"  #  CLIP \n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # \n",
        "print(\"CLIP \")\n",
        "\n",
        "# \n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # \n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\" {image_folder}  {len(image_paths)} \")\n",
        "\n",
        "    # \n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # \n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # \n",
        "\n",
        "            # \n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # \n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # \n",
        "\n",
        "            #  CPU \n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" {image_path} : {e}\")\n",
        "\n",
        "    # \n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\" {output_file}\")\n",
        "    else:\n",
        "        print(f\" {image_folder} \")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "#  CSV \n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"\")\n",
        "        return\n",
        "\n",
        "    print(\"...\")\n",
        "\n",
        "    # \n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\": {similarity_matrix.shape}\")\n",
        "\n",
        "    #  DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # \n",
        "    column_means = df.mean(axis=0)  # \n",
        "    df.loc['Mean', :] = column_means  # \n",
        "\n",
        "    #  CSV \n",
        "    df.to_csv(csv_output)\n",
        "    print(f\" {csv_output}\")\n",
        "\n",
        "    #  0.8 \n",
        "    high_similarity_columns = column_means[column_means > 0.8].index.tolist()\n",
        "    with open(mean_output, 'w') as f:\n",
        "        for col in high_similarity_columns:\n",
        "            f.write(f\"{col}\\n\")\n",
        "    print(f\" 0.8  {mean_output}\")\n",
        "\n",
        "# \n",
        "if __name__ == \"__main__\":\n",
        "    # \n",
        "    image_folder = './Data/commercial'\n",
        "    feature_output = './imgs_vit_commercial.pt'\n",
        "    csv_output = './cosine_similarity_matrix_commercial.csv'\n",
        "    mean_output = './commercial.txt'  #  0.8 \n",
        "\n",
        "    # \n",
        "    os.makedirs(os.path.dirname(feature_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(csv_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(mean_output), exist_ok=True)\n",
        "\n",
        "    # \n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    #  CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cS6BLN6N9MD",
        "outputId": "1e1baa76-dd25-4588-821e-591d69c564bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP \n",
            " ./Data/commercial  208 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/commercial: 100%|| 208/208 [00:05<00:00, 36.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ./imgs_vit_commercial.pt\n",
            "...\n",
            ": (208, 208)\n",
            " ./cosine_similarity_matrix_commercial.csv\n",
            " 0.8  ./commercial.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "#  CLIP \n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "#  GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#  CLIP \n",
        "model_name = \"ViT-L/14@336px\"  #  CLIP \n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # \n",
        "print(\"CLIP \")\n",
        "\n",
        "#  high_similarity_columns.txt \n",
        "def load_high_similarity_images(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        image_filenames = [line.strip() for line in f.readlines()]\n",
        "    return image_filenames\n",
        "\n",
        "# \n",
        "def extract_selected_features(image_folder, selected_filenames):\n",
        "    image_features_list = []\n",
        "\n",
        "    # \n",
        "    for image_filename in tqdm(selected_filenames, desc=\"Processing selected images\"):\n",
        "        image_path = os.path.join(image_folder, image_filename)\n",
        "\n",
        "        try:\n",
        "            # \n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # \n",
        "\n",
        "            # \n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # \n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # \n",
        "\n",
        "            #  CPU \n",
        "            image_features_list.append(image_features.cpu())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" {image_path} : {e}\")\n",
        "\n",
        "    # \n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        return image_features\n",
        "    else:\n",
        "        print(f\"\")\n",
        "        return None\n",
        "\n",
        "# \n",
        "def compute_feature_mean(features):\n",
        "    if features is None:\n",
        "        print(\"\")\n",
        "        return None\n",
        "    feature_mean = features.mean(dim=0)  # \n",
        "    return feature_mean\n",
        "\n",
        "# \n",
        "def compute_cosine_similarity(feature_mean, all_features):\n",
        "    # \n",
        "    cosine_similarities = torch.matmul(all_features, feature_mean)  # \n",
        "    return cosine_similarities\n",
        "\n",
        "# \n",
        "if __name__ == \"__main__\":\n",
        "    # \n",
        "    image_folder = './Data/commercial'  # \n",
        "    high_similarity_file = './commercial.txt'  # \n",
        "    feature_file = './imgs_vit_commercial.pt'  # \n",
        "\n",
        "    #  high_similarity_columns.txt \n",
        "    selected_filenames = load_high_similarity_images(high_similarity_file)\n",
        "\n",
        "    # \n",
        "    selected_features = extract_selected_features(image_folder, selected_filenames)\n",
        "\n",
        "    # \n",
        "    feature_mean = compute_feature_mean(selected_features)\n",
        "\n",
        "    if feature_mean is not None:\n",
        "        print(f\"{feature_mean}\")\n",
        "\n",
        "        #  imgs_vit_commercial.pt \n",
        "        all_features = torch.load(feature_file)\n",
        "        print(f\": {all_features.shape}\")\n",
        "\n",
        "        # \n",
        "        cosine_similarities = compute_cosine_similarity(feature_mean, all_features)\n",
        "\n",
        "        #  DataFrame  CSV\n",
        "        similarity_df = pd.DataFrame(cosine_similarities.numpy(), columns=[\"Cosine Similarity\"])\n",
        "        similarity_df[\"Image Filename\"] = os.listdir(image_folder)  # \n",
        "\n",
        "        #  CSV\n",
        "        similarity_df = similarity_df.sort_values(by=\"Cosine Similarity\", ascending=False)\n",
        "        similarity_df.to_csv('./cosine_similarity_with_mean.csv', index=False)\n",
        "\n",
        "        print(\" cosine_similarity_with_mean.csv\")\n",
        "    else:\n",
        "        print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCN-Emu8Qchy",
        "outputId": "9a26584d-8916-4eb4-8f02-c9896388dca3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing selected images: 100%|| 109/109 [00:02<00:00, 37.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.0981e-02,  3.9764e-02,  1.8112e-02,  2.4582e-02, -1.0033e-02,\n",
            "         1.6434e-02,  1.9516e-02, -2.9358e-02,  3.7231e-02, -3.5980e-02,\n",
            "        -1.5366e-02, -1.6769e-02, -1.6876e-02,  3.1799e-02, -7.8430e-03,\n",
            "         2.4902e-02, -1.6174e-02, -5.2071e-04,  5.3162e-02, -1.9531e-02,\n",
            "        -1.3123e-02,  2.2354e-03, -1.2657e-02,  3.2867e-02, -4.1656e-03,\n",
            "        -1.0452e-02,  3.3722e-02, -3.7441e-03, -4.1138e-02,  1.0544e-02,\n",
            "         4.0436e-03,  1.3916e-02,  4.9477e-03, -2.7313e-02, -1.3763e-02,\n",
            "         3.5828e-02, -3.1036e-02, -2.1881e-02,  5.4693e-04, -1.1475e-02,\n",
            "        -1.2726e-02, -3.0098e-03,  1.5381e-02, -1.7792e-02,  3.4790e-02,\n",
            "         2.1027e-02,  3.0746e-02, -1.0727e-02,  9.2316e-03, -1.5732e-02,\n",
            "         1.8143e-02, -7.8430e-03,  1.4763e-02,  1.8616e-02, -8.7280e-03,\n",
            "        -2.8133e-03,  1.9577e-02,  4.2877e-03, -2.4185e-02, -2.3224e-02,\n",
            "         1.7899e-02, -2.9129e-02,  1.6632e-02,  6.3858e-03,  2.5543e-02,\n",
            "         7.6904e-03, -1.5869e-03,  9.1095e-03,  3.3951e-03, -4.7188e-03,\n",
            "         1.7517e-02, -7.4081e-03,  1.1551e-02, -1.6281e-02,  2.4460e-02,\n",
            "         8.2493e-04, -9.0332e-03,  1.8875e-02,  1.0002e-02,  1.4992e-03,\n",
            "         2.9945e-03,  3.4149e-02, -3.6896e-02,  8.6823e-03,  5.2338e-03,\n",
            "        -2.0966e-02, -3.3752e-02,  2.6276e-02, -2.5024e-02,  3.1311e-02,\n",
            "         2.2263e-02,  1.3794e-02, -2.6875e-03, -2.2858e-02,  1.0086e-02,\n",
            "        -2.8305e-03, -7.5531e-04,  2.2354e-02, -9.0408e-03, -9.2926e-03,\n",
            "        -5.0781e-02,  1.4618e-02,  3.0518e-02, -1.9913e-02, -1.8661e-02,\n",
            "        -1.8555e-02,  7.5417e-03, -1.2505e-02,  7.0686e-03,  4.2801e-03,\n",
            "        -7.7591e-03,  3.6774e-02, -2.8372e-05,  1.1169e-02, -1.7426e-02,\n",
            "         1.7685e-02, -5.4230e-02, -1.1482e-02, -9.1309e-02, -8.0872e-03,\n",
            "        -1.8417e-02,  1.3666e-03,  6.1321e-04, -7.2250e-03, -1.7242e-02,\n",
            "        -2.0081e-02, -4.0680e-02,  1.8661e-02, -3.6346e-02, -1.9470e-02,\n",
            "        -3.1830e-02,  1.6870e-01, -1.1047e-02, -5.0903e-02,  8.6060e-03,\n",
            "        -6.5125e-02, -6.8665e-03, -5.8060e-03, -6.4230e-04, -2.5940e-02,\n",
            "        -6.8626e-03, -4.9095e-03, -1.8326e-02, -7.4234e-03, -3.3844e-02,\n",
            "        -9.3994e-03,  2.0538e-02,  1.1102e-01, -2.7222e-02,  1.3710e-02,\n",
            "        -1.2421e-02, -4.5837e-02, -1.8387e-02,  2.7588e-02,  1.2459e-02,\n",
            "        -7.4081e-03, -3.6041e-02,  2.5864e-02, -2.6505e-02, -1.0963e-02,\n",
            "        -1.3718e-02,  1.9897e-02,  1.1086e-04, -8.1253e-03,  5.4512e-03,\n",
            "        -2.3376e-02, -1.9714e-02,  2.1271e-02, -2.1454e-02,  6.1951e-03,\n",
            "         2.9205e-02, -3.2272e-03, -6.1893e-04,  6.1493e-03, -9.6588e-03,\n",
            "        -4.4037e-02,  1.9638e-02, -3.8574e-02, -2.6035e-03,  1.6617e-02,\n",
            "         6.6528e-02, -3.9406e-03, -3.5801e-03,  1.7838e-02, -2.4612e-02,\n",
            "        -1.2131e-02, -4.9782e-03,  3.7556e-03,  3.8452e-02,  6.1035e-03,\n",
            "         2.6245e-02,  3.1815e-03, -3.0174e-03, -2.3315e-02, -1.8433e-02,\n",
            "        -5.3070e-02, -1.9196e-02,  4.0779e-03, -1.0376e-02, -3.8544e-02,\n",
            "        -5.0783e-04, -2.9877e-02, -6.1417e-03,  5.7716e-03, -2.1606e-02,\n",
            "         3.5187e-02,  6.1913e-03,  8.7967e-03,  2.4765e-02, -1.6296e-02,\n",
            "         1.9207e-03, -3.1376e-03,  1.9608e-02, -1.1391e-02,  1.1131e-02,\n",
            "        -1.1070e-02, -1.2169e-02,  1.9089e-02, -1.2238e-02, -1.4130e-02,\n",
            "         2.0714e-03, -2.0157e-02, -2.8427e-02,  3.8666e-02, -1.5129e-02,\n",
            "        -2.0004e-02,  4.3213e-02, -2.0813e-02,  1.1200e-02, -1.0834e-02,\n",
            "        -1.1833e-02, -3.5889e-02,  5.1575e-03,  9.1095e-03, -3.9459e-02,\n",
            "        -1.4772e-03, -3.8147e-04,  2.6550e-03,  1.3405e-02,  1.4015e-02,\n",
            "        -1.2634e-02, -9.4986e-03,  5.7526e-03,  2.7771e-03, -2.0767e-02,\n",
            "         4.0527e-02, -1.7805e-03,  1.6159e-02,  3.2043e-02, -8.4152e-03,\n",
            "         3.4313e-03, -6.0577e-03,  5.0812e-03,  1.9512e-03,  1.4427e-02,\n",
            "        -2.1332e-02, -8.2321e-03, -2.2293e-02, -9.2468e-03, -2.2202e-02,\n",
            "        -9.7504e-03, -1.4137e-02,  2.8114e-03, -1.0853e-03, -2.3605e-02,\n",
            "         3.4607e-02,  5.8985e-04,  1.7471e-02, -6.1464e-04,  1.6174e-02,\n",
            "        -2.9526e-02,  4.8676e-02, -3.7785e-03,  1.6129e-02, -6.0005e-03,\n",
            "         2.6550e-03, -1.1978e-02,  3.4363e-02, -1.2321e-02,  2.8778e-02,\n",
            "        -1.2573e-02,  7.4339e-04,  1.2985e-02,  1.0239e-02,  4.6783e-02,\n",
            "        -2.8244e-02,  1.7990e-02, -2.2110e-02, -3.8818e-02, -1.1467e-02,\n",
            "         1.1238e-02, -4.9744e-03, -1.8845e-02, -3.5492e-02, -8.1062e-04,\n",
            "        -3.5431e-02, -1.4858e-03, -3.1616e-02,  1.2772e-02, -1.1238e-02,\n",
            "         2.2446e-02,  3.2883e-03,  2.0462e-02,  1.0422e-02,  7.8506e-03,\n",
            "         5.4893e-03, -1.1726e-02,  1.2264e-03, -3.3379e-03,  3.0945e-02,\n",
            "        -2.8824e-02,  7.7629e-04,  3.5706e-03,  4.6997e-03, -2.4815e-03,\n",
            "         2.9694e-02, -4.2969e-02,  4.2328e-02, -1.2039e-02,  5.5267e-02,\n",
            "        -9.4938e-04,  2.2446e-02,  7.6103e-03,  1.2428e-02, -2.1164e-02,\n",
            "        -2.6493e-03, -3.1952e-02, -9.7504e-03, -2.5223e-02, -3.7537e-02,\n",
            "        -6.7368e-03,  5.5389e-03, -7.0534e-03, -5.3673e-03, -1.4023e-02,\n",
            "         3.9917e-02, -2.6062e-02, -1.1909e-02, -3.3875e-02,  7.4158e-03,\n",
            "         1.1292e-02,  3.7422e-03, -1.1009e-02, -2.1439e-02, -5.1361e-02,\n",
            "        -1.5656e-02,  1.0052e-03, -1.2001e-02, -2.9545e-03,  1.6388e-02,\n",
            "         2.1648e-03, -1.1375e-02,  8.1558e-03, -3.5119e-04, -6.3782e-03,\n",
            "        -7.3357e-03,  3.1494e-02,  2.5043e-03,  6.6757e-03, -1.8295e-02,\n",
            "        -1.3031e-02,  2.5635e-03,  4.1016e-02,  3.1830e-02, -1.1345e-02,\n",
            "         2.1286e-03,  7.1167e-02, -4.8218e-03,  3.1647e-02,  5.8460e-04,\n",
            "        -3.3447e-02,  2.4506e-02,  2.4586e-03,  4.2610e-03, -9.8343e-03,\n",
            "        -5.9967e-03,  9.5215e-03,  2.2522e-02, -1.0193e-02, -3.4485e-02,\n",
            "        -3.4885e-03,  8.3618e-03, -7.1678e-03, -2.6657e-02, -2.5513e-02,\n",
            "        -1.4496e-02, -5.3711e-03,  3.4088e-02, -2.3834e-02, -2.5139e-03,\n",
            "         5.1483e-02, -1.6832e-03, -2.5070e-02,  3.2501e-02, -1.5450e-02,\n",
            "        -6.9580e-03, -2.8900e-02, -1.5884e-02,  1.7670e-02,  4.8599e-03,\n",
            "         3.9001e-02, -1.5381e-02, -3.8185e-03,  9.2697e-03,  2.4376e-03,\n",
            "        -2.7603e-02, -2.5177e-02,  2.8015e-02,  1.5091e-02, -6.6338e-03,\n",
            "         3.7079e-03, -4.1809e-02,  3.2654e-03, -4.0771e-01,  1.2993e-02,\n",
            "        -3.6713e-02, -7.5989e-03, -1.8112e-02,  3.6987e-02,  1.0612e-02,\n",
            "         4.3121e-02, -8.8577e-03,  7.0801e-03, -1.3977e-02, -1.2817e-02,\n",
            "        -1.8524e-02, -3.8815e-03,  1.5961e-02,  5.3501e-04,  1.8494e-02,\n",
            "         7.3051e-03,  1.5419e-02, -1.5900e-02,  5.0163e-03,  4.1771e-03,\n",
            "         1.8600e-02,  1.5869e-02, -1.3443e-02,  9.8038e-03,  3.4504e-03,\n",
            "         3.6743e-02,  1.0620e-02,  3.7872e-02, -1.2596e-02,  3.2440e-02,\n",
            "         7.5760e-03,  1.4755e-02,  2.6932e-02,  1.7075e-02, -1.5747e-02,\n",
            "         8.9264e-03, -1.4435e-02,  3.4515e-02,  4.2114e-02,  2.9770e-02,\n",
            "         2.7580e-03, -1.4999e-02, -1.7595e-03,  9.3842e-03, -1.0941e-02,\n",
            "        -3.8727e-02,  5.0659e-03, -1.0147e-02, -7.0374e-02, -8.0688e-02,\n",
            "        -5.8174e-03,  1.3027e-03,  4.0344e-02,  2.8870e-02,  3.9840e-04,\n",
            "        -3.6755e-03, -9.3842e-03, -6.4545e-03, -7.9193e-03,  1.1650e-02,\n",
            "         1.1406e-02, -4.5410e-02,  3.7201e-02, -1.9653e-02,  3.0346e-03,\n",
            "        -5.2261e-03,  1.3092e-02, -1.2596e-02, -4.2267e-02,  4.2297e-02,\n",
            "         1.6266e-02, -1.2695e-02, -9.1476e-03, -1.9745e-02, -6.5536e-03,\n",
            "         7.8964e-03, -3.0365e-02,  1.8661e-02,  1.7303e-02, -5.7793e-03,\n",
            "        -4.0985e-02,  3.0746e-03,  4.5776e-02, -9.3460e-03,  9.9411e-03,\n",
            "         1.9516e-02, -1.8417e-02,  2.8702e-02, -7.3433e-04,  3.9253e-03,\n",
            "         2.1458e-03,  2.5009e-02,  1.5205e-02, -5.8960e-02,  2.8976e-02,\n",
            "        -1.8814e-02, -2.3178e-02,  4.8279e-02, -2.4551e-02, -1.4320e-02,\n",
            "         2.3666e-02,  2.7435e-02,  2.0199e-03, -6.6376e-03,  1.9363e-02,\n",
            "         1.6647e-02,  4.0245e-03,  4.9988e-02,  8.7967e-03, -1.8707e-02,\n",
            "         6.3515e-03,  1.6830e-02,  1.8206e-03, -1.3538e-01, -9.2621e-03,\n",
            "         1.0895e-02, -1.9577e-02,  2.0493e-02,  9.0265e-04, -5.1689e-03,\n",
            "        -1.6037e-02,  7.1411e-02,  1.5884e-02, -3.7201e-02, -1.4938e-02,\n",
            "        -1.1272e-03, -5.2261e-03,  1.7029e-02, -3.0727e-03,  3.5954e-03,\n",
            "        -1.5640e-02, -1.5869e-02,  6.4049e-03,  4.5471e-02, -1.5320e-02,\n",
            "        -4.0100e-02, -3.5370e-02, -1.7365e-02,  4.2847e-02,  1.3847e-02,\n",
            "        -1.0395e-03, -1.3403e-01, -7.2823e-03,  2.0020e-02, -6.3972e-03,\n",
            "        -3.2501e-02,  9.4681e-03, -2.2659e-02,  3.2544e-04, -9.7534e-02,\n",
            "        -1.7120e-02,  2.0370e-02, -1.9516e-02,  8.1558e-03, -2.4155e-02,\n",
            "         2.3163e-02,  3.3630e-02, -2.1606e-02,  9.3765e-03, -3.3951e-03,\n",
            "        -1.2062e-02,  1.7334e-02,  1.8951e-02, -2.1469e-02, -2.1881e-02,\n",
            "         1.3184e-02, -2.0447e-02, -2.7679e-02, -3.8391e-02,  2.0844e-02,\n",
            "         3.8738e-03,  5.5206e-02,  3.4912e-02, -6.0303e-02,  1.3420e-02,\n",
            "        -1.9592e-02, -7.2718e-04, -3.9551e-02,  1.9867e-02, -3.0930e-02,\n",
            "        -1.2840e-02,  1.8997e-02,  1.7197e-02, -1.1650e-02, -6.8626e-03,\n",
            "        -2.2537e-02, -4.7180e-02, -2.2583e-02,  2.5909e-02,  1.7071e-03,\n",
            "        -2.0172e-02, -2.4734e-02,  4.7913e-03,  1.4992e-02, -2.4307e-02,\n",
            "        -2.0142e-02,  1.8778e-03, -1.6052e-02,  1.2222e-02,  3.5645e-02,\n",
            "        -3.8666e-02,  1.6427e-04, -4.8340e-02, -1.6388e-02,  8.2397e-03,\n",
            "        -2.6260e-02, -1.2798e-03,  3.3356e-02,  1.0307e-02, -6.6223e-02,\n",
            "         3.8671e-04, -1.1147e-02,  3.0441e-02,  2.0859e-02,  4.1351e-03,\n",
            "        -1.6663e-02,  1.3153e-02, -1.9623e-02,  5.2704e-02, -1.3351e-02,\n",
            "         2.6413e-02, -2.5131e-02,  4.4922e-02, -1.9445e-03, -3.7537e-03,\n",
            "         1.6922e-02, -7.8659e-03,  1.2383e-02, -2.8046e-02,  4.3994e-01,\n",
            "         1.2901e-02,  2.2400e-02,  2.2812e-02, -3.4561e-03, -1.2083e-03,\n",
            "         1.1513e-02, -1.0622e-04,  7.1068e-03,  2.4689e-02,  4.0550e-03,\n",
            "         4.4342e-02,  2.2873e-02, -1.7273e-02, -1.5556e-02,  1.3062e-01,\n",
            "         4.1260e-02,  1.6663e-02, -9.1362e-04, -1.9882e-02,  1.5198e-02,\n",
            "         8.1558e-03, -9.4910e-03, -1.3268e-02,  2.0660e-02,  4.9866e-02,\n",
            "         3.8166e-03,  1.4107e-02,  2.1362e-04,  2.3254e-02,  6.8741e-03,\n",
            "        -3.3703e-03,  8.5602e-03, -7.7705e-03,  6.1722e-03, -7.3853e-03,\n",
            "         1.8539e-02,  2.4841e-02, -3.0487e-02,  2.3994e-03, -4.1748e-02,\n",
            "         4.9408e-02,  2.5238e-02, -2.2476e-02,  1.1063e-02,  7.9880e-03,\n",
            "         2.3758e-02, -1.2886e-02,  3.8361e-02, -1.9028e-02, -5.5199e-03,\n",
            "         8.3084e-03, -2.6169e-02, -2.7023e-02,  1.9958e-02,  2.7267e-02,\n",
            "        -2.7084e-03,  1.7883e-02,  8.2474e-03, -6.3820e-03,  1.8148e-03,\n",
            "        -1.9012e-02, -1.0139e-02, -6.0349e-03, -2.0638e-03, -3.5477e-04,\n",
            "        -2.3865e-02, -7.3128e-03, -9.3689e-03,  1.9760e-02,  1.7672e-03,\n",
            "        -1.6052e-02, -1.9196e-02, -1.1932e-02, -6.3324e-03,  1.6356e-04,\n",
            "        -9.7370e-04, -2.7802e-02,  3.2410e-02, -1.1792e-01,  9.9716e-03,\n",
            "         6.5247e-02, -2.7313e-03, -1.8890e-02,  7.1297e-03,  1.9531e-02,\n",
            "        -3.7727e-03, -1.3847e-02,  8.6060e-03,  2.8667e-03,  3.0334e-02,\n",
            "        -3.8269e-02, -3.2406e-03, -2.4452e-03, -2.8397e-02,  3.2825e-03,\n",
            "        -1.1681e-02, -2.5955e-02,  1.6384e-03,  2.3212e-03,  3.2444e-03,\n",
            "         2.6505e-02,  3.0746e-02, -5.7755e-03, -1.3145e-02, -4.8462e-02,\n",
            "         2.3636e-02, -1.2188e-03, -1.7441e-02, -1.0048e-02,  3.2867e-02,\n",
            "         1.7481e-03,  1.4191e-02, -3.2635e-03,  1.2695e-02,  5.1537e-03,\n",
            "        -1.4038e-03, -1.2909e-02,  8.5258e-04, -5.7869e-03,  1.5549e-02,\n",
            "         2.6665e-03,  7.6408e-03,  8.2092e-03], dtype=torch.float16)\n",
            ": torch.Size([208, 768])\n",
            " cosine_similarity_with_mean.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-6-7238caa19f5d>:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  all_features = torch.load(feature_file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "#  CLIP \n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "#  GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#  CLIP \n",
        "model_name = \"ViT-L/14@336px\"  #  CLIP \n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # \n",
        "print(\"CLIP \")\n",
        "\n",
        "# \n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # \n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\" {image_folder}  {len(image_paths)} \")\n",
        "\n",
        "    # \n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # \n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # \n",
        "\n",
        "            # \n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # \n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # \n",
        "\n",
        "            #  CPU \n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" {image_path} : {e}\")\n",
        "\n",
        "    # \n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\" {output_file}\")\n",
        "    else:\n",
        "        print(f\" {image_folder} \")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "#  CSV \n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"\")\n",
        "        return\n",
        "\n",
        "    print(\"...\")\n",
        "\n",
        "    # \n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\": {similarity_matrix.shape}\")\n",
        "\n",
        "    #  DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # \n",
        "    column_means = df.mean(axis=0)  # \n",
        "    df.loc['Mean', :] = column_means  # \n",
        "\n",
        "    #  CSV \n",
        "    df.to_csv(csv_output)\n",
        "    print(f\" {csv_output}\")\n",
        "\n",
        "    #  0.8 \n",
        "    high_similarity_columns = column_means[column_means > 0.8].index.tolist()\n",
        "    with open(mean_output, 'w') as f:\n",
        "        for col in high_similarity_columns:\n",
        "            f.write(f\"{col}\\n\")\n",
        "    print(f\" 0.8  {mean_output}\")\n",
        "\n",
        "#  high_similarity_columns.txt \n",
        "def load_high_similarity_images(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\" {file_path} \")\n",
        "        return []\n",
        "    with open(file_path, 'r') as f:\n",
        "        image_filenames = [line.strip() for line in f.readlines()]\n",
        "    print(f\" {file_path}  {len(image_filenames)} \")\n",
        "    return image_filenames\n",
        "\n",
        "# \n",
        "def extract_selected_features(image_folder, selected_filenames):\n",
        "    image_features_list = []\n",
        "\n",
        "    print(f\" {len(selected_filenames)} \")\n",
        "\n",
        "    # \n",
        "    for image_filename in tqdm(selected_filenames, desc=\"Processing selected images\"):\n",
        "        image_path = os.path.join(image_folder, image_filename)\n",
        "\n",
        "        try:\n",
        "            # \n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # \n",
        "\n",
        "            # \n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # \n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # \n",
        "\n",
        "            #  CPU \n",
        "            image_features_list.append(image_features.cpu())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" {image_path} : {e}\")\n",
        "\n",
        "    # \n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, './selected_imgs_vit_commercial.pt')  # \n",
        "        print(f\"\")\n",
        "        return image_features\n",
        "    else:\n",
        "        print(f\"\")\n",
        "        return None\n",
        "\n",
        "# \n",
        "def compute_feature_mean(features):\n",
        "    if features is None:\n",
        "        print(\"\")\n",
        "        return None\n",
        "    feature_mean = features.mean(dim=0)  # \n",
        "    return feature_mean\n",
        "\n",
        "# \n",
        "def compute_cosine_similarity(feature_mean, all_features):\n",
        "    # \n",
        "    cosine_similarities = torch.matmul(all_features, feature_mean)  # \n",
        "    return cosine_similarities\n",
        "\n",
        "# \n",
        "def main():\n",
        "    # \n",
        "    image_folder = './Data/transportation'\n",
        "    feature_output = './imgs_vit_commercial.pt'\n",
        "    csv_output = './cosine_similarity_matrix_commercial.csv'\n",
        "    mean_output = './commercial.txt'  #  0.8 \n",
        "    high_similarity_file = mean_output  #  mean_output \n",
        "    feature_mean_output = './transportation.pt'\n",
        "\n",
        "    # \n",
        "    output_dirs = [\n",
        "        os.path.dirname(feature_output),\n",
        "        os.path.dirname(csv_output),\n",
        "        os.path.dirname(mean_output),\n",
        "        os.path.dirname(feature_mean_output)\n",
        "    ]\n",
        "\n",
        "    # \n",
        "    for dir_path in output_dirs:\n",
        "        if dir_path:  # \n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    # \n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    #  CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output)\n",
        "\n",
        "    # \n",
        "    selected_filenames = load_high_similarity_images(high_similarity_file)\n",
        "\n",
        "    if not selected_filenames:\n",
        "        print(\"\")\n",
        "        return\n",
        "\n",
        "    # \n",
        "    selected_features = extract_selected_features(image_folder, selected_filenames)\n",
        "\n",
        "    # \n",
        "    feature_mean = compute_feature_mean(selected_features)\n",
        "\n",
        "    if feature_mean is not None:\n",
        "        print(f\"{feature_mean}\")\n",
        "\n",
        "        # Save feature_mean to a .pt file\n",
        "        torch.save(feature_mean, feature_mean_output)\n",
        "        print(f\"Feature mean saved to {feature_mean_output}\")\n",
        "\n",
        "        #  imgs_vit_commercial.pt \n",
        "        if not os.path.exists(feature_output):\n",
        "            print(f\" {feature_output} \")\n",
        "            return\n",
        "        all_features = torch.load(feature_output)\n",
        "        print(f\": {all_features.shape}\")\n",
        "\n",
        "        # \n",
        "        all_features = all_features / all_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # \n",
        "        cosine_similarities = compute_cosine_similarity(feature_mean, all_features)\n",
        "\n",
        "        #  DataFrame  CSV\n",
        "        similarity_df = pd.DataFrame({\n",
        "            \"Image Filename\": filenames,\n",
        "            \"Cosine Similarity\": cosine_similarities.numpy()\n",
        "        })\n",
        "\n",
        "        #  CSV\n",
        "        similarity_df = similarity_df.sort_values(by=\"Cosine Similarity\", ascending=False)\n",
        "        similarity_df.to_csv('./cosine_similarity_with_mean.csv', index=False)\n",
        "\n",
        "        print(\" cosine_similarity_with_mean.csv\")\n",
        "    else:\n",
        "        print(\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZrvi5oKLBUe",
        "outputId": "1db95ec5-f82c-404d-f5ef-14e205e6959c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP \n",
            " ./Data/transportation  47 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/transportation: 100%|| 47/47 [00:01<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ./imgs_vit_commercial.pt\n",
            "...\n",
            ": (47, 47)\n",
            " ./cosine_similarity_matrix_commercial.csv\n",
            " 0.8  ./commercial.txt\n",
            " ./commercial.txt  1 \n",
            " 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing selected images: 100%|| 1/1 [00:00<00:00, 36.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tensor([ 1.9943e-02,  4.9652e-02,  5.6061e-02,  3.1067e-02, -8.9111e-03,\n",
            "         2.6215e-02,  2.4109e-02, -3.8727e-02,  2.9312e-02, -2.2003e-02,\n",
            "        -4.0054e-04, -1.0071e-02, -1.3031e-02,  4.1779e-02,  1.3725e-02,\n",
            "         4.1595e-02, -1.5419e-02,  5.6458e-04,  6.9580e-02,  4.0092e-03,\n",
            "         1.2901e-02,  6.3362e-03, -1.8021e-02,  2.9663e-02, -1.4961e-02,\n",
            "        -1.5472e-02,  5.4443e-02,  8.7357e-03, -1.7670e-02,  5.3177e-03,\n",
            "        -1.0201e-02,  2.8854e-02,  1.1971e-02, -4.0924e-02, -9.9335e-03,\n",
            "         3.5187e-02, -4.5563e-02, -2.2156e-02,  9.3002e-03, -3.8177e-02,\n",
            "        -1.3840e-02,  1.4877e-02,  1.5312e-02, -1.9989e-02,  4.3671e-02,\n",
            "         3.7018e-02,  2.4658e-02, -2.4017e-02, -1.4168e-02,  2.4071e-03,\n",
            "         3.1616e-02, -1.5373e-03,  1.0330e-02,  9.2363e-04,  6.1646e-03,\n",
            "        -5.7640e-03,  3.4119e-02, -1.3359e-02, -4.3701e-02, -3.5950e-02,\n",
            "         2.8610e-02, -8.6899e-03,  1.2825e-02,  1.0544e-02,  1.8143e-02,\n",
            "         1.3748e-02,  1.0315e-02,  1.8112e-02,  7.2670e-04, -1.9312e-03,\n",
            "         9.0714e-03, -1.2146e-02,  8.1635e-03, -2.4658e-02,  2.2583e-02,\n",
            "        -1.2291e-02, -2.1133e-02,  4.3365e-02,  7.3624e-03,  1.1055e-02,\n",
            "        -2.2980e-02,  4.3579e-02, -3.0136e-02,  1.0366e-03, -2.9945e-03,\n",
            "        -1.4587e-02, -2.8122e-02,  3.2135e-02, -4.4220e-02,  3.9368e-02,\n",
            "         8.9874e-03,  3.7251e-03, -5.9814e-03, -9.7504e-03,  1.8631e-02,\n",
            "        -1.8864e-03,  5.9700e-03,  1.0559e-02,  6.9084e-03,  3.3245e-03,\n",
            "        -5.6610e-02,  5.1651e-03,  2.3880e-02, -2.1149e-02, -1.0170e-02,\n",
            "        -2.0691e-02,  9.6207e-03, -1.7426e-02, -3.8185e-03,  1.3329e-02,\n",
            "        -5.0011e-03,  4.3304e-02,  2.5986e-02, -6.5575e-03, -3.2013e-02,\n",
            "         3.0731e-02, -4.0771e-02, -1.2436e-02, -7.5378e-02,  4.2191e-03,\n",
            "        -3.9490e-02,  4.7646e-03, -5.3177e-03, -4.9858e-03, -1.2230e-02,\n",
            "        -1.9775e-02, -3.3386e-02,  1.3779e-02, -3.5492e-02, -3.3997e-02,\n",
            "        -3.9215e-02,  1.7981e-01,  1.4210e-03, -4.9164e-02,  5.4512e-03,\n",
            "        -6.4514e-02, -5.5122e-03, -8.2016e-03,  3.8834e-03, -3.3051e-02,\n",
            "         3.3340e-03, -1.9730e-02, -2.5162e-02,  4.4322e-04, -4.6173e-02,\n",
            "        -1.5541e-02,  5.1971e-02,  8.8379e-02, -2.5726e-02,  8.8806e-03,\n",
            "        -4.1695e-03, -4.0222e-02, -2.4811e-02,  2.9556e-02,  1.5312e-02,\n",
            "        -1.2581e-02, -4.6814e-02,  3.0426e-02, -3.5400e-02, -1.7471e-02,\n",
            "        -3.9101e-03,  1.4015e-02, -1.3023e-02, -1.3947e-02, -2.3479e-03,\n",
            "        -2.8198e-02, -2.3117e-03,  3.2135e-02, -3.8391e-02,  1.0643e-02,\n",
            "         1.6861e-02,  6.1417e-03,  1.2260e-02,  2.9163e-03, -2.1935e-03,\n",
            "        -4.0771e-02,  1.4740e-02, -4.6967e-02, -7.2327e-03,  4.1260e-02,\n",
            "         5.7037e-02,  2.2817e-04, -3.1494e-02,  2.1759e-02, -2.7199e-03,\n",
            "        -6.4969e-05, -2.4757e-03, -2.2755e-03,  2.9373e-02,  6.0654e-03,\n",
            "         3.4668e-02,  8.3313e-03,  4.8981e-03, -1.8448e-02, -9.4070e-03,\n",
            "        -4.5349e-02, -1.9257e-02,  1.0910e-02, -9.6207e-03, -4.7943e-02,\n",
            "         2.0645e-02, -3.9185e-02, -8.3237e-03,  4.0321e-03, -3.5339e-02,\n",
            "         2.9022e-02, -1.8425e-03,  1.6193e-03,  4.5380e-02, -1.5572e-02,\n",
            "         1.1787e-02,  1.5541e-02,  1.9821e-02, -2.3056e-02,  1.8753e-02,\n",
            "        -8.6451e-04, -2.1042e-02,  1.2779e-02, -5.5313e-03, -5.5122e-03,\n",
            "         3.8147e-04, -2.7496e-02, -2.0828e-02,  4.1107e-02, -2.1469e-02,\n",
            "        -1.6083e-02,  3.4821e-02, -2.4471e-03,  5.9052e-03, -8.1635e-03,\n",
            "        -1.3008e-02, -1.6891e-02,  1.4877e-02,  3.6163e-02, -2.8793e-02,\n",
            "         6.6185e-03, -5.5923e-03,  1.1387e-03,  1.8387e-02,  2.5848e-02,\n",
            "        -9.6970e-03, -8.4000e-03, -2.4521e-02,  1.7365e-02, -1.9058e-02,\n",
            "         4.1321e-02,  1.4931e-02,  2.1988e-02,  3.1250e-02, -3.7628e-02,\n",
            "         3.4046e-03, -1.4496e-02,  5.6381e-03,  6.4011e-03,  1.9653e-02,\n",
            "        -3.8177e-02, -1.6769e-02, -2.6489e-02, -1.5503e-02,  3.3398e-03,\n",
            "        -1.7273e-02, -3.8147e-02,  2.0447e-02, -2.1332e-02, -2.1790e-02,\n",
            "         5.0018e-02,  3.5934e-03,  3.6240e-03,  1.5884e-02, -4.8923e-04,\n",
            "        -3.7048e-02,  5.1849e-02,  1.0498e-02,  1.4084e-02,  6.4659e-03,\n",
            "         1.1208e-02,  3.4771e-03,  4.1595e-02, -8.9264e-03,  5.9166e-03,\n",
            "        -2.5482e-02,  1.4412e-02,  5.5542e-03,  3.6987e-02,  4.2847e-02,\n",
            "        -3.3783e-02,  1.7868e-02, -3.3264e-02, -3.8544e-02, -4.7150e-03,\n",
            "        -4.7798e-03, -6.4163e-03, -2.1851e-02, -2.2797e-02, -1.9928e-02,\n",
            "        -6.9336e-02, -3.7804e-03, -5.1819e-02, -1.0132e-02, -2.1194e-02,\n",
            "         2.8854e-02, -8.2703e-03,  1.8738e-02, -2.4090e-03,  4.6730e-03,\n",
            "         9.5978e-03, -1.1070e-02,  1.1854e-03, -1.6052e-02,  4.9164e-02,\n",
            "        -2.7985e-02, -7.0305e-03,  4.6997e-03, -4.2496e-03,  4.4250e-03,\n",
            "         2.6474e-02, -4.2542e-02,  3.5126e-02, -1.3306e-02,  6.1676e-02,\n",
            "        -1.1528e-02,  3.6072e-02,  1.8860e-02,  2.5024e-02, -1.9012e-02,\n",
            "        -2.3346e-02, -5.0842e-02, -6.8245e-03, -1.1169e-02, -1.7624e-02,\n",
            "        -8.5068e-03, -5.3673e-03,  1.1398e-02, -3.4618e-03, -1.4465e-02,\n",
            "         5.4321e-02, -3.4424e-02, -1.4633e-02, -5.9845e-02,  4.1771e-03,\n",
            "         1.9760e-02, -3.8314e-04,  4.5204e-03, -3.0731e-02, -5.8319e-02,\n",
            "        -1.1742e-02, -2.1210e-03, -3.8422e-02, -4.1771e-03,  8.1406e-03,\n",
            "        -1.4565e-02,  4.1466e-03,  1.2108e-02,  1.9464e-03, -1.6052e-02,\n",
            "        -1.1345e-02,  2.4963e-02,  7.9956e-03, -1.4206e-02, -1.9806e-02,\n",
            "        -6.2523e-03,  1.0284e-02,  3.4790e-02,  3.7689e-02, -3.5553e-03,\n",
            "         2.3895e-02,  6.8726e-02,  4.5586e-03,  3.3600e-02,  5.3062e-03,\n",
            "        -4.8218e-02,  2.9968e-02,  1.3840e-02,  1.7761e-02,  2.1149e-02,\n",
            "        -2.0340e-02,  1.1406e-02,  2.9449e-02, -2.9892e-02, -6.0822e-02,\n",
            "        -7.1259e-03,  1.1597e-02,  1.6427e-04, -2.1652e-02, -4.4586e-02,\n",
            "        -2.2766e-02, -2.8336e-02,  4.1809e-02, -1.5312e-02,  7.2136e-03,\n",
            "         3.4485e-02,  6.4516e-04, -1.4328e-02,  4.1199e-02, -1.4359e-02,\n",
            "         7.9041e-03, -1.2611e-02, -2.0142e-02,  2.4750e-02,  1.7441e-02,\n",
            "         2.5101e-02, -1.5854e-02, -1.4931e-02,  5.0659e-03, -4.2510e-04,\n",
            "        -4.2542e-02, -2.6749e-02,  3.6652e-02,  1.2955e-02, -1.6434e-02,\n",
            "         4.2076e-03, -3.4119e-02, -8.9493e-03, -4.2456e-01, -4.7913e-03,\n",
            "        -3.1036e-02, -1.2985e-02, -8.0338e-03,  2.6794e-02,  1.6693e-02,\n",
            "         4.5441e-02, -2.4918e-02,  6.2904e-03, -1.6785e-02, -6.2332e-03,\n",
            "        -2.5009e-02, -8.3542e-03,  2.9205e-02,  6.3362e-03,  1.0330e-02,\n",
            "         1.5869e-02,  2.0386e-02, -2.3560e-02,  1.9989e-02,  6.8283e-03,\n",
            "         3.4698e-02,  2.0096e-02, -1.8478e-02,  1.6571e-02, -3.0727e-03,\n",
            "         3.7201e-02,  4.7836e-03,  4.7363e-02, -2.7878e-02,  2.2552e-02,\n",
            "         1.1528e-02, -6.1188e-03,  2.8122e-02,  3.3142e-02, -2.1973e-02,\n",
            "         2.5654e-03, -2.4918e-02,  6.1890e-02,  3.7415e-02,  2.6016e-02,\n",
            "        -8.3237e-03, -1.4824e-02,  4.3983e-03,  1.5259e-02, -2.2339e-02,\n",
            "        -4.2419e-02,  2.5696e-02, -1.9165e-02, -6.2683e-02, -5.8960e-02,\n",
            "         4.4594e-03,  1.5541e-02,  5.8807e-02,  8.0643e-03, -7.8487e-04,\n",
            "        -9.7733e-03,  3.0861e-03,  5.3120e-04, -7.8964e-03,  1.5434e-02,\n",
            "         2.9697e-03, -2.3819e-02,  3.4515e-02, -2.6932e-02, -1.1806e-03,\n",
            "        -7.4997e-03,  1.8707e-02,  1.4057e-03, -6.4575e-02,  5.5084e-02,\n",
            "         9.5901e-03, -1.1986e-02,  4.5943e-04, -2.6138e-02, -8.9550e-04,\n",
            "         2.6749e-02, -2.7695e-02,  1.7914e-02,  3.9795e-02, -2.5883e-03,\n",
            "        -3.3966e-02, -3.5152e-03,  4.4769e-02, -3.4142e-03,  3.8648e-04,\n",
            "         2.7100e-02, -1.8219e-02,  9.5215e-03, -6.6900e-04,  4.0293e-04,\n",
            "        -1.4084e-02,  1.6953e-02,  9.8343e-03, -4.1290e-02,  2.2034e-02,\n",
            "        -2.2415e-02, -2.5543e-02,  3.4668e-02, -4.6356e-02, -9.3536e-03,\n",
            "        -8.1635e-03,  3.9093e-02,  6.6299e-03, -1.5541e-02,  2.7496e-02,\n",
            "         8.0566e-03, -1.6953e-02,  4.8920e-02,  5.1193e-03, -3.2379e-02,\n",
            "        -1.7654e-02,  2.0721e-02, -1.2527e-02, -1.5063e-01, -1.8823e-04,\n",
            "         6.2675e-03, -2.4429e-02,  1.7090e-02,  1.7349e-02, -2.1027e-02,\n",
            "        -9.9869e-03,  5.9662e-02,  1.7349e-02, -4.2419e-02,  1.1726e-02,\n",
            "        -1.7715e-02, -9.5901e-03,  2.6932e-02, -1.0176e-03, -1.3618e-02,\n",
            "        -1.0643e-02, -2.0798e-02,  2.3941e-02,  2.1667e-02, -2.5009e-02,\n",
            "        -2.2751e-02, -4.4830e-02, -2.7298e-02,  5.7648e-02,  2.6718e-02,\n",
            "        -6.8521e-04, -1.4819e-01, -2.0767e-02,  1.5396e-02, -1.4847e-02,\n",
            "        -4.1779e-02, -1.1108e-02, -2.6398e-02,  3.2604e-05, -9.3750e-02,\n",
            "        -2.8824e-02,  4.1107e-02, -2.2781e-02,  1.0994e-02, -4.6600e-02,\n",
            "         3.3722e-02,  4.0222e-02, -1.1726e-02,  1.7120e-02, -5.9509e-03,\n",
            "        -2.8229e-02,  2.5120e-03,  1.4915e-02, -2.7817e-02, -7.6714e-03,\n",
            "         1.0811e-02, -1.7288e-02, -3.7628e-02, -3.6255e-02,  2.2842e-02,\n",
            "        -7.4577e-03,  5.5695e-02,  3.5431e-02, -5.5511e-02, -4.2458e-03,\n",
            "        -2.1973e-02, -9.4528e-03, -5.7770e-02,  1.1520e-02, -2.1439e-02,\n",
            "        -1.7776e-02,  1.7853e-02, -1.0529e-03, -2.5223e-02, -1.9272e-02,\n",
            "        -3.4546e-02, -4.6539e-02, -1.7120e-02,  2.9266e-02,  7.7667e-03,\n",
            "        -1.5366e-02, -3.3142e-02,  2.4979e-02,  2.4368e-02, -3.9062e-02,\n",
            "        -1.1795e-02,  1.2642e-02,  1.1009e-02,  1.2802e-02,  2.9404e-02,\n",
            "        -4.6387e-02, -6.7749e-03, -5.9570e-02, -2.3529e-02,  1.8280e-02,\n",
            "        -2.6169e-02, -5.6076e-03,  2.9617e-02,  1.5053e-02, -7.1899e-02,\n",
            "         4.5738e-03, -4.6349e-03,  2.7985e-02,  1.7960e-02,  5.4283e-03,\n",
            "        -2.4673e-02,  6.6719e-03, -4.9400e-03,  6.2439e-02, -2.1088e-02,\n",
            "         1.5839e-02, -5.0201e-03,  4.3671e-02, -1.0658e-02, -2.0813e-02,\n",
            "         2.0569e-02, -1.3199e-03,  2.5330e-02, -1.8631e-02,  4.5776e-01,\n",
            "         7.6065e-03,  1.3618e-02,  1.1185e-02,  1.1467e-02, -1.4847e-02,\n",
            "         2.4185e-02,  1.7578e-02,  1.1078e-02,  1.8799e-02,  3.9139e-03,\n",
            "         4.0680e-02,  2.2629e-02, -2.1698e-02, -1.3794e-02,  1.2805e-01,\n",
            "         4.2542e-02,  2.4963e-02,  9.8801e-03, -2.0142e-02,  2.1988e-02,\n",
            "         3.5553e-03,  1.4099e-02, -3.1982e-02,  5.6305e-03,  6.8481e-02,\n",
            "         3.1967e-03, -7.4654e-03,  5.2309e-04,  3.2715e-02, -2.2736e-02,\n",
            "        -1.0803e-02,  1.3992e-02, -2.9011e-03,  1.8677e-02,  4.8614e-04,\n",
            "         2.1500e-02,  2.1271e-02, -3.5645e-02,  2.1194e-02, -3.3844e-02,\n",
            "         5.7098e-02,  3.5400e-02, -1.0345e-02,  2.5040e-02,  1.2245e-03,\n",
            "         1.6769e-02, -1.8799e-02,  5.5023e-02, -1.6251e-02, -2.4994e-02,\n",
            "         1.4633e-02, -3.1708e-02, -2.0111e-02,  2.3407e-02,  1.8448e-02,\n",
            "         3.4392e-05,  1.2604e-02,  2.0294e-02,  2.0294e-02,  3.6373e-03,\n",
            "        -1.2779e-02, -7.1259e-03, -3.4271e-02, -1.1169e-02,  2.4384e-02,\n",
            "        -2.3148e-02, -1.1909e-02, -1.4900e-02,  1.2192e-02,  4.5319e-03,\n",
            "        -3.9825e-02, -1.2650e-02, -1.8723e-02, -2.1935e-03, -2.1805e-02,\n",
            "        -4.9934e-03, -4.5197e-02,  2.8473e-02, -1.3391e-01,  3.9864e-03,\n",
            "         6.7810e-02, -6.9275e-03, -2.1042e-02,  8.9111e-03,  1.0567e-02,\n",
            "         8.5449e-03, -2.6093e-02, -1.5747e-02, -4.9973e-03,  4.5319e-02,\n",
            "        -3.5919e-02, -1.7090e-02, -6.3095e-03, -3.9024e-03,  8.0948e-03,\n",
            "         5.0664e-05, -1.3290e-02,  1.4618e-02, -2.0615e-02,  1.1528e-02,\n",
            "         2.0325e-02,  2.6260e-02, -1.4275e-02, -1.7700e-02, -4.9225e-02,\n",
            "         1.5450e-03, -4.9515e-03, -2.3842e-03, -2.8717e-02,  4.6265e-02,\n",
            "         7.1602e-03,  5.9471e-03, -5.5733e-03, -7.0915e-03,  8.0032e-03,\n",
            "        -1.8711e-03, -2.2858e-02, -8.7967e-03,  1.7227e-02,  1.4778e-02,\n",
            "        -8.7967e-03,  2.4918e-02,  5.3673e-03], dtype=torch.float16)\n",
            "Feature mean saved to ./transportation.pt\n",
            ": torch.Size([47, 768])\n",
            " cosine_similarity_with_mean.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-19-20053843678c>:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  all_features = torch.load(feature_output)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure you have installed the CLIP library. If not, install it using:\n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the pre-trained CLIP model and preprocessing function\n",
        "model_name = \"ViT-L/14@336px\"  # Ensure this model name is available in the CLIP library\n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "print(\"CLIP model loaded successfully.\")\n",
        "\n",
        "# Define the feature extraction function\n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # Get and sort image paths. Adjust sorting if filenames are not purely numeric.\n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: os.path.splitext(os.path.basename(x))[0]  # Sort by filename without extension\n",
        "    )\n",
        "\n",
        "    print(f\"Found {len(image_paths)} images in folder: {image_folder}\")\n",
        "\n",
        "    # Process each image\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {os.path.basename(image_folder)}\"):\n",
        "        try:\n",
        "            # Load and preprocess image\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "            # Disable gradient calculation for efficiency\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # Encode image\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # Normalize feature vector\n",
        "\n",
        "            # Move features to CPU and append to list\n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    # Concatenate all features into a single tensor\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # Shape: [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"Features saved to {output_file}\")\n",
        "    else:\n",
        "        print(f\"No valid images found in {image_folder}\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "# Define the function to compute and save cosine similarity matrix (optional)\n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"Features or filenames are empty. Cannot compute cosine similarity.\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculating cosine similarity matrix...\")\n",
        "\n",
        "    # Cosine similarity via dot product (features are already normalized)\n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # Shape: [num_images, num_images]\n",
        "\n",
        "    print(f\"Similarity matrix size: {similarity_matrix.shape}\")\n",
        "\n",
        "    # Convert similarity matrix to DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # Calculate mean of each column and add as the last row\n",
        "    column_means = df.mean(axis=0)  # Mean of each column\n",
        "    df.loc['Mean', :] = column_means  # Add mean as the last row\n",
        "\n",
        "    # Save the similarity matrix to CSV\n",
        "    df.to_csv(csv_output)\n",
        "    print(f\"Cosine similarity matrix saved to {csv_output}\")\n",
        "\n",
        "    # Identify and save column names with mean similarity > 0.8\n",
        "    high_similarity_columns = column_means[column_means > 0.8].index.tolist()\n",
        "    with open(mean_output, 'w') as f:\n",
        "        for col in high_similarity_columns:\n",
        "            f.write(f\"{col}\\n\")\n",
        "    print(f\"Column names with mean similarity > 0.8 saved to {mean_output}\")\n",
        "\n",
        "# Define the function to compute the mean feature\n",
        "def compute_feature_mean(features):\n",
        "    if features is None:\n",
        "        print(\"No valid features available to compute mean.\")\n",
        "        return None\n",
        "    feature_mean = features.mean(dim=0)  # Compute mean across all image features\n",
        "    return feature_mean\n",
        "\n",
        "# Main processing function\n",
        "def main():\n",
        "    # Define the root data directory\n",
        "    data_root = './Data'\n",
        "\n",
        "    # Define the list of folders to process\n",
        "    folders_to_process = [\n",
        "        'civic, governmental and cultural',\n",
        "        'education',\n",
        "        'industrial',\n",
        "        'sports and recreation',\n",
        "        'commercial',\n",
        "        'health care',\n",
        "        'outdoors and natural',\n",
        "        'transportation',\n",
        "        'hotel',\n",
        "        'residential'\n",
        "    ]\n",
        "\n",
        "    # Define directories to save features and mean features\n",
        "    features_dir = './features'\n",
        "    mean_features_dir = './mean_features'\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(features_dir, exist_ok=True)\n",
        "    os.makedirs(mean_features_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate over each folder and process\n",
        "    for folder in folders_to_process:\n",
        "        folder_path = os.path.join(data_root, folder)\n",
        "\n",
        "        # Check if the folder exists\n",
        "        if not os.path.isdir(folder_path):\n",
        "            print(f\"Folder {folder_path} does not exist. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing folder: {folder}\")\n",
        "\n",
        "        # Define output file paths\n",
        "        feature_output = os.path.join(features_dir, f\"{folder.replace(' ', '_')}_features.pt\")\n",
        "        mean_output = os.path.join(mean_features_dir, f\"{folder.replace(' ', '_')}_mean.pt\")\n",
        "\n",
        "        # Extract features\n",
        "        features, filenames = extract_features(folder_path, feature_output)\n",
        "\n",
        "        if features is None:\n",
        "            print(f\"Skipping mean computation for {folder} due to no features.\")\n",
        "            continue\n",
        "\n",
        "        # Compute mean feature\n",
        "        feature_mean = compute_feature_mean(features)\n",
        "\n",
        "        if feature_mean is not None:\n",
        "            # Save the mean feature\n",
        "            torch.save(feature_mean, mean_output)\n",
        "            print(f\"Mean feature saved to {mean_output}\")\n",
        "        else:\n",
        "            print(f\"Failed to compute mean feature for {folder}.\")\n",
        "\n",
        "        # Optional: Compute and save cosine similarity matrix\n",
        "        # Uncomment the following lines if you want to compute similarity matrices\n",
        "        \"\"\"\n",
        "        csv_output = os.path.join(features_dir, f\"{folder.replace(' ', '_')}_cosine_similarity.csv\")\n",
        "        high_similarity_output = os.path.join(features_dir, f\"{folder.replace(' ', '_')}_high_similarity.txt\")\n",
        "        compute_and_save_cosine_similarity(features, filenames, csv_output, high_similarity_output)\n",
        "        \"\"\"\n",
        "\n",
        "    print(\"\\nAll specified folders have been processed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-35cPWfpOf-P",
        "outputId": "6c91eee4-c0eb-4216-8b67-ef5cf02a9725"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP model loaded successfully.\n",
            "\n",
            "Processing folder: civic, governmental and cultural\n",
            "Found 36 images in folder: ./Data/civic, governmental and cultural\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing civic, governmental and cultural: 100%|| 36/36 [00:01<00:00, 33.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/civic,_governmental_and_cultural_features.pt\n",
            "Mean feature saved to ./mean_features/civic,_governmental_and_cultural_mean.pt\n",
            "\n",
            "Processing folder: education\n",
            "Found 99 images in folder: ./Data/education\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing education: 100%|| 99/99 [00:02<00:00, 36.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/education_features.pt\n",
            "Mean feature saved to ./mean_features/education_mean.pt\n",
            "\n",
            "Processing folder: industrial\n",
            "Found 145 images in folder: ./Data/industrial\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing industrial: 100%|| 145/145 [00:03<00:00, 36.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/industrial_features.pt\n",
            "Mean feature saved to ./mean_features/industrial_mean.pt\n",
            "\n",
            "Processing folder: sports and recreation\n",
            "Found 28 images in folder: ./Data/sports and recreation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing sports and recreation: 100%|| 28/28 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/sports_and_recreation_features.pt\n",
            "Mean feature saved to ./mean_features/sports_and_recreation_mean.pt\n",
            "\n",
            "Processing folder: commercial\n",
            "Found 208 images in folder: ./Data/commercial\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing commercial: 100%|| 208/208 [00:05<00:00, 36.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/commercial_features.pt\n",
            "Mean feature saved to ./mean_features/commercial_mean.pt\n",
            "\n",
            "Processing folder: health care\n",
            "Found 27 images in folder: ./Data/health care\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing health care: 100%|| 27/27 [00:00<00:00, 35.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/health_care_features.pt\n",
            "Mean feature saved to ./mean_features/health_care_mean.pt\n",
            "\n",
            "Processing folder: outdoors and natural\n",
            "Found 38 images in folder: ./Data/outdoors and natural\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing outdoors and natural: 100%|| 38/38 [00:01<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/outdoors_and_natural_features.pt\n",
            "Mean feature saved to ./mean_features/outdoors_and_natural_mean.pt\n",
            "\n",
            "Processing folder: transportation\n",
            "Found 47 images in folder: ./Data/transportation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing transportation: 100%|| 47/47 [00:01<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/transportation_features.pt\n",
            "Mean feature saved to ./mean_features/transportation_mean.pt\n",
            "\n",
            "Processing folder: hotel\n",
            "Found 30 images in folder: ./Data/hotel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing hotel: 100%|| 30/30 [00:00<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/hotel_features.pt\n",
            "Mean feature saved to ./mean_features/hotel_mean.pt\n",
            "\n",
            "Processing folder: residential\n",
            "Found 335 images in folder: ./Data/residential\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing residential: 100%|| 335/335 [00:09<00:00, 35.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/residential_features.pt\n",
            "Mean feature saved to ./mean_features/residential_mean.pt\n",
            "\n",
            "All specified folders have been processed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "#  GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#  CLIP \n",
        "model_name = \"ViT-L/14@336px\"  #  CLIP \n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # \n",
        "print(\"CLIP \")\n",
        "\n",
        "# \n",
        "def extract_features(image_folders, output_file, num_images=10):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # \n",
        "    for image_folder in image_folders:\n",
        "        # \n",
        "        image_paths = sorted(\n",
        "            [\n",
        "                os.path.join(image_folder, img)\n",
        "                for img in os.listdir(image_folder)\n",
        "                if img.lower().endswith(('.jpg', '.png'))\n",
        "            ],\n",
        "            key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "        )\n",
        "\n",
        "        #  num_images, \n",
        "        if len(image_paths) > num_images:\n",
        "            image_paths = random.sample(image_paths, num_images)  #  num_images \n",
        "\n",
        "        print(f\" {image_folder}  {len(image_paths)} \")\n",
        "\n",
        "        # \n",
        "        for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "            try:\n",
        "                # \n",
        "                image = Image.open(image_path).convert(\"RGB\")\n",
        "                image_input = preprocess(image).unsqueeze(0).to(device)  # \n",
        "\n",
        "                # \n",
        "                with torch.no_grad():\n",
        "                    image_features = model.encode_image(image_input)  # \n",
        "                    image_features /= image_features.norm(dim=-1, keepdim=True)  # \n",
        "\n",
        "                #  CPU \n",
        "                image_features_list.append(image_features.cpu())\n",
        "                image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\" {image_path} : {e}\")\n",
        "\n",
        "    # \n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\" {output_file}\")\n",
        "    else:\n",
        "        print(f\"\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "#  CSV \n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"\")\n",
        "        return\n",
        "\n",
        "    print(\"...\")\n",
        "\n",
        "    # \n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\": {similarity_matrix.shape}\")\n",
        "\n",
        "    #  DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    #  CSV \n",
        "    df.to_csv(csv_output)\n",
        "    print(f\" {csv_output}\")\n",
        "\n",
        "# \n",
        "if __name__ == \"__main__\":\n",
        "    # \n",
        "    image_folders = ['./Data/commercial', './Data/residential', './Data/industrial']  # \n",
        "    feature_output = './features/combined_features.pt'\n",
        "    csv_output = './cosine_similarity_combined.csv'\n",
        "\n",
        "    # \n",
        "    os.makedirs(os.path.dirname(feature_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(csv_output), exist_ok=True)\n",
        "\n",
        "    # \n",
        "    features, filenames = extract_features(image_folders, feature_output, num_images=10)\n",
        "\n",
        "    #  CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0m8I9s0LLB",
        "outputId": "f8729266-3b5f-4d10-d1b6-8eaa011f8154"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 891M/891M [01:41<00:00, 9.19MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP \n",
            " ./Data/commercial  10 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/commercial: 100%|| 10/10 [00:01<00:00,  7.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ./Data/residential  10 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/residential: 100%|| 10/10 [00:00<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ./Data/industrial  10 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/industrial: 100%|| 10/10 [00:00<00:00, 35.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ./features/combined_features.pt\n",
            "...\n",
            ": (30, 30)\n",
            " ./cosine_similarity_combined.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}