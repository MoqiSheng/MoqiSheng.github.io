{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOVwJwbXmOwC0AZOhp7WQmd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/function1229.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF-4_K43mtF6",
        "outputId": "6b76efc1-813e-4dea-edc9-4f68fb501e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/CommonFeatures/correct_function.zip -d /content/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgNV_JHQm31v",
        "outputId": "deb7edf1-28ba-46d4-b02f-cca1ae465f44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/CommonFeatures/correct_function.zip\n",
            "   creating: /content/Data/civic, governmental and cultural/\n",
            "  inflating: /content/Data/civic, governmental and cultural/0.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1035.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1056.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1219.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1246.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1266.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1272.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1286.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1287.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1288.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1289.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1290.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1291.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1292.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1303.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1316.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1416.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1431.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1432.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1480.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/15.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1501.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1503.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1504.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1507.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1509.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1510.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1512.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/1514.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/198.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/223.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/228.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/556.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/600.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/858.png  \n",
            "  inflating: /content/Data/civic, governmental and cultural/943.png  \n",
            "   creating: /content/Data/commercial/\n",
            "  inflating: /content/Data/commercial/100.png  \n",
            "  inflating: /content/Data/commercial/1002.png  \n",
            "  inflating: /content/Data/commercial/1006.png  \n",
            "  inflating: /content/Data/commercial/1007.png  \n",
            "  inflating: /content/Data/commercial/1010.png  \n",
            "  inflating: /content/Data/commercial/1014.png  \n",
            "  inflating: /content/Data/commercial/1016.png  \n",
            "  inflating: /content/Data/commercial/1019.png  \n",
            "  inflating: /content/Data/commercial/1025.png  \n",
            "  inflating: /content/Data/commercial/1028.png  \n",
            "  inflating: /content/Data/commercial/1032.png  \n",
            "  inflating: /content/Data/commercial/1034.png  \n",
            "  inflating: /content/Data/commercial/1043.png  \n",
            "  inflating: /content/Data/commercial/1049.png  \n",
            "  inflating: /content/Data/commercial/106.png  \n",
            "  inflating: /content/Data/commercial/1062.png  \n",
            "  inflating: /content/Data/commercial/108.png  \n",
            "  inflating: /content/Data/commercial/1080.png  \n",
            "  inflating: /content/Data/commercial/1083.png  \n",
            "  inflating: /content/Data/commercial/1086.png  \n",
            "  inflating: /content/Data/commercial/1094.png  \n",
            "  inflating: /content/Data/commercial/1116.png  \n",
            "  inflating: /content/Data/commercial/1122.png  \n",
            "  inflating: /content/Data/commercial/1125.png  \n",
            "  inflating: /content/Data/commercial/1134.png  \n",
            "  inflating: /content/Data/commercial/1135.png  \n",
            "  inflating: /content/Data/commercial/1140.png  \n",
            "  inflating: /content/Data/commercial/1146.png  \n",
            "  inflating: /content/Data/commercial/1153.png  \n",
            "  inflating: /content/Data/commercial/1158.png  \n",
            "  inflating: /content/Data/commercial/1161.png  \n",
            "  inflating: /content/Data/commercial/1169.png  \n",
            "  inflating: /content/Data/commercial/1175.png  \n",
            "  inflating: /content/Data/commercial/1176.png  \n",
            "  inflating: /content/Data/commercial/1178.png  \n",
            "  inflating: /content/Data/commercial/1179.png  \n",
            "  inflating: /content/Data/commercial/12.png  \n",
            "  inflating: /content/Data/commercial/1200.png  \n",
            "  inflating: /content/Data/commercial/1207.png  \n",
            "  inflating: /content/Data/commercial/1215.png  \n",
            "  inflating: /content/Data/commercial/1226.png  \n",
            "  inflating: /content/Data/commercial/1237.png  \n",
            "  inflating: /content/Data/commercial/1238.png  \n",
            "  inflating: /content/Data/commercial/126.png  \n",
            "  inflating: /content/Data/commercial/1264.png  \n",
            "  inflating: /content/Data/commercial/1267.png  \n",
            "  inflating: /content/Data/commercial/1269.png  \n",
            "  inflating: /content/Data/commercial/1270.png  \n",
            "  inflating: /content/Data/commercial/1274.png  \n",
            "  inflating: /content/Data/commercial/1285.png  \n",
            "  inflating: /content/Data/commercial/13.png  \n",
            "  inflating: /content/Data/commercial/141.png  \n",
            "  inflating: /content/Data/commercial/1474.png  \n",
            "  inflating: /content/Data/commercial/1488.png  \n",
            "  inflating: /content/Data/commercial/1499.png  \n",
            "  inflating: /content/Data/commercial/151.png  \n",
            "  inflating: /content/Data/commercial/1515.png  \n",
            "  inflating: /content/Data/commercial/1516.png  \n",
            "  inflating: /content/Data/commercial/152.png  \n",
            "  inflating: /content/Data/commercial/155.png  \n",
            "  inflating: /content/Data/commercial/157.png  \n",
            "  inflating: /content/Data/commercial/17.png  \n",
            "  inflating: /content/Data/commercial/195.png  \n",
            "  inflating: /content/Data/commercial/2.png  \n",
            "  inflating: /content/Data/commercial/238.png  \n",
            "  inflating: /content/Data/commercial/249.png  \n",
            "  inflating: /content/Data/commercial/259.png  \n",
            "  inflating: /content/Data/commercial/261.png  \n",
            "  inflating: /content/Data/commercial/280.png  \n",
            "  inflating: /content/Data/commercial/285.png  \n",
            "  inflating: /content/Data/commercial/288.png  \n",
            "  inflating: /content/Data/commercial/293.png  \n",
            "  inflating: /content/Data/commercial/294.png  \n",
            "  inflating: /content/Data/commercial/3.png  \n",
            "  inflating: /content/Data/commercial/301.png  \n",
            "  inflating: /content/Data/commercial/306.png  \n",
            "  inflating: /content/Data/commercial/33.png  \n",
            "  inflating: /content/Data/commercial/332.png  \n",
            "  inflating: /content/Data/commercial/350.png  \n",
            "  inflating: /content/Data/commercial/352.png  \n",
            "  inflating: /content/Data/commercial/355.png  \n",
            "  inflating: /content/Data/commercial/359.png  \n",
            "  inflating: /content/Data/commercial/371.png  \n",
            "  inflating: /content/Data/commercial/376.png  \n",
            "  inflating: /content/Data/commercial/377.png  \n",
            "  inflating: /content/Data/commercial/378.png  \n",
            "  inflating: /content/Data/commercial/38.png  \n",
            "  inflating: /content/Data/commercial/388.png  \n",
            "  inflating: /content/Data/commercial/392.png  \n",
            "  inflating: /content/Data/commercial/397.png  \n",
            "  inflating: /content/Data/commercial/402.png  \n",
            "  inflating: /content/Data/commercial/403.png  \n",
            "  inflating: /content/Data/commercial/406.png  \n",
            "  inflating: /content/Data/commercial/41.png  \n",
            "  inflating: /content/Data/commercial/410.png  \n",
            "  inflating: /content/Data/commercial/411.png  \n",
            "  inflating: /content/Data/commercial/414.png  \n",
            "  inflating: /content/Data/commercial/430.png  \n",
            "  inflating: /content/Data/commercial/434.png  \n",
            "  inflating: /content/Data/commercial/440.png  \n",
            "  inflating: /content/Data/commercial/441.png  \n",
            "  inflating: /content/Data/commercial/442.png  \n",
            "  inflating: /content/Data/commercial/451.png  \n",
            "  inflating: /content/Data/commercial/452.png  \n",
            "  inflating: /content/Data/commercial/455.png  \n",
            "  inflating: /content/Data/commercial/470.png  \n",
            "  inflating: /content/Data/commercial/471.png  \n",
            "  inflating: /content/Data/commercial/473.png  \n",
            "  inflating: /content/Data/commercial/478.png  \n",
            "  inflating: /content/Data/commercial/490.png  \n",
            "  inflating: /content/Data/commercial/496.png  \n",
            "  inflating: /content/Data/commercial/498.png  \n",
            "  inflating: /content/Data/commercial/499.png  \n",
            "  inflating: /content/Data/commercial/510.png  \n",
            "  inflating: /content/Data/commercial/511.png  \n",
            "  inflating: /content/Data/commercial/516.png  \n",
            "  inflating: /content/Data/commercial/524.png  \n",
            "  inflating: /content/Data/commercial/530.png  \n",
            "  inflating: /content/Data/commercial/535.png  \n",
            "  inflating: /content/Data/commercial/538.png  \n",
            "  inflating: /content/Data/commercial/540.png  \n",
            "  inflating: /content/Data/commercial/542.png  \n",
            "  inflating: /content/Data/commercial/548.png  \n",
            "  inflating: /content/Data/commercial/550.png  \n",
            "  inflating: /content/Data/commercial/555.png  \n",
            "  inflating: /content/Data/commercial/560.png  \n",
            "  inflating: /content/Data/commercial/568.png  \n",
            "  inflating: /content/Data/commercial/581.png  \n",
            "  inflating: /content/Data/commercial/582.png  \n",
            "  inflating: /content/Data/commercial/583.png  \n",
            "  inflating: /content/Data/commercial/589.png  \n",
            "  inflating: /content/Data/commercial/591.png  \n",
            "  inflating: /content/Data/commercial/595.png  \n",
            "  inflating: /content/Data/commercial/598.png  \n",
            "  inflating: /content/Data/commercial/602.png  \n",
            "  inflating: /content/Data/commercial/607.png  \n",
            "  inflating: /content/Data/commercial/608.png  \n",
            "  inflating: /content/Data/commercial/610.png  \n",
            "  inflating: /content/Data/commercial/616.png  \n",
            "  inflating: /content/Data/commercial/617.png  \n",
            "  inflating: /content/Data/commercial/627.png  \n",
            "  inflating: /content/Data/commercial/630.png  \n",
            "  inflating: /content/Data/commercial/644.png  \n",
            "  inflating: /content/Data/commercial/653.png  \n",
            "  inflating: /content/Data/commercial/654.png  \n",
            "  inflating: /content/Data/commercial/655.png  \n",
            "  inflating: /content/Data/commercial/659.png  \n",
            "  inflating: /content/Data/commercial/661.png  \n",
            "  inflating: /content/Data/commercial/67.png  \n",
            "  inflating: /content/Data/commercial/672.png  \n",
            "  inflating: /content/Data/commercial/681.png  \n",
            "  inflating: /content/Data/commercial/688.png  \n",
            "  inflating: /content/Data/commercial/699.png  \n",
            "  inflating: /content/Data/commercial/7.png  \n",
            "  inflating: /content/Data/commercial/714.png  \n",
            "  inflating: /content/Data/commercial/73.png  \n",
            "  inflating: /content/Data/commercial/739.png  \n",
            "  inflating: /content/Data/commercial/750.png  \n",
            "  inflating: /content/Data/commercial/751.png  \n",
            "  inflating: /content/Data/commercial/758.png  \n",
            "  inflating: /content/Data/commercial/76.png  \n",
            "  inflating: /content/Data/commercial/766.png  \n",
            "  inflating: /content/Data/commercial/77.png  \n",
            "  inflating: /content/Data/commercial/771.png  \n",
            "  inflating: /content/Data/commercial/775.png  \n",
            "  inflating: /content/Data/commercial/783.png  \n",
            "  inflating: /content/Data/commercial/785.png  \n",
            "  inflating: /content/Data/commercial/794.png  \n",
            "  inflating: /content/Data/commercial/80.png  \n",
            "  inflating: /content/Data/commercial/804.png  \n",
            "  inflating: /content/Data/commercial/807.png  \n",
            "  inflating: /content/Data/commercial/810.png  \n",
            "  inflating: /content/Data/commercial/812.png  \n",
            "  inflating: /content/Data/commercial/819.png  \n",
            "  inflating: /content/Data/commercial/820.png  \n",
            "  inflating: /content/Data/commercial/823.png  \n",
            "  inflating: /content/Data/commercial/838.png  \n",
            "  inflating: /content/Data/commercial/854.png  \n",
            "  inflating: /content/Data/commercial/856.png  \n",
            "  inflating: /content/Data/commercial/864.png  \n",
            "  inflating: /content/Data/commercial/868.png  \n",
            "  inflating: /content/Data/commercial/874.png  \n",
            "  inflating: /content/Data/commercial/875.png  \n",
            "  inflating: /content/Data/commercial/893.png  \n",
            "  inflating: /content/Data/commercial/894.png  \n",
            "  inflating: /content/Data/commercial/896.png  \n",
            "  inflating: /content/Data/commercial/903.png  \n",
            "  inflating: /content/Data/commercial/905.png  \n",
            "  inflating: /content/Data/commercial/908.png  \n",
            "  inflating: /content/Data/commercial/913.png  \n",
            "  inflating: /content/Data/commercial/919.png  \n",
            "  inflating: /content/Data/commercial/921.png  \n",
            "  inflating: /content/Data/commercial/923.png  \n",
            "  inflating: /content/Data/commercial/935.png  \n",
            "  inflating: /content/Data/commercial/940.png  \n",
            "  inflating: /content/Data/commercial/946.png  \n",
            "  inflating: /content/Data/commercial/951.png  \n",
            "  inflating: /content/Data/commercial/952.png  \n",
            "  inflating: /content/Data/commercial/953.png  \n",
            "  inflating: /content/Data/commercial/957.png  \n",
            "  inflating: /content/Data/commercial/966.png  \n",
            "  inflating: /content/Data/commercial/969.png  \n",
            "  inflating: /content/Data/commercial/98.png  \n",
            "  inflating: /content/Data/commercial/982.png  \n",
            "  inflating: /content/Data/commercial/983.png  \n",
            "  inflating: /content/Data/commercial/986.png  \n",
            "  inflating: /content/Data/commercial/993.png  \n",
            "  inflating: /content/Data/commercial/997.png  \n",
            "  inflating: /content/Data/correct_function.py  \n",
            "   creating: /content/Data/education/\n",
            "  inflating: /content/Data/education/1050.png  \n",
            "  inflating: /content/Data/education/1072.png  \n",
            "  inflating: /content/Data/education/1087.png  \n",
            "  inflating: /content/Data/education/1109.png  \n",
            "  inflating: /content/Data/education/1110.png  \n",
            "  inflating: /content/Data/education/1111.png  \n",
            "  inflating: /content/Data/education/1112.png  \n",
            "  inflating: /content/Data/education/1197.png  \n",
            "  inflating: /content/Data/education/1213.png  \n",
            "  inflating: /content/Data/education/123.png  \n",
            "  inflating: /content/Data/education/1279.png  \n",
            "  inflating: /content/Data/education/1280.png  \n",
            "  inflating: /content/Data/education/1300.png  \n",
            "  inflating: /content/Data/education/1312.png  \n",
            "  inflating: /content/Data/education/1314.png  \n",
            "  inflating: /content/Data/education/1315.png  \n",
            "  inflating: /content/Data/education/1319.png  \n",
            "  inflating: /content/Data/education/1322.png  \n",
            "  inflating: /content/Data/education/1330.png  \n",
            "  inflating: /content/Data/education/1332.png  \n",
            "  inflating: /content/Data/education/1337.png  \n",
            "  inflating: /content/Data/education/1338.png  \n",
            "  inflating: /content/Data/education/1339.png  \n",
            "  inflating: /content/Data/education/1342.png  \n",
            "  inflating: /content/Data/education/1346.png  \n",
            "  inflating: /content/Data/education/1349.png  \n",
            "  inflating: /content/Data/education/1356.png  \n",
            "  inflating: /content/Data/education/1357.png  \n",
            "  inflating: /content/Data/education/1371.png  \n",
            "  inflating: /content/Data/education/1374.png  \n",
            "  inflating: /content/Data/education/1375.png  \n",
            "  inflating: /content/Data/education/1382.png  \n",
            "  inflating: /content/Data/education/1383.png  \n",
            "  inflating: /content/Data/education/1385.png  \n",
            "  inflating: /content/Data/education/1387.png  \n",
            "  inflating: /content/Data/education/1388.png  \n",
            "  inflating: /content/Data/education/1391.png  \n",
            "  inflating: /content/Data/education/1392.png  \n",
            "  inflating: /content/Data/education/1394.png  \n",
            "  inflating: /content/Data/education/1395.png  \n",
            "  inflating: /content/Data/education/1396.png  \n",
            "  inflating: /content/Data/education/1399.png  \n",
            "  inflating: /content/Data/education/1400.png  \n",
            "  inflating: /content/Data/education/1405.png  \n",
            "  inflating: /content/Data/education/1414.png  \n",
            "  inflating: /content/Data/education/1420.png  \n",
            "  inflating: /content/Data/education/1421.png  \n",
            "  inflating: /content/Data/education/1425.png  \n",
            "  inflating: /content/Data/education/1428.png  \n",
            "  inflating: /content/Data/education/143.png  \n",
            "  inflating: /content/Data/education/1435.png  \n",
            "  inflating: /content/Data/education/1437.png  \n",
            "  inflating: /content/Data/education/1446.png  \n",
            "  inflating: /content/Data/education/1447.png  \n",
            "  inflating: /content/Data/education/1448.png  \n",
            "  inflating: /content/Data/education/1457.png  \n",
            "  inflating: /content/Data/education/1461.png  \n",
            "  inflating: /content/Data/education/1462.png  \n",
            "  inflating: /content/Data/education/1465.png  \n",
            "  inflating: /content/Data/education/1467.png  \n",
            "  inflating: /content/Data/education/1471.png  \n",
            "  inflating: /content/Data/education/1472.png  \n",
            "  inflating: /content/Data/education/1473.png  \n",
            "  inflating: /content/Data/education/1477.png  \n",
            "  inflating: /content/Data/education/1478.png  \n",
            "  inflating: /content/Data/education/1485.png  \n",
            "  inflating: /content/Data/education/174.png  \n",
            "  inflating: /content/Data/education/184.png  \n",
            "  inflating: /content/Data/education/240.png  \n",
            "  inflating: /content/Data/education/262.png  \n",
            "  inflating: /content/Data/education/284.png  \n",
            "  inflating: /content/Data/education/291.png  \n",
            "  inflating: /content/Data/education/316.png  \n",
            "  inflating: /content/Data/education/330.png  \n",
            "  inflating: /content/Data/education/43.png  \n",
            "  inflating: /content/Data/education/432.png  \n",
            "  inflating: /content/Data/education/468.png  \n",
            "  inflating: /content/Data/education/525.png  \n",
            "  inflating: /content/Data/education/543.png  \n",
            "  inflating: /content/Data/education/576.png  \n",
            "  inflating: /content/Data/education/620.png  \n",
            "  inflating: /content/Data/education/621.png  \n",
            "  inflating: /content/Data/education/631.png  \n",
            "  inflating: /content/Data/education/65.png  \n",
            "  inflating: /content/Data/education/664.png  \n",
            "  inflating: /content/Data/education/682.png  \n",
            "  inflating: /content/Data/education/695.png  \n",
            "  inflating: /content/Data/education/705.png  \n",
            "  inflating: /content/Data/education/709.png  \n",
            "  inflating: /content/Data/education/724.png  \n",
            "  inflating: /content/Data/education/764.png  \n",
            "  inflating: /content/Data/education/798.png  \n",
            "  inflating: /content/Data/education/8.png  \n",
            "  inflating: /content/Data/education/802.png  \n",
            "  inflating: /content/Data/education/865.png  \n",
            "  inflating: /content/Data/education/882.png  \n",
            "  inflating: /content/Data/education/941.png  \n",
            "  inflating: /content/Data/education/956.png  \n",
            "  inflating: /content/Data/education/973.png  \n",
            "   creating: /content/Data/health care/\n",
            "  inflating: /content/Data/health care/1244.png  \n",
            "  inflating: /content/Data/health care/1276.png  \n",
            "  inflating: /content/Data/health care/1278.png  \n",
            "  inflating: /content/Data/health care/1298.png  \n",
            "  inflating: /content/Data/health care/1299.png  \n",
            "  inflating: /content/Data/health care/1308.png  \n",
            "  inflating: /content/Data/health care/1311.png  \n",
            "  inflating: /content/Data/health care/1320.png  \n",
            "  inflating: /content/Data/health care/1321.png  \n",
            "  inflating: /content/Data/health care/1326.png  \n",
            "  inflating: /content/Data/health care/1327.png  \n",
            "  inflating: /content/Data/health care/1344.png  \n",
            "  inflating: /content/Data/health care/1361.png  \n",
            "  inflating: /content/Data/health care/1362.png  \n",
            "  inflating: /content/Data/health care/1370.png  \n",
            "  inflating: /content/Data/health care/1372.png  \n",
            "  inflating: /content/Data/health care/1404.png  \n",
            "  inflating: /content/Data/health care/1409.png  \n",
            "  inflating: /content/Data/health care/1505.png  \n",
            "  inflating: /content/Data/health care/200.png  \n",
            "  inflating: /content/Data/health care/333.png  \n",
            "  inflating: /content/Data/health care/454.png  \n",
            "  inflating: /content/Data/health care/483.png  \n",
            "  inflating: /content/Data/health care/575.png  \n",
            "  inflating: /content/Data/health care/70.png  \n",
            "  inflating: /content/Data/health care/86.png  \n",
            "  inflating: /content/Data/health care/890.png  \n",
            "   creating: /content/Data/hotel/\n",
            "  inflating: /content/Data/hotel/1123.png  \n",
            "  inflating: /content/Data/hotel/1127.png  \n",
            "  inflating: /content/Data/hotel/1128.png  \n",
            "  inflating: /content/Data/hotel/1191.png  \n",
            "  inflating: /content/Data/hotel/121.png  \n",
            "  inflating: /content/Data/hotel/1263.png  \n",
            "  inflating: /content/Data/hotel/1306.png  \n",
            "  inflating: /content/Data/hotel/1487.png  \n",
            "  inflating: /content/Data/hotel/179.png  \n",
            "  inflating: /content/Data/hotel/203.png  \n",
            "  inflating: /content/Data/hotel/204.png  \n",
            "  inflating: /content/Data/hotel/206.png  \n",
            "  inflating: /content/Data/hotel/23.png  \n",
            "  inflating: /content/Data/hotel/272.png  \n",
            "  inflating: /content/Data/hotel/327.png  \n",
            "  inflating: /content/Data/hotel/365.png  \n",
            "  inflating: /content/Data/hotel/431.png  \n",
            "  inflating: /content/Data/hotel/526.png  \n",
            "  inflating: /content/Data/hotel/622.png  \n",
            "  inflating: /content/Data/hotel/623.png  \n",
            "  inflating: /content/Data/hotel/625.png  \n",
            "  inflating: /content/Data/hotel/69.png  \n",
            "  inflating: /content/Data/hotel/71.png  \n",
            "  inflating: /content/Data/hotel/718.png  \n",
            "  inflating: /content/Data/hotel/829.png  \n",
            "  inflating: /content/Data/hotel/870.png  \n",
            "  inflating: /content/Data/hotel/873.png  \n",
            "  inflating: /content/Data/hotel/878.png  \n",
            "  inflating: /content/Data/hotel/884.png  \n",
            "  inflating: /content/Data/hotel/948.png  \n",
            "   creating: /content/Data/industrial/\n",
            "  inflating: /content/Data/industrial/1001.png  \n",
            "  inflating: /content/Data/industrial/1004.png  \n",
            "  inflating: /content/Data/industrial/1008.png  \n",
            "  inflating: /content/Data/industrial/1009.png  \n",
            "  inflating: /content/Data/industrial/1013.png  \n",
            "  inflating: /content/Data/industrial/1017.png  \n",
            "  inflating: /content/Data/industrial/1020.png  \n",
            "  inflating: /content/Data/industrial/1026.png  \n",
            "  inflating: /content/Data/industrial/1033.png  \n",
            "  inflating: /content/Data/industrial/1054.png  \n",
            "  inflating: /content/Data/industrial/1055.png  \n",
            "  inflating: /content/Data/industrial/1059.png  \n",
            "  inflating: /content/Data/industrial/1063.png  \n",
            "  inflating: /content/Data/industrial/1067.png  \n",
            "  inflating: /content/Data/industrial/107.png  \n",
            "  inflating: /content/Data/industrial/1071.png  \n",
            "  inflating: /content/Data/industrial/1074.png  \n",
            "  inflating: /content/Data/industrial/1078.png  \n",
            "  inflating: /content/Data/industrial/1085.png  \n",
            "  inflating: /content/Data/industrial/1101.png  \n",
            "  inflating: /content/Data/industrial/1104.png  \n",
            "  inflating: /content/Data/industrial/1105.png  \n",
            "  inflating: /content/Data/industrial/1107.png  \n",
            "  inflating: /content/Data/industrial/1108.png  \n",
            "  inflating: /content/Data/industrial/1113.png  \n",
            "  inflating: /content/Data/industrial/1114.png  \n",
            "  inflating: /content/Data/industrial/1119.png  \n",
            "  inflating: /content/Data/industrial/1121.png  \n",
            "  inflating: /content/Data/industrial/1129.png  \n",
            "  inflating: /content/Data/industrial/1131.png  \n",
            "  inflating: /content/Data/industrial/1133.png  \n",
            "  inflating: /content/Data/industrial/1137.png  \n",
            "  inflating: /content/Data/industrial/1148.png  \n",
            "  inflating: /content/Data/industrial/1157.png  \n",
            "  inflating: /content/Data/industrial/1164.png  \n",
            "  inflating: /content/Data/industrial/1165.png  \n",
            "  inflating: /content/Data/industrial/1182.png  \n",
            "  inflating: /content/Data/industrial/1184.png  \n",
            "  inflating: /content/Data/industrial/1188.png  \n",
            "  inflating: /content/Data/industrial/1195.png  \n",
            "  inflating: /content/Data/industrial/1199.png  \n",
            "  inflating: /content/Data/industrial/1217.png  \n",
            "  inflating: /content/Data/industrial/1224.png  \n",
            "  inflating: /content/Data/industrial/1239.png  \n",
            "  inflating: /content/Data/industrial/1243.png  \n",
            "  inflating: /content/Data/industrial/1250.png  \n",
            "  inflating: /content/Data/industrial/1251.png  \n",
            "  inflating: /content/Data/industrial/1259.png  \n",
            "  inflating: /content/Data/industrial/1260.png  \n",
            "  inflating: /content/Data/industrial/14.png  \n",
            "  inflating: /content/Data/industrial/142.png  \n",
            "  inflating: /content/Data/industrial/1445.png  \n",
            "  inflating: /content/Data/industrial/1453.png  \n",
            "  inflating: /content/Data/industrial/1455.png  \n",
            "  inflating: /content/Data/industrial/1456.png  \n",
            "  inflating: /content/Data/industrial/166.png  \n",
            "  inflating: /content/Data/industrial/167.png  \n",
            "  inflating: /content/Data/industrial/253.png  \n",
            "  inflating: /content/Data/industrial/256.png  \n",
            "  inflating: /content/Data/industrial/268.png  \n",
            "  inflating: /content/Data/industrial/273.png  \n",
            "  inflating: /content/Data/industrial/339.png  \n",
            "  inflating: /content/Data/industrial/340.png  \n",
            "  inflating: /content/Data/industrial/342.png  \n",
            "  inflating: /content/Data/industrial/360.png  \n",
            "  inflating: /content/Data/industrial/361.png  \n",
            "  inflating: /content/Data/industrial/367.png  \n",
            "  inflating: /content/Data/industrial/370.png  \n",
            "  inflating: /content/Data/industrial/396.png  \n",
            "  inflating: /content/Data/industrial/400.png  \n",
            "  inflating: /content/Data/industrial/436.png  \n",
            "  inflating: /content/Data/industrial/437.png  \n",
            "  inflating: /content/Data/industrial/438.png  \n",
            "  inflating: /content/Data/industrial/486.png  \n",
            "  inflating: /content/Data/industrial/488.png  \n",
            "  inflating: /content/Data/industrial/494.png  \n",
            "  inflating: /content/Data/industrial/500.png  \n",
            "  inflating: /content/Data/industrial/503.png  \n",
            "  inflating: /content/Data/industrial/504.png  \n",
            "  inflating: /content/Data/industrial/514.png  \n",
            "  inflating: /content/Data/industrial/521.png  \n",
            "  inflating: /content/Data/industrial/533.png  \n",
            "  inflating: /content/Data/industrial/537.png  \n",
            "  inflating: /content/Data/industrial/54.png  \n",
            "  inflating: /content/Data/industrial/545.png  \n",
            "  inflating: /content/Data/industrial/553.png  \n",
            "  inflating: /content/Data/industrial/567.png  \n",
            "  inflating: /content/Data/industrial/580.png  \n",
            "  inflating: /content/Data/industrial/585.png  \n",
            "  inflating: /content/Data/industrial/590.png  \n",
            "  inflating: /content/Data/industrial/599.png  \n",
            "  inflating: /content/Data/industrial/614.png  \n",
            "  inflating: /content/Data/industrial/618.png  \n",
            "  inflating: /content/Data/industrial/647.png  \n",
            "  inflating: /content/Data/industrial/671.png  \n",
            "  inflating: /content/Data/industrial/676.png  \n",
            "  inflating: /content/Data/industrial/693.png  \n",
            "  inflating: /content/Data/industrial/701.png  \n",
            "  inflating: /content/Data/industrial/703.png  \n",
            "  inflating: /content/Data/industrial/712.png  \n",
            "  inflating: /content/Data/industrial/716.png  \n",
            "  inflating: /content/Data/industrial/723.png  \n",
            "  inflating: /content/Data/industrial/726.png  \n",
            "  inflating: /content/Data/industrial/734.png  \n",
            "  inflating: /content/Data/industrial/737.png  \n",
            "  inflating: /content/Data/industrial/738.png  \n",
            "  inflating: /content/Data/industrial/743.png  \n",
            "  inflating: /content/Data/industrial/744.png  \n",
            "  inflating: /content/Data/industrial/748.png  \n",
            "  inflating: /content/Data/industrial/75.png  \n",
            "  inflating: /content/Data/industrial/753.png  \n",
            "  inflating: /content/Data/industrial/757.png  \n",
            "  inflating: /content/Data/industrial/761.png  \n",
            "  inflating: /content/Data/industrial/768.png  \n",
            "  inflating: /content/Data/industrial/769.png  \n",
            "  inflating: /content/Data/industrial/773.png  \n",
            "  inflating: /content/Data/industrial/774.png  \n",
            "  inflating: /content/Data/industrial/777.png  \n",
            "  inflating: /content/Data/industrial/778.png  \n",
            "  inflating: /content/Data/industrial/779.png  \n",
            "  inflating: /content/Data/industrial/781.png  \n",
            "  inflating: /content/Data/industrial/787.png  \n",
            "  inflating: /content/Data/industrial/791.png  \n",
            "  inflating: /content/Data/industrial/792.png  \n",
            "  inflating: /content/Data/industrial/796.png  \n",
            "  inflating: /content/Data/industrial/801.png  \n",
            "  inflating: /content/Data/industrial/813.png  \n",
            "  inflating: /content/Data/industrial/827.png  \n",
            "  inflating: /content/Data/industrial/828.png  \n",
            "  inflating: /content/Data/industrial/839.png  \n",
            "  inflating: /content/Data/industrial/840.png  \n",
            "  inflating: /content/Data/industrial/850.png  \n",
            "  inflating: /content/Data/industrial/852.png  \n",
            "  inflating: /content/Data/industrial/853.png  \n",
            "  inflating: /content/Data/industrial/881.png  \n",
            "  inflating: /content/Data/industrial/898.png  \n",
            "  inflating: /content/Data/industrial/899.png  \n",
            "  inflating: /content/Data/industrial/901.png  \n",
            "  inflating: /content/Data/industrial/910.png  \n",
            "  inflating: /content/Data/industrial/911.png  \n",
            "  inflating: /content/Data/industrial/95.png  \n",
            "  inflating: /content/Data/industrial/96.png  \n",
            "  inflating: /content/Data/industrial/963.png  \n",
            "  inflating: /content/Data/industrial/996.png  \n",
            "  inflating: /content/Data/industrial/999.png  \n",
            "   creating: /content/Data/outdoors and natural/\n",
            "  inflating: /content/Data/outdoors and natural/1011.png  \n",
            "  inflating: /content/Data/outdoors and natural/1115.png  \n",
            "  inflating: /content/Data/outdoors and natural/1136.png  \n",
            "  inflating: /content/Data/outdoors and natural/1154.png  \n",
            "  inflating: /content/Data/outdoors and natural/1172.png  \n",
            "  inflating: /content/Data/outdoors and natural/119.png  \n",
            "  inflating: /content/Data/outdoors and natural/1198.png  \n",
            "  inflating: /content/Data/outdoors and natural/1203.png  \n",
            "  inflating: /content/Data/outdoors and natural/1247.png  \n",
            "  inflating: /content/Data/outdoors and natural/1248.png  \n",
            "  inflating: /content/Data/outdoors and natural/1253.png  \n",
            "  inflating: /content/Data/outdoors and natural/1265.png  \n",
            "  inflating: /content/Data/outdoors and natural/1301.png  \n",
            "  inflating: /content/Data/outdoors and natural/132.png  \n",
            "  inflating: /content/Data/outdoors and natural/1490.png  \n",
            "  inflating: /content/Data/outdoors and natural/205.png  \n",
            "  inflating: /content/Data/outdoors and natural/237.png  \n",
            "  inflating: /content/Data/outdoors and natural/258.png  \n",
            "  inflating: /content/Data/outdoors and natural/422.png  \n",
            "  inflating: /content/Data/outdoors and natural/466.png  \n",
            "  inflating: /content/Data/outdoors and natural/476.png  \n",
            "  inflating: /content/Data/outdoors and natural/577.png  \n",
            "  inflating: /content/Data/outdoors and natural/593.png  \n",
            "  inflating: /content/Data/outdoors and natural/613.png  \n",
            "  inflating: /content/Data/outdoors and natural/637.png  \n",
            "  inflating: /content/Data/outdoors and natural/641.png  \n",
            "  inflating: /content/Data/outdoors and natural/646.png  \n",
            "  inflating: /content/Data/outdoors and natural/652.png  \n",
            "  inflating: /content/Data/outdoors and natural/657.png  \n",
            "  inflating: /content/Data/outdoors and natural/719.png  \n",
            "  inflating: /content/Data/outdoors and natural/722.png  \n",
            "  inflating: /content/Data/outdoors and natural/825.png  \n",
            "  inflating: /content/Data/outdoors and natural/915.png  \n",
            "  inflating: /content/Data/outdoors and natural/964.png  \n",
            "  inflating: /content/Data/outdoors and natural/965.png  \n",
            "  inflating: /content/Data/outdoors and natural/972.png  \n",
            "  inflating: /content/Data/outdoors and natural/990.png  \n",
            "  inflating: /content/Data/outdoors and natural/991.png  \n",
            "   creating: /content/Data/residential/\n",
            "  inflating: /content/Data/residential/1012.png  \n",
            "  inflating: /content/Data/residential/1018.png  \n",
            "  inflating: /content/Data/residential/102.png  \n",
            "  inflating: /content/Data/residential/1023.png  \n",
            "  inflating: /content/Data/residential/1024.png  \n",
            "  inflating: /content/Data/residential/103.png  \n",
            "  inflating: /content/Data/residential/1030.png  \n",
            "  inflating: /content/Data/residential/1031.png  \n",
            "  inflating: /content/Data/residential/1036.png  \n",
            "  inflating: /content/Data/residential/1041.png  \n",
            "  inflating: /content/Data/residential/1042.png  \n",
            "  inflating: /content/Data/residential/1044.png  \n",
            "  inflating: /content/Data/residential/1045.png  \n",
            "  inflating: /content/Data/residential/1046.png  \n",
            "  inflating: /content/Data/residential/1048.png  \n",
            "  inflating: /content/Data/residential/105.png  \n",
            "  inflating: /content/Data/residential/1052.png  \n",
            "  inflating: /content/Data/residential/1053.png  \n",
            "  inflating: /content/Data/residential/1057.png  \n",
            "  inflating: /content/Data/residential/1058.png  \n",
            "  inflating: /content/Data/residential/1060.png  \n",
            "  inflating: /content/Data/residential/1061.png  \n",
            "  inflating: /content/Data/residential/1066.png  \n",
            "  inflating: /content/Data/residential/1068.png  \n",
            "  inflating: /content/Data/residential/1070.png  \n",
            "  inflating: /content/Data/residential/1073.png  \n",
            "  inflating: /content/Data/residential/1075.png  \n",
            "  inflating: /content/Data/residential/1079.png  \n",
            "  inflating: /content/Data/residential/1084.png  \n",
            "  inflating: /content/Data/residential/1088.png  \n",
            "  inflating: /content/Data/residential/1089.png  \n",
            "  inflating: /content/Data/residential/1090.png  \n",
            "  inflating: /content/Data/residential/1091.png  \n",
            "  inflating: /content/Data/residential/1095.png  \n",
            "  inflating: /content/Data/residential/1103.png  \n",
            "  inflating: /content/Data/residential/1106.png  \n",
            "  inflating: /content/Data/residential/1118.png  \n",
            "  inflating: /content/Data/residential/1126.png  \n",
            "  inflating: /content/Data/residential/1132.png  \n",
            "  inflating: /content/Data/residential/114.png  \n",
            "  inflating: /content/Data/residential/1141.png  \n",
            "  inflating: /content/Data/residential/1145.png  \n",
            "  inflating: /content/Data/residential/1149.png  \n",
            "  inflating: /content/Data/residential/1155.png  \n",
            "  inflating: /content/Data/residential/1156.png  \n",
            "  inflating: /content/Data/residential/1159.png  \n",
            "  inflating: /content/Data/residential/1160.png  \n",
            "  inflating: /content/Data/residential/1163.png  \n",
            "  inflating: /content/Data/residential/1166.png  \n",
            "  inflating: /content/Data/residential/1167.png  \n",
            "  inflating: /content/Data/residential/1168.png  \n",
            "  inflating: /content/Data/residential/1177.png  \n",
            "  inflating: /content/Data/residential/118.png  \n",
            "  inflating: /content/Data/residential/1180.png  \n",
            "  inflating: /content/Data/residential/1186.png  \n",
            "  inflating: /content/Data/residential/1187.png  \n",
            "  inflating: /content/Data/residential/1190.png  \n",
            "  inflating: /content/Data/residential/1192.png  \n",
            "  inflating: /content/Data/residential/1204.png  \n",
            "  inflating: /content/Data/residential/1205.png  \n",
            "  inflating: /content/Data/residential/1209.png  \n",
            "  inflating: /content/Data/residential/1210.png  \n",
            "  inflating: /content/Data/residential/1216.png  \n",
            "  inflating: /content/Data/residential/1222.png  \n",
            "  inflating: /content/Data/residential/1233.png  \n",
            "  inflating: /content/Data/residential/124.png  \n",
            "  inflating: /content/Data/residential/1240.png  \n",
            "  inflating: /content/Data/residential/1241.png  \n",
            "  inflating: /content/Data/residential/1249.png  \n",
            "  inflating: /content/Data/residential/1252.png  \n",
            "  inflating: /content/Data/residential/1254.png  \n",
            "  inflating: /content/Data/residential/1255.png  \n",
            "  inflating: /content/Data/residential/1256.png  \n",
            "  inflating: /content/Data/residential/133.png  \n",
            "  inflating: /content/Data/residential/134.png  \n",
            "  inflating: /content/Data/residential/135.png  \n",
            "  inflating: /content/Data/residential/137.png  \n",
            "  inflating: /content/Data/residential/145.png  \n",
            "  inflating: /content/Data/residential/1468.png  \n",
            "  inflating: /content/Data/residential/149.png  \n",
            "  inflating: /content/Data/residential/150.png  \n",
            "  inflating: /content/Data/residential/154.png  \n",
            "  inflating: /content/Data/residential/158.png  \n",
            "  inflating: /content/Data/residential/159.png  \n",
            "  inflating: /content/Data/residential/160.png  \n",
            "  inflating: /content/Data/residential/161.png  \n",
            "  inflating: /content/Data/residential/163.png  \n",
            "  inflating: /content/Data/residential/165.png  \n",
            "  inflating: /content/Data/residential/170.png  \n",
            "  inflating: /content/Data/residential/172.png  \n",
            "  inflating: /content/Data/residential/173.png  \n",
            "  inflating: /content/Data/residential/18.png  \n",
            "  inflating: /content/Data/residential/186.png  \n",
            "  inflating: /content/Data/residential/187.png  \n",
            "  inflating: /content/Data/residential/194.png  \n",
            "  inflating: /content/Data/residential/208.png  \n",
            "  inflating: /content/Data/residential/21.png  \n",
            "  inflating: /content/Data/residential/210.png  \n",
            "  inflating: /content/Data/residential/211.png  \n",
            "  inflating: /content/Data/residential/214.png  \n",
            "  inflating: /content/Data/residential/217.png  \n",
            "  inflating: /content/Data/residential/219.png  \n",
            "  inflating: /content/Data/residential/22.png  \n",
            "  inflating: /content/Data/residential/222.png  \n",
            "  inflating: /content/Data/residential/226.png  \n",
            "  inflating: /content/Data/residential/227.png  \n",
            "  inflating: /content/Data/residential/231.png  \n",
            "  inflating: /content/Data/residential/232.png  \n",
            "  inflating: /content/Data/residential/242.png  \n",
            "  inflating: /content/Data/residential/243.png  \n",
            "  inflating: /content/Data/residential/246.png  \n",
            "  inflating: /content/Data/residential/247.png  \n",
            "  inflating: /content/Data/residential/248.png  \n",
            "  inflating: /content/Data/residential/252.png  \n",
            "  inflating: /content/Data/residential/26.png  \n",
            "  inflating: /content/Data/residential/260.png  \n",
            "  inflating: /content/Data/residential/266.png  \n",
            "  inflating: /content/Data/residential/269.png  \n",
            "  inflating: /content/Data/residential/270.png  \n",
            "  inflating: /content/Data/residential/274.png  \n",
            "  inflating: /content/Data/residential/277.png  \n",
            "  inflating: /content/Data/residential/279.png  \n",
            "  inflating: /content/Data/residential/286.png  \n",
            "  inflating: /content/Data/residential/287.png  \n",
            "  inflating: /content/Data/residential/289.png  \n",
            "  inflating: /content/Data/residential/295.png  \n",
            "  inflating: /content/Data/residential/296.png  \n",
            "  inflating: /content/Data/residential/297.png  \n",
            "  inflating: /content/Data/residential/298.png  \n",
            "  inflating: /content/Data/residential/299.png  \n",
            "  inflating: /content/Data/residential/303.png  \n",
            "  inflating: /content/Data/residential/307.png  \n",
            "  inflating: /content/Data/residential/308.png  \n",
            "  inflating: /content/Data/residential/310.png  \n",
            "  inflating: /content/Data/residential/314.png  \n",
            "  inflating: /content/Data/residential/315.png  \n",
            "  inflating: /content/Data/residential/317.png  \n",
            "  inflating: /content/Data/residential/32.png  \n",
            "  inflating: /content/Data/residential/329.png  \n",
            "  inflating: /content/Data/residential/331.png  \n",
            "  inflating: /content/Data/residential/334.png  \n",
            "  inflating: /content/Data/residential/335.png  \n",
            "  inflating: /content/Data/residential/336.png  \n",
            "  inflating: /content/Data/residential/341.png  \n",
            "  inflating: /content/Data/residential/343.png  \n",
            "  inflating: /content/Data/residential/344.png  \n",
            "  inflating: /content/Data/residential/346.png  \n",
            "  inflating: /content/Data/residential/349.png  \n",
            "  inflating: /content/Data/residential/35.png  \n",
            "  inflating: /content/Data/residential/357.png  \n",
            "  inflating: /content/Data/residential/36.png  \n",
            "  inflating: /content/Data/residential/37.png  \n",
            "  inflating: /content/Data/residential/372.png  \n",
            "  inflating: /content/Data/residential/375.png  \n",
            "  inflating: /content/Data/residential/381.png  \n",
            "  inflating: /content/Data/residential/386.png  \n",
            "  inflating: /content/Data/residential/394.png  \n",
            "  inflating: /content/Data/residential/398.png  \n",
            "  inflating: /content/Data/residential/4.png  \n",
            "  inflating: /content/Data/residential/40.png  \n",
            "  inflating: /content/Data/residential/405.png  \n",
            "  inflating: /content/Data/residential/412.png  \n",
            "  inflating: /content/Data/residential/42.png  \n",
            "  inflating: /content/Data/residential/427.png  \n",
            "  inflating: /content/Data/residential/433.png  \n",
            "  inflating: /content/Data/residential/443.png  \n",
            "  inflating: /content/Data/residential/448.png  \n",
            "  inflating: /content/Data/residential/449.png  \n",
            "  inflating: /content/Data/residential/456.png  \n",
            "  inflating: /content/Data/residential/458.png  \n",
            "  inflating: /content/Data/residential/459.png  \n",
            "  inflating: /content/Data/residential/463.png  \n",
            "  inflating: /content/Data/residential/464.png  \n",
            "  inflating: /content/Data/residential/467.png  \n",
            "  inflating: /content/Data/residential/47.png  \n",
            "  inflating: /content/Data/residential/474.png  \n",
            "  inflating: /content/Data/residential/475.png  \n",
            "  inflating: /content/Data/residential/477.png  \n",
            "  inflating: /content/Data/residential/480.png  \n",
            "  inflating: /content/Data/residential/481.png  \n",
            "  inflating: /content/Data/residential/482.png  \n",
            "  inflating: /content/Data/residential/484.png  \n",
            "  inflating: /content/Data/residential/485.png  \n",
            "  inflating: /content/Data/residential/487.png  \n",
            "  inflating: /content/Data/residential/49.png  \n",
            "  inflating: /content/Data/residential/493.png  \n",
            "  inflating: /content/Data/residential/495.png  \n",
            "  inflating: /content/Data/residential/50.png  \n",
            "  inflating: /content/Data/residential/501.png  \n",
            "  inflating: /content/Data/residential/505.png  \n",
            "  inflating: /content/Data/residential/506.png  \n",
            "  inflating: /content/Data/residential/507.png  \n",
            "  inflating: /content/Data/residential/508.png  \n",
            "  inflating: /content/Data/residential/509.png  \n",
            "  inflating: /content/Data/residential/51.png  \n",
            "  inflating: /content/Data/residential/512.png  \n",
            "  inflating: /content/Data/residential/513.png  \n",
            "  inflating: /content/Data/residential/519.png  \n",
            "  inflating: /content/Data/residential/523.png  \n",
            "  inflating: /content/Data/residential/536.png  \n",
            "  inflating: /content/Data/residential/539.png  \n",
            "  inflating: /content/Data/residential/546.png  \n",
            "  inflating: /content/Data/residential/554.png  \n",
            "  inflating: /content/Data/residential/559.png  \n",
            "  inflating: /content/Data/residential/561.png  \n",
            "  inflating: /content/Data/residential/563.png  \n",
            "  inflating: /content/Data/residential/564.png  \n",
            "  inflating: /content/Data/residential/570.png  \n",
            "  inflating: /content/Data/residential/572.png  \n",
            "  inflating: /content/Data/residential/573.png  \n",
            "  inflating: /content/Data/residential/578.png  \n",
            "  inflating: /content/Data/residential/579.png  \n",
            "  inflating: /content/Data/residential/586.png  \n",
            "  inflating: /content/Data/residential/588.png  \n",
            "  inflating: /content/Data/residential/594.png  \n",
            "  inflating: /content/Data/residential/6.png  \n",
            "  inflating: /content/Data/residential/61.png  \n",
            "  inflating: /content/Data/residential/612.png  \n",
            "  inflating: /content/Data/residential/619.png  \n",
            "  inflating: /content/Data/residential/629.png  \n",
            "  inflating: /content/Data/residential/636.png  \n",
            "  inflating: /content/Data/residential/638.png  \n",
            "  inflating: /content/Data/residential/643.png  \n",
            "  inflating: /content/Data/residential/650.png  \n",
            "  inflating: /content/Data/residential/656.png  \n",
            "  inflating: /content/Data/residential/658.png  \n",
            "  inflating: /content/Data/residential/662.png  \n",
            "  inflating: /content/Data/residential/663.png  \n",
            "  inflating: /content/Data/residential/667.png  \n",
            "  inflating: /content/Data/residential/669.png  \n",
            "  inflating: /content/Data/residential/670.png  \n",
            "  inflating: /content/Data/residential/673.png  \n",
            "  inflating: /content/Data/residential/675.png  \n",
            "  inflating: /content/Data/residential/677.png  \n",
            "  inflating: /content/Data/residential/678.png  \n",
            "  inflating: /content/Data/residential/68.png  \n",
            "  inflating: /content/Data/residential/686.png  \n",
            "  inflating: /content/Data/residential/687.png  \n",
            "  inflating: /content/Data/residential/692.png  \n",
            "  inflating: /content/Data/residential/698.png  \n",
            "  inflating: /content/Data/residential/702.png  \n",
            "  inflating: /content/Data/residential/710.png  \n",
            "  inflating: /content/Data/residential/715.png  \n",
            "  inflating: /content/Data/residential/729.png  \n",
            "  inflating: /content/Data/residential/731.png  \n",
            "  inflating: /content/Data/residential/735.png  \n",
            "  inflating: /content/Data/residential/736.png  \n",
            "  inflating: /content/Data/residential/740.png  \n",
            "  inflating: /content/Data/residential/741.png  \n",
            "  inflating: /content/Data/residential/742.png  \n",
            "  inflating: /content/Data/residential/752.png  \n",
            "  inflating: /content/Data/residential/756.png  \n",
            "  inflating: /content/Data/residential/759.png  \n",
            "  inflating: /content/Data/residential/762.png  \n",
            "  inflating: /content/Data/residential/765.png  \n",
            "  inflating: /content/Data/residential/767.png  \n",
            "  inflating: /content/Data/residential/770.png  \n",
            "  inflating: /content/Data/residential/776.png  \n",
            "  inflating: /content/Data/residential/78.png  \n",
            "  inflating: /content/Data/residential/780.png  \n",
            "  inflating: /content/Data/residential/782.png  \n",
            "  inflating: /content/Data/residential/786.png  \n",
            "  inflating: /content/Data/residential/788.png  \n",
            "  inflating: /content/Data/residential/789.png  \n",
            "  inflating: /content/Data/residential/790.png  \n",
            "  inflating: /content/Data/residential/793.png  \n",
            "  inflating: /content/Data/residential/795.png  \n",
            "  inflating: /content/Data/residential/797.png  \n",
            "  inflating: /content/Data/residential/803.png  \n",
            "  inflating: /content/Data/residential/806.png  \n",
            "  inflating: /content/Data/residential/811.png  \n",
            "  inflating: /content/Data/residential/814.png  \n",
            "  inflating: /content/Data/residential/818.png  \n",
            "  inflating: /content/Data/residential/822.png  \n",
            "  inflating: /content/Data/residential/824.png  \n",
            "  inflating: /content/Data/residential/83.png  \n",
            "  inflating: /content/Data/residential/830.png  \n",
            "  inflating: /content/Data/residential/833.png  \n",
            "  inflating: /content/Data/residential/834.png  \n",
            "  inflating: /content/Data/residential/836.png  \n",
            "  inflating: /content/Data/residential/842.png  \n",
            "  inflating: /content/Data/residential/844.png  \n",
            "  inflating: /content/Data/residential/845.png  \n",
            "  inflating: /content/Data/residential/846.png  \n",
            "  inflating: /content/Data/residential/847.png  \n",
            "  inflating: /content/Data/residential/849.png  \n",
            "  inflating: /content/Data/residential/851.png  \n",
            "  inflating: /content/Data/residential/857.png  \n",
            "  inflating: /content/Data/residential/863.png  \n",
            "  inflating: /content/Data/residential/867.png  \n",
            "  inflating: /content/Data/residential/871.png  \n",
            "  inflating: /content/Data/residential/879.png  \n",
            "  inflating: /content/Data/residential/88.png  \n",
            "  inflating: /content/Data/residential/887.png  \n",
            "  inflating: /content/Data/residential/888.png  \n",
            "  inflating: /content/Data/residential/889.png  \n",
            "  inflating: /content/Data/residential/891.png  \n",
            "  inflating: /content/Data/residential/892.png  \n",
            "  inflating: /content/Data/residential/897.png  \n",
            "  inflating: /content/Data/residential/9.png  \n",
            "  inflating: /content/Data/residential/902.png  \n",
            "  inflating: /content/Data/residential/906.png  \n",
            "  inflating: /content/Data/residential/907.png  \n",
            "  inflating: /content/Data/residential/912.png  \n",
            "  inflating: /content/Data/residential/914.png  \n",
            "  inflating: /content/Data/residential/918.png  \n",
            "  inflating: /content/Data/residential/922.png  \n",
            "  inflating: /content/Data/residential/925.png  \n",
            "  inflating: /content/Data/residential/927.png  \n",
            "  inflating: /content/Data/residential/928.png  \n",
            "  inflating: /content/Data/residential/93.png  \n",
            "  inflating: /content/Data/residential/930.png  \n",
            "  inflating: /content/Data/residential/931.png  \n",
            "  inflating: /content/Data/residential/933.png  \n",
            "  inflating: /content/Data/residential/936.png  \n",
            "  inflating: /content/Data/residential/938.png  \n",
            "  inflating: /content/Data/residential/939.png  \n",
            "  inflating: /content/Data/residential/942.png  \n",
            "  inflating: /content/Data/residential/944.png  \n",
            "  inflating: /content/Data/residential/945.png  \n",
            "  inflating: /content/Data/residential/947.png  \n",
            "  inflating: /content/Data/residential/949.png  \n",
            "  inflating: /content/Data/residential/955.png  \n",
            "  inflating: /content/Data/residential/959.png  \n",
            "  inflating: /content/Data/residential/961.png  \n",
            "  inflating: /content/Data/residential/968.png  \n",
            "  inflating: /content/Data/residential/970.png  \n",
            "  inflating: /content/Data/residential/974.png  \n",
            "  inflating: /content/Data/residential/975.png  \n",
            "  inflating: /content/Data/residential/979.png  \n",
            "  inflating: /content/Data/residential/988.png  \n",
            "  inflating: /content/Data/residential/989.png  \n",
            "  inflating: /content/Data/residential/992.png  \n",
            "  inflating: /content/Data/residential/995.png  \n",
            "  inflating: /content/Data/residential/998.png  \n",
            "   creating: /content/Data/sports and recreation/\n",
            "  inflating: /content/Data/sports and recreation/1098.png  \n",
            "  inflating: /content/Data/sports and recreation/130.png  \n",
            "  inflating: /content/Data/sports and recreation/1341.png  \n",
            "  inflating: /content/Data/sports and recreation/1366.png  \n",
            "  inflating: /content/Data/sports and recreation/1376.png  \n",
            "  inflating: /content/Data/sports and recreation/1377.png  \n",
            "  inflating: /content/Data/sports and recreation/138.png  \n",
            "  inflating: /content/Data/sports and recreation/1381.png  \n",
            "  inflating: /content/Data/sports and recreation/1389.png  \n",
            "  inflating: /content/Data/sports and recreation/1410.png  \n",
            "  inflating: /content/Data/sports and recreation/1486.png  \n",
            "  inflating: /content/Data/sports and recreation/1495.png  \n",
            "  inflating: /content/Data/sports and recreation/182.png  \n",
            "  inflating: /content/Data/sports and recreation/185.png  \n",
            "  inflating: /content/Data/sports and recreation/196.png  \n",
            "  inflating: /content/Data/sports and recreation/220.png  \n",
            "  inflating: /content/Data/sports and recreation/25.png  \n",
            "  inflating: /content/Data/sports and recreation/31.png  \n",
            "  inflating: /content/Data/sports and recreation/55.png  \n",
            "  inflating: /content/Data/sports and recreation/571.png  \n",
            "  inflating: /content/Data/sports and recreation/574.png  \n",
            "  inflating: /content/Data/sports and recreation/604.png  \n",
            "  inflating: /content/Data/sports and recreation/680.png  \n",
            "  inflating: /content/Data/sports and recreation/691.png  \n",
            "  inflating: /content/Data/sports and recreation/704.png  \n",
            "  inflating: /content/Data/sports and recreation/717.png  \n",
            "  inflating: /content/Data/sports and recreation/746.png  \n",
            "  inflating: /content/Data/sports and recreation/920.png  \n",
            "   creating: /content/Data/transportation/\n",
            "  inflating: /content/Data/transportation/1.png  \n",
            "  inflating: /content/Data/transportation/1005.png  \n",
            "  inflating: /content/Data/transportation/1021.png  \n",
            "  inflating: /content/Data/transportation/1069.png  \n",
            "  inflating: /content/Data/transportation/1232.png  \n",
            "  inflating: /content/Data/transportation/1234.png  \n",
            "  inflating: /content/Data/transportation/125.png  \n",
            "  inflating: /content/Data/transportation/144.png  \n",
            "  inflating: /content/Data/transportation/147.png  \n",
            "  inflating: /content/Data/transportation/164.png  \n",
            "  inflating: /content/Data/transportation/171.png  \n",
            "  inflating: /content/Data/transportation/190.png  \n",
            "  inflating: /content/Data/transportation/192.png  \n",
            "  inflating: /content/Data/transportation/193.png  \n",
            "  inflating: /content/Data/transportation/221.png  \n",
            "  inflating: /content/Data/transportation/235.png  \n",
            "  inflating: /content/Data/transportation/236.png  \n",
            "  inflating: /content/Data/transportation/251.png  \n",
            "  inflating: /content/Data/transportation/254.png  \n",
            "  inflating: /content/Data/transportation/263.png  \n",
            "  inflating: /content/Data/transportation/304.png  \n",
            "  inflating: /content/Data/transportation/318.png  \n",
            "  inflating: /content/Data/transportation/319.png  \n",
            "  inflating: /content/Data/transportation/320.png  \n",
            "  inflating: /content/Data/transportation/321.png  \n",
            "  inflating: /content/Data/transportation/323.png  \n",
            "  inflating: /content/Data/transportation/328.png  \n",
            "  inflating: /content/Data/transportation/45.png  \n",
            "  inflating: /content/Data/transportation/457.png  \n",
            "  inflating: /content/Data/transportation/460.png  \n",
            "  inflating: /content/Data/transportation/479.png  \n",
            "  inflating: /content/Data/transportation/48.png  \n",
            "  inflating: /content/Data/transportation/489.png  \n",
            "  inflating: /content/Data/transportation/491.png  \n",
            "  inflating: /content/Data/transportation/517.png  \n",
            "  inflating: /content/Data/transportation/528.png  \n",
            "  inflating: /content/Data/transportation/57.png  \n",
            "  inflating: /content/Data/transportation/615.png  \n",
            "  inflating: /content/Data/transportation/626.png  \n",
            "  inflating: /content/Data/transportation/685.png  \n",
            "  inflating: /content/Data/transportation/72.png  \n",
            "  inflating: /content/Data/transportation/720.png  \n",
            "  inflating: /content/Data/transportation/860.png  \n",
            "  inflating: /content/Data/transportation/87.png  \n",
            "  inflating: /content/Data/transportation/900.png  \n",
            "  inflating: /content/Data/transportation/937.png  \n",
            "  inflating: /content/Data/transportation/99.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfAYmgUKHqSA",
        "outputId": "6961a9db-2e8b-4006-f097-8798c4cf9584"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'civic, governmental and cultural'   education\t    industrial\t\t   'sports and recreation'\n",
            " commercial\t\t\t    'health care'  'outdoors and natural'   transportation\n",
            " correct_function.py\t\t     hotel\t    residential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoFeatureExtractor, AutoModel\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加载预训练的 facebook/vit-large-patch14-336 模型和特征提取器\n",
        "model_name = \"facebook/vit-large-patch14-336\"\n",
        "print(f\"Loading model and feature extractor for {model_name}...\")\n",
        "model = AutoModel.from_pretrained(model_name).to(device)\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "model.eval()  # 设置模型为评估模式\n",
        "\n",
        "# 定义特征提取函数\n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # 获取并按文件名中的数字顺序排序图像路径\n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\"Found {len(image_paths)} images in {image_folder}.\")\n",
        "\n",
        "    # 处理每一张图像\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 加载并确保图像为 RGB 格式\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            # 使用特征提取器进行预处理\n",
        "            inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "            # 禁用梯度计算，提高效率\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "                # 提取 [CLS] token 的特征\n",
        "                image_features = outputs.last_hidden_state[:, 0]\n",
        "\n",
        "                # 归一化特征向量\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                # 将特征移动到 CPU 并添加到列表中\n",
        "                image_features_list.append(image_features.cpu())\n",
        "                image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"特征已保存到 {output_file}\")\n",
        "    else:\n",
        "        print(f\"在 {image_folder} 中未找到有效的图像\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "# 定义计算余弦相似度并保存为 CSV 的函数\n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"特征或文件名为空，无法计算余弦相似度。\")\n",
        "        return\n",
        "\n",
        "    print(\"计算余弦相似度矩阵...\")\n",
        "\n",
        "    # 确保特征已经归一化\n",
        "    # 余弦相似度可以通过特征矩阵与其转置的点积计算\n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()\n",
        "\n",
        "    print(f\"相似度矩阵大小: {similarity_matrix.shape}\")\n",
        "\n",
        "    # 将相似度矩阵转换为 DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # 保存为 CSV 文件\n",
        "    df.to_csv(csv_output)\n",
        "    print(f\"余弦相似度矩阵已保存到 {csv_output}\")\n",
        "\n",
        "# 主流程\n",
        "if __name__ == \"__main__\":\n",
        "    # 定义图像文件夹和输出文件\n",
        "    image_folder = './Data/civic, governmental and cultural'\n",
        "    feature_output = './imgs_vit_1.pt'\n",
        "    csv_output = './cosine_similarity_matrix.csv'\n",
        "\n",
        "    # 提取特征\n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    # 计算余弦相似度并保存为 CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nmSSOt2KnScB",
        "outputId": "6c843d9e-2b81-45f0-a8be-9508e982991b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading model and feature extractor for facebook/vit-large-patch14-336...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "facebook/vit-large-patch14-336 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/facebook/vit-large-patch14-336/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-677007cb-6049569f32f3bb840d2568c5;d3013012-13a7-4677-b684-be550afda868)\n\nRepository Not Found for url: https://huggingface.co/facebook/vit-large-patch14-336/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7734868a636d>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/vit-large-patch14-336\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading model and feature extractor for {model_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoFeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 设置模型为评估模式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: facebook/vit-large-patch14-336 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j6zfMt-r4lS",
        "outputId": "2c52b717-fcc3-40a3-f657-2dc87dc8e63d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-kw85g05g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-kw85g05g\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=60fb964f90981a8aff8ff3b55aff3f4becbdcfaaa49f1520189692a3f450eea0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m0mu_3n7/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# 确保你已经安装了 CLIP 库。如果尚未安装，可以使用以下命令：\n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加载预训练的 CLIP 模型和预处理函数\n",
        "model_name = \"ViT-L/14@336px\"  # 确保该模型名称在 CLIP 库中可用\n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # 设置模型为评估模式\n",
        "print(\"CLIP 模型加载完成。\")\n",
        "\n",
        "# 定义特征提取函数\n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # 获取并按文件名中的数字顺序排序图像路径\n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\"在文件夹 {image_folder} 中找到 {len(image_paths)} 张图像。\")\n",
        "\n",
        "    # 处理每一张图像\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 加载并预处理图像\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # 添加批次维度并移动到设备\n",
        "\n",
        "            # 禁用梯度计算，提高效率\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # 编码图像\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化特征向量\n",
        "\n",
        "            # 将特征移动到 CPU 并添加到列表中\n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"特征已保存到 {output_file}\")\n",
        "    else:\n",
        "        print(f\"在 {image_folder} 中未找到有效的图像\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "# 定义计算余弦相似度并保存为 CSV 的函数\n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"特征或文件名为空，无法计算余弦相似度。\")\n",
        "        return\n",
        "\n",
        "    print(\"计算余弦相似度矩阵...\")\n",
        "\n",
        "    # 余弦相似度可以通过特征矩阵与其转置的点积计算（假设特征已经归一化）\n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\"相似度矩阵大小: {similarity_matrix.shape}\")\n",
        "\n",
        "    # 将相似度矩阵转换为 DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # 保存为 CSV 文件\n",
        "    df.to_csv(csv_output)\n",
        "    print(f\"余弦相似度矩阵已保存到 {csv_output}\")\n",
        "\n",
        "# 主流程\n",
        "if __name__ == \"__main__\":\n",
        "    # 定义图像文件夹和输出文件路径\n",
        "    image_folder = './Data/commercial'\n",
        "    feature_output = './imgs_vit_commercial.pt'\n",
        "    csv_output = './cosine_similarity_matrix_commercial.csv'\n",
        "\n",
        "    # 确保输出目录存在\n",
        "    os.makedirs(os.path.dirname(feature_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(csv_output), exist_ok=True)\n",
        "\n",
        "    # 提取特征\n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    # 计算余弦相似度并保存为 CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s-jv9yIqs8S",
        "outputId": "f24c5765-6e7b-4bf9-af9a-5ff21cf7f844"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 891M/891M [00:09<00:00, 95.6MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP 模型加载完成。\n",
            "在文件夹 ./Data/commercial 中找到 208 张图像。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/commercial: 100%|██████████| 208/208 [00:06<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征已保存到 ./imgs_vit_commercial.pt\n",
            "计算余弦相似度矩阵...\n",
            "相似度矩阵大小: (208, 208)\n",
            "余弦相似度矩阵已保存到 ./cosine_similarity_matrix_commercial.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# 确保你已经安装了 CLIP 库。如果尚未安装，可以使用以下命令：\n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加载预训练的 CLIP 模型和预处理函数\n",
        "model_name = \"ViT-L/14@336px\"  # 确保该模型名称在 CLIP 库中可用\n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # 设置模型为评估模式\n",
        "print(\"CLIP 模型加载完成。\")\n",
        "\n",
        "# 定义特征提取函数\n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # 获取并按文件名中的数字顺序排序图像路径\n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\"在文件夹 {image_folder} 中找到 {len(image_paths)} 张图像。\")\n",
        "\n",
        "    # 处理每一张图像\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 加载并预处理图像\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # 添加批次维度并移动到设备\n",
        "\n",
        "            # 禁用梯度计算，提高效率\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # 编码图像\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化特征向量\n",
        "\n",
        "            # 将特征移动到 CPU 并添加到列表中\n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"特征已保存到 {output_file}\")\n",
        "    else:\n",
        "        print(f\"在 {image_folder} 中未找到有效的图像\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "# 定义计算余弦相似度并保存为 CSV 的函数\n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"特征或文件名为空，无法计算余弦相似度。\")\n",
        "        return\n",
        "\n",
        "    print(\"计算余弦相似度矩阵...\")\n",
        "\n",
        "    # 余弦相似度可以通过特征矩阵与其转置的点积计算（假设特征已经归一化）\n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\"相似度矩阵大小: {similarity_matrix.shape}\")\n",
        "\n",
        "    # 将相似度矩阵转换为 DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # 计算每列的均值并添加为最后一行\n",
        "    column_means = df.mean(axis=0)  # 计算每列均值\n",
        "    df.loc['Mean', :] = column_means  # 添加均值作为最后一行\n",
        "\n",
        "    # 保存为 CSV 文件\n",
        "    df.to_csv(csv_output)\n",
        "    print(f\"余弦相似度矩阵已保存到 {csv_output}\")\n",
        "\n",
        "    # 找出均值大于 0.8 的列名并保存\n",
        "    high_similarity_columns = column_means[column_means > 0.8].index.tolist()\n",
        "    with open(mean_output, 'w') as f:\n",
        "        for col in high_similarity_columns:\n",
        "            f.write(f\"{col}\\n\")\n",
        "    print(f\"均值大于 0.8 的列名已保存到 {mean_output}\")\n",
        "\n",
        "# 主流程\n",
        "if __name__ == \"__main__\":\n",
        "    # 定义图像文件夹和输出文件路径\n",
        "    image_folder = './Data/commercial'\n",
        "    feature_output = './imgs_vit_commercial.pt'\n",
        "    csv_output = './cosine_similarity_matrix_commercial.csv'\n",
        "    mean_output = './commercial.txt'  # 保存均值大于 0.8 的列名\n",
        "\n",
        "    # 确保输出目录存在\n",
        "    os.makedirs(os.path.dirname(feature_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(csv_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(mean_output), exist_ok=True)\n",
        "\n",
        "    # 提取特征\n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    # 计算余弦相似度并保存为 CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cS6BLN6N9MD",
        "outputId": "1e1baa76-dd25-4588-821e-591d69c564bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP 模型加载完成。\n",
            "在文件夹 ./Data/commercial 中找到 208 张图像。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/commercial: 100%|██████████| 208/208 [00:05<00:00, 36.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征已保存到 ./imgs_vit_commercial.pt\n",
            "计算余弦相似度矩阵...\n",
            "相似度矩阵大小: (208, 208)\n",
            "余弦相似度矩阵已保存到 ./cosine_similarity_matrix_commercial.csv\n",
            "均值大于 0.8 的列名已保存到 ./commercial.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# 确保你已经安装了 CLIP 库。如果尚未安装，可以使用以下命令：\n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加载预训练的 CLIP 模型和预处理函数\n",
        "model_name = \"ViT-L/14@336px\"  # 确保该模型名称在 CLIP 库中可用\n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # 设置模型为评估模式\n",
        "print(\"CLIP 模型加载完成。\")\n",
        "\n",
        "# 从 high_similarity_columns.txt 读取图片文件名\n",
        "def load_high_similarity_images(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        image_filenames = [line.strip() for line in f.readlines()]\n",
        "    return image_filenames\n",
        "\n",
        "# 提取选定图像的特征\n",
        "def extract_selected_features(image_folder, selected_filenames):\n",
        "    image_features_list = []\n",
        "\n",
        "    # 处理每个选定的图像\n",
        "    for image_filename in tqdm(selected_filenames, desc=\"Processing selected images\"):\n",
        "        image_path = os.path.join(image_folder, image_filename)\n",
        "\n",
        "        try:\n",
        "            # 加载并预处理图像\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # 添加批次维度并移动到设备\n",
        "\n",
        "            # 禁用梯度计算，提高效率\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # 编码图像\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化特征向量\n",
        "\n",
        "            # 将特征移动到 CPU 并添加到列表中\n",
        "            image_features_list.append(image_features.cpu())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        return image_features\n",
        "    else:\n",
        "        print(f\"未找到有效的图像\")\n",
        "        return None\n",
        "\n",
        "# 计算特征的均值\n",
        "def compute_feature_mean(features):\n",
        "    if features is None:\n",
        "        print(\"没有有效的特征可用于计算均值。\")\n",
        "        return None\n",
        "    feature_mean = features.mean(dim=0)  # 计算所有图像特征的均值\n",
        "    return feature_mean\n",
        "\n",
        "# 计算余弦相似度\n",
        "def compute_cosine_similarity(feature_mean, all_features):\n",
        "    # 计算特征均值和所有嵌入的余弦相似度\n",
        "    cosine_similarities = torch.matmul(all_features, feature_mean)  # 点积（余弦相似度，假设已经归一化）\n",
        "    return cosine_similarities\n",
        "\n",
        "# 主流程\n",
        "if __name__ == \"__main__\":\n",
        "    # 定义文件路径\n",
        "    image_folder = './Data/commercial'  # 图像所在文件夹路径\n",
        "    high_similarity_file = './commercial.txt'  # 包含高相似度图像的文件路径\n",
        "    feature_file = './imgs_vit_commercial.pt'  # 所有图像的特征文件路径\n",
        "\n",
        "    # 读取 high_similarity_columns.txt 文件中的图像文件名\n",
        "    selected_filenames = load_high_similarity_images(high_similarity_file)\n",
        "\n",
        "    # 提取选定图像的特征\n",
        "    selected_features = extract_selected_features(image_folder, selected_filenames)\n",
        "\n",
        "    # 计算特征均值\n",
        "    feature_mean = compute_feature_mean(selected_features)\n",
        "\n",
        "    if feature_mean is not None:\n",
        "        print(f\"计算得到的特征均值：{feature_mean}\")\n",
        "\n",
        "        # 加载 imgs_vit_commercial.pt 中保存的所有特征\n",
        "        all_features = torch.load(feature_file)\n",
        "        print(f\"加载所有图像的特征，形状为: {all_features.shape}\")\n",
        "\n",
        "        # 计算余弦相似度\n",
        "        cosine_similarities = compute_cosine_similarity(feature_mean, all_features)\n",
        "\n",
        "        # 将相似度转换为 DataFrame 并保存为 CSV\n",
        "        similarity_df = pd.DataFrame(cosine_similarities.numpy(), columns=[\"Cosine Similarity\"])\n",
        "        similarity_df[\"Image Filename\"] = os.listdir(image_folder)  # 添加文件名列\n",
        "\n",
        "        # 按相似度排序并保存到 CSV\n",
        "        similarity_df = similarity_df.sort_values(by=\"Cosine Similarity\", ascending=False)\n",
        "        similarity_df.to_csv('./cosine_similarity_with_mean.csv', index=False)\n",
        "\n",
        "        print(\"余弦相似度计算完成，结果已保存到 cosine_similarity_with_mean.csv\")\n",
        "    else:\n",
        "        print(\"没有有效的图像特征可用于计算均值。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCN-Emu8Qchy",
        "outputId": "9a26584d-8916-4eb4-8f02-c9896388dca3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP 模型加载完成。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing selected images: 100%|██████████| 109/109 [00:02<00:00, 37.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "计算得到的特征均值：tensor([ 2.0981e-02,  3.9764e-02,  1.8112e-02,  2.4582e-02, -1.0033e-02,\n",
            "         1.6434e-02,  1.9516e-02, -2.9358e-02,  3.7231e-02, -3.5980e-02,\n",
            "        -1.5366e-02, -1.6769e-02, -1.6876e-02,  3.1799e-02, -7.8430e-03,\n",
            "         2.4902e-02, -1.6174e-02, -5.2071e-04,  5.3162e-02, -1.9531e-02,\n",
            "        -1.3123e-02,  2.2354e-03, -1.2657e-02,  3.2867e-02, -4.1656e-03,\n",
            "        -1.0452e-02,  3.3722e-02, -3.7441e-03, -4.1138e-02,  1.0544e-02,\n",
            "         4.0436e-03,  1.3916e-02,  4.9477e-03, -2.7313e-02, -1.3763e-02,\n",
            "         3.5828e-02, -3.1036e-02, -2.1881e-02,  5.4693e-04, -1.1475e-02,\n",
            "        -1.2726e-02, -3.0098e-03,  1.5381e-02, -1.7792e-02,  3.4790e-02,\n",
            "         2.1027e-02,  3.0746e-02, -1.0727e-02,  9.2316e-03, -1.5732e-02,\n",
            "         1.8143e-02, -7.8430e-03,  1.4763e-02,  1.8616e-02, -8.7280e-03,\n",
            "        -2.8133e-03,  1.9577e-02,  4.2877e-03, -2.4185e-02, -2.3224e-02,\n",
            "         1.7899e-02, -2.9129e-02,  1.6632e-02,  6.3858e-03,  2.5543e-02,\n",
            "         7.6904e-03, -1.5869e-03,  9.1095e-03,  3.3951e-03, -4.7188e-03,\n",
            "         1.7517e-02, -7.4081e-03,  1.1551e-02, -1.6281e-02,  2.4460e-02,\n",
            "         8.2493e-04, -9.0332e-03,  1.8875e-02,  1.0002e-02,  1.4992e-03,\n",
            "         2.9945e-03,  3.4149e-02, -3.6896e-02,  8.6823e-03,  5.2338e-03,\n",
            "        -2.0966e-02, -3.3752e-02,  2.6276e-02, -2.5024e-02,  3.1311e-02,\n",
            "         2.2263e-02,  1.3794e-02, -2.6875e-03, -2.2858e-02,  1.0086e-02,\n",
            "        -2.8305e-03, -7.5531e-04,  2.2354e-02, -9.0408e-03, -9.2926e-03,\n",
            "        -5.0781e-02,  1.4618e-02,  3.0518e-02, -1.9913e-02, -1.8661e-02,\n",
            "        -1.8555e-02,  7.5417e-03, -1.2505e-02,  7.0686e-03,  4.2801e-03,\n",
            "        -7.7591e-03,  3.6774e-02, -2.8372e-05,  1.1169e-02, -1.7426e-02,\n",
            "         1.7685e-02, -5.4230e-02, -1.1482e-02, -9.1309e-02, -8.0872e-03,\n",
            "        -1.8417e-02,  1.3666e-03,  6.1321e-04, -7.2250e-03, -1.7242e-02,\n",
            "        -2.0081e-02, -4.0680e-02,  1.8661e-02, -3.6346e-02, -1.9470e-02,\n",
            "        -3.1830e-02,  1.6870e-01, -1.1047e-02, -5.0903e-02,  8.6060e-03,\n",
            "        -6.5125e-02, -6.8665e-03, -5.8060e-03, -6.4230e-04, -2.5940e-02,\n",
            "        -6.8626e-03, -4.9095e-03, -1.8326e-02, -7.4234e-03, -3.3844e-02,\n",
            "        -9.3994e-03,  2.0538e-02,  1.1102e-01, -2.7222e-02,  1.3710e-02,\n",
            "        -1.2421e-02, -4.5837e-02, -1.8387e-02,  2.7588e-02,  1.2459e-02,\n",
            "        -7.4081e-03, -3.6041e-02,  2.5864e-02, -2.6505e-02, -1.0963e-02,\n",
            "        -1.3718e-02,  1.9897e-02,  1.1086e-04, -8.1253e-03,  5.4512e-03,\n",
            "        -2.3376e-02, -1.9714e-02,  2.1271e-02, -2.1454e-02,  6.1951e-03,\n",
            "         2.9205e-02, -3.2272e-03, -6.1893e-04,  6.1493e-03, -9.6588e-03,\n",
            "        -4.4037e-02,  1.9638e-02, -3.8574e-02, -2.6035e-03,  1.6617e-02,\n",
            "         6.6528e-02, -3.9406e-03, -3.5801e-03,  1.7838e-02, -2.4612e-02,\n",
            "        -1.2131e-02, -4.9782e-03,  3.7556e-03,  3.8452e-02,  6.1035e-03,\n",
            "         2.6245e-02,  3.1815e-03, -3.0174e-03, -2.3315e-02, -1.8433e-02,\n",
            "        -5.3070e-02, -1.9196e-02,  4.0779e-03, -1.0376e-02, -3.8544e-02,\n",
            "        -5.0783e-04, -2.9877e-02, -6.1417e-03,  5.7716e-03, -2.1606e-02,\n",
            "         3.5187e-02,  6.1913e-03,  8.7967e-03,  2.4765e-02, -1.6296e-02,\n",
            "         1.9207e-03, -3.1376e-03,  1.9608e-02, -1.1391e-02,  1.1131e-02,\n",
            "        -1.1070e-02, -1.2169e-02,  1.9089e-02, -1.2238e-02, -1.4130e-02,\n",
            "         2.0714e-03, -2.0157e-02, -2.8427e-02,  3.8666e-02, -1.5129e-02,\n",
            "        -2.0004e-02,  4.3213e-02, -2.0813e-02,  1.1200e-02, -1.0834e-02,\n",
            "        -1.1833e-02, -3.5889e-02,  5.1575e-03,  9.1095e-03, -3.9459e-02,\n",
            "        -1.4772e-03, -3.8147e-04,  2.6550e-03,  1.3405e-02,  1.4015e-02,\n",
            "        -1.2634e-02, -9.4986e-03,  5.7526e-03,  2.7771e-03, -2.0767e-02,\n",
            "         4.0527e-02, -1.7805e-03,  1.6159e-02,  3.2043e-02, -8.4152e-03,\n",
            "         3.4313e-03, -6.0577e-03,  5.0812e-03,  1.9512e-03,  1.4427e-02,\n",
            "        -2.1332e-02, -8.2321e-03, -2.2293e-02, -9.2468e-03, -2.2202e-02,\n",
            "        -9.7504e-03, -1.4137e-02,  2.8114e-03, -1.0853e-03, -2.3605e-02,\n",
            "         3.4607e-02,  5.8985e-04,  1.7471e-02, -6.1464e-04,  1.6174e-02,\n",
            "        -2.9526e-02,  4.8676e-02, -3.7785e-03,  1.6129e-02, -6.0005e-03,\n",
            "         2.6550e-03, -1.1978e-02,  3.4363e-02, -1.2321e-02,  2.8778e-02,\n",
            "        -1.2573e-02,  7.4339e-04,  1.2985e-02,  1.0239e-02,  4.6783e-02,\n",
            "        -2.8244e-02,  1.7990e-02, -2.2110e-02, -3.8818e-02, -1.1467e-02,\n",
            "         1.1238e-02, -4.9744e-03, -1.8845e-02, -3.5492e-02, -8.1062e-04,\n",
            "        -3.5431e-02, -1.4858e-03, -3.1616e-02,  1.2772e-02, -1.1238e-02,\n",
            "         2.2446e-02,  3.2883e-03,  2.0462e-02,  1.0422e-02,  7.8506e-03,\n",
            "         5.4893e-03, -1.1726e-02,  1.2264e-03, -3.3379e-03,  3.0945e-02,\n",
            "        -2.8824e-02,  7.7629e-04,  3.5706e-03,  4.6997e-03, -2.4815e-03,\n",
            "         2.9694e-02, -4.2969e-02,  4.2328e-02, -1.2039e-02,  5.5267e-02,\n",
            "        -9.4938e-04,  2.2446e-02,  7.6103e-03,  1.2428e-02, -2.1164e-02,\n",
            "        -2.6493e-03, -3.1952e-02, -9.7504e-03, -2.5223e-02, -3.7537e-02,\n",
            "        -6.7368e-03,  5.5389e-03, -7.0534e-03, -5.3673e-03, -1.4023e-02,\n",
            "         3.9917e-02, -2.6062e-02, -1.1909e-02, -3.3875e-02,  7.4158e-03,\n",
            "         1.1292e-02,  3.7422e-03, -1.1009e-02, -2.1439e-02, -5.1361e-02,\n",
            "        -1.5656e-02,  1.0052e-03, -1.2001e-02, -2.9545e-03,  1.6388e-02,\n",
            "         2.1648e-03, -1.1375e-02,  8.1558e-03, -3.5119e-04, -6.3782e-03,\n",
            "        -7.3357e-03,  3.1494e-02,  2.5043e-03,  6.6757e-03, -1.8295e-02,\n",
            "        -1.3031e-02,  2.5635e-03,  4.1016e-02,  3.1830e-02, -1.1345e-02,\n",
            "         2.1286e-03,  7.1167e-02, -4.8218e-03,  3.1647e-02,  5.8460e-04,\n",
            "        -3.3447e-02,  2.4506e-02,  2.4586e-03,  4.2610e-03, -9.8343e-03,\n",
            "        -5.9967e-03,  9.5215e-03,  2.2522e-02, -1.0193e-02, -3.4485e-02,\n",
            "        -3.4885e-03,  8.3618e-03, -7.1678e-03, -2.6657e-02, -2.5513e-02,\n",
            "        -1.4496e-02, -5.3711e-03,  3.4088e-02, -2.3834e-02, -2.5139e-03,\n",
            "         5.1483e-02, -1.6832e-03, -2.5070e-02,  3.2501e-02, -1.5450e-02,\n",
            "        -6.9580e-03, -2.8900e-02, -1.5884e-02,  1.7670e-02,  4.8599e-03,\n",
            "         3.9001e-02, -1.5381e-02, -3.8185e-03,  9.2697e-03,  2.4376e-03,\n",
            "        -2.7603e-02, -2.5177e-02,  2.8015e-02,  1.5091e-02, -6.6338e-03,\n",
            "         3.7079e-03, -4.1809e-02,  3.2654e-03, -4.0771e-01,  1.2993e-02,\n",
            "        -3.6713e-02, -7.5989e-03, -1.8112e-02,  3.6987e-02,  1.0612e-02,\n",
            "         4.3121e-02, -8.8577e-03,  7.0801e-03, -1.3977e-02, -1.2817e-02,\n",
            "        -1.8524e-02, -3.8815e-03,  1.5961e-02,  5.3501e-04,  1.8494e-02,\n",
            "         7.3051e-03,  1.5419e-02, -1.5900e-02,  5.0163e-03,  4.1771e-03,\n",
            "         1.8600e-02,  1.5869e-02, -1.3443e-02,  9.8038e-03,  3.4504e-03,\n",
            "         3.6743e-02,  1.0620e-02,  3.7872e-02, -1.2596e-02,  3.2440e-02,\n",
            "         7.5760e-03,  1.4755e-02,  2.6932e-02,  1.7075e-02, -1.5747e-02,\n",
            "         8.9264e-03, -1.4435e-02,  3.4515e-02,  4.2114e-02,  2.9770e-02,\n",
            "         2.7580e-03, -1.4999e-02, -1.7595e-03,  9.3842e-03, -1.0941e-02,\n",
            "        -3.8727e-02,  5.0659e-03, -1.0147e-02, -7.0374e-02, -8.0688e-02,\n",
            "        -5.8174e-03,  1.3027e-03,  4.0344e-02,  2.8870e-02,  3.9840e-04,\n",
            "        -3.6755e-03, -9.3842e-03, -6.4545e-03, -7.9193e-03,  1.1650e-02,\n",
            "         1.1406e-02, -4.5410e-02,  3.7201e-02, -1.9653e-02,  3.0346e-03,\n",
            "        -5.2261e-03,  1.3092e-02, -1.2596e-02, -4.2267e-02,  4.2297e-02,\n",
            "         1.6266e-02, -1.2695e-02, -9.1476e-03, -1.9745e-02, -6.5536e-03,\n",
            "         7.8964e-03, -3.0365e-02,  1.8661e-02,  1.7303e-02, -5.7793e-03,\n",
            "        -4.0985e-02,  3.0746e-03,  4.5776e-02, -9.3460e-03,  9.9411e-03,\n",
            "         1.9516e-02, -1.8417e-02,  2.8702e-02, -7.3433e-04,  3.9253e-03,\n",
            "         2.1458e-03,  2.5009e-02,  1.5205e-02, -5.8960e-02,  2.8976e-02,\n",
            "        -1.8814e-02, -2.3178e-02,  4.8279e-02, -2.4551e-02, -1.4320e-02,\n",
            "         2.3666e-02,  2.7435e-02,  2.0199e-03, -6.6376e-03,  1.9363e-02,\n",
            "         1.6647e-02,  4.0245e-03,  4.9988e-02,  8.7967e-03, -1.8707e-02,\n",
            "         6.3515e-03,  1.6830e-02,  1.8206e-03, -1.3538e-01, -9.2621e-03,\n",
            "         1.0895e-02, -1.9577e-02,  2.0493e-02,  9.0265e-04, -5.1689e-03,\n",
            "        -1.6037e-02,  7.1411e-02,  1.5884e-02, -3.7201e-02, -1.4938e-02,\n",
            "        -1.1272e-03, -5.2261e-03,  1.7029e-02, -3.0727e-03,  3.5954e-03,\n",
            "        -1.5640e-02, -1.5869e-02,  6.4049e-03,  4.5471e-02, -1.5320e-02,\n",
            "        -4.0100e-02, -3.5370e-02, -1.7365e-02,  4.2847e-02,  1.3847e-02,\n",
            "        -1.0395e-03, -1.3403e-01, -7.2823e-03,  2.0020e-02, -6.3972e-03,\n",
            "        -3.2501e-02,  9.4681e-03, -2.2659e-02,  3.2544e-04, -9.7534e-02,\n",
            "        -1.7120e-02,  2.0370e-02, -1.9516e-02,  8.1558e-03, -2.4155e-02,\n",
            "         2.3163e-02,  3.3630e-02, -2.1606e-02,  9.3765e-03, -3.3951e-03,\n",
            "        -1.2062e-02,  1.7334e-02,  1.8951e-02, -2.1469e-02, -2.1881e-02,\n",
            "         1.3184e-02, -2.0447e-02, -2.7679e-02, -3.8391e-02,  2.0844e-02,\n",
            "         3.8738e-03,  5.5206e-02,  3.4912e-02, -6.0303e-02,  1.3420e-02,\n",
            "        -1.9592e-02, -7.2718e-04, -3.9551e-02,  1.9867e-02, -3.0930e-02,\n",
            "        -1.2840e-02,  1.8997e-02,  1.7197e-02, -1.1650e-02, -6.8626e-03,\n",
            "        -2.2537e-02, -4.7180e-02, -2.2583e-02,  2.5909e-02,  1.7071e-03,\n",
            "        -2.0172e-02, -2.4734e-02,  4.7913e-03,  1.4992e-02, -2.4307e-02,\n",
            "        -2.0142e-02,  1.8778e-03, -1.6052e-02,  1.2222e-02,  3.5645e-02,\n",
            "        -3.8666e-02,  1.6427e-04, -4.8340e-02, -1.6388e-02,  8.2397e-03,\n",
            "        -2.6260e-02, -1.2798e-03,  3.3356e-02,  1.0307e-02, -6.6223e-02,\n",
            "         3.8671e-04, -1.1147e-02,  3.0441e-02,  2.0859e-02,  4.1351e-03,\n",
            "        -1.6663e-02,  1.3153e-02, -1.9623e-02,  5.2704e-02, -1.3351e-02,\n",
            "         2.6413e-02, -2.5131e-02,  4.4922e-02, -1.9445e-03, -3.7537e-03,\n",
            "         1.6922e-02, -7.8659e-03,  1.2383e-02, -2.8046e-02,  4.3994e-01,\n",
            "         1.2901e-02,  2.2400e-02,  2.2812e-02, -3.4561e-03, -1.2083e-03,\n",
            "         1.1513e-02, -1.0622e-04,  7.1068e-03,  2.4689e-02,  4.0550e-03,\n",
            "         4.4342e-02,  2.2873e-02, -1.7273e-02, -1.5556e-02,  1.3062e-01,\n",
            "         4.1260e-02,  1.6663e-02, -9.1362e-04, -1.9882e-02,  1.5198e-02,\n",
            "         8.1558e-03, -9.4910e-03, -1.3268e-02,  2.0660e-02,  4.9866e-02,\n",
            "         3.8166e-03,  1.4107e-02,  2.1362e-04,  2.3254e-02,  6.8741e-03,\n",
            "        -3.3703e-03,  8.5602e-03, -7.7705e-03,  6.1722e-03, -7.3853e-03,\n",
            "         1.8539e-02,  2.4841e-02, -3.0487e-02,  2.3994e-03, -4.1748e-02,\n",
            "         4.9408e-02,  2.5238e-02, -2.2476e-02,  1.1063e-02,  7.9880e-03,\n",
            "         2.3758e-02, -1.2886e-02,  3.8361e-02, -1.9028e-02, -5.5199e-03,\n",
            "         8.3084e-03, -2.6169e-02, -2.7023e-02,  1.9958e-02,  2.7267e-02,\n",
            "        -2.7084e-03,  1.7883e-02,  8.2474e-03, -6.3820e-03,  1.8148e-03,\n",
            "        -1.9012e-02, -1.0139e-02, -6.0349e-03, -2.0638e-03, -3.5477e-04,\n",
            "        -2.3865e-02, -7.3128e-03, -9.3689e-03,  1.9760e-02,  1.7672e-03,\n",
            "        -1.6052e-02, -1.9196e-02, -1.1932e-02, -6.3324e-03,  1.6356e-04,\n",
            "        -9.7370e-04, -2.7802e-02,  3.2410e-02, -1.1792e-01,  9.9716e-03,\n",
            "         6.5247e-02, -2.7313e-03, -1.8890e-02,  7.1297e-03,  1.9531e-02,\n",
            "        -3.7727e-03, -1.3847e-02,  8.6060e-03,  2.8667e-03,  3.0334e-02,\n",
            "        -3.8269e-02, -3.2406e-03, -2.4452e-03, -2.8397e-02,  3.2825e-03,\n",
            "        -1.1681e-02, -2.5955e-02,  1.6384e-03,  2.3212e-03,  3.2444e-03,\n",
            "         2.6505e-02,  3.0746e-02, -5.7755e-03, -1.3145e-02, -4.8462e-02,\n",
            "         2.3636e-02, -1.2188e-03, -1.7441e-02, -1.0048e-02,  3.2867e-02,\n",
            "         1.7481e-03,  1.4191e-02, -3.2635e-03,  1.2695e-02,  5.1537e-03,\n",
            "        -1.4038e-03, -1.2909e-02,  8.5258e-04, -5.7869e-03,  1.5549e-02,\n",
            "         2.6665e-03,  7.6408e-03,  8.2092e-03], dtype=torch.float16)\n",
            "加载所有图像的特征，形状为: torch.Size([208, 768])\n",
            "余弦相似度计算完成，结果已保存到 cosine_similarity_with_mean.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-6-7238caa19f5d>:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  all_features = torch.load(feature_file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# 确保你已经安装了 CLIP 库。如果尚未安装，可以使用以下命令：\n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加载预训练的 CLIP 模型和预处理函数\n",
        "model_name = \"ViT-L/14@336px\"  # 确保该模型名称在 CLIP 库中可用\n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # 设置模型为评估模式\n",
        "print(\"CLIP 模型加载完成。\")\n",
        "\n",
        "# 定义特征提取函数\n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # 获取并按文件名中的数字顺序排序图像路径\n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    print(f\"在文件夹 {image_folder} 中找到 {len(image_paths)} 张图像。\")\n",
        "\n",
        "    # 处理每一张图像\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 加载并预处理图像\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # 添加批次维度并移动到设备\n",
        "\n",
        "            # 禁用梯度计算，提高效率\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # 编码图像\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化特征向量\n",
        "\n",
        "            # 将特征移动到 CPU 并添加到列表中\n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"特征已保存到 {output_file}\")\n",
        "    else:\n",
        "        print(f\"在 {image_folder} 中未找到有效的图像\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "# 定义计算余弦相似度并保存为 CSV 的函数\n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"特征或文件名为空，无法计算余弦相似度。\")\n",
        "        return\n",
        "\n",
        "    print(\"计算余弦相似度矩阵...\")\n",
        "\n",
        "    # 余弦相似度可以通过特征矩阵与其转置的点积计算（假设特征已经归一化）\n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\"相似度矩阵大小: {similarity_matrix.shape}\")\n",
        "\n",
        "    # 将相似度矩阵转换为 DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # 计算每列的均值并添加为最后一行\n",
        "    column_means = df.mean(axis=0)  # 计算每列均值\n",
        "    df.loc['Mean', :] = column_means  # 添加均值作为最后一行\n",
        "\n",
        "    # 保存为 CSV 文件\n",
        "    df.to_csv(csv_output)\n",
        "    print(f\"余弦相似度矩阵已保存到 {csv_output}\")\n",
        "\n",
        "    # 找出均值大于 0.8 的列名并保存\n",
        "    high_similarity_columns = column_means[column_means > 0.8].index.tolist()\n",
        "    with open(mean_output, 'w') as f:\n",
        "        for col in high_similarity_columns:\n",
        "            f.write(f\"{col}\\n\")\n",
        "    print(f\"均值大于 0.8 的列名已保存到 {mean_output}\")\n",
        "\n",
        "# 从 high_similarity_columns.txt 读取图片文件名\n",
        "def load_high_similarity_images(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"文件 {file_path} 不存在。\")\n",
        "        return []\n",
        "    with open(file_path, 'r') as f:\n",
        "        image_filenames = [line.strip() for line in f.readlines()]\n",
        "    print(f\"从 {file_path} 加载了 {len(image_filenames)} 个高相似度图像文件名。\")\n",
        "    return image_filenames\n",
        "\n",
        "# 提取选定图像的特征\n",
        "def extract_selected_features(image_folder, selected_filenames):\n",
        "    image_features_list = []\n",
        "\n",
        "    print(f\"提取选定图像的特征，共 {len(selected_filenames)} 张图像。\")\n",
        "\n",
        "    # 处理每个选定的图像\n",
        "    for image_filename in tqdm(selected_filenames, desc=\"Processing selected images\"):\n",
        "        image_path = os.path.join(image_folder, image_filename)\n",
        "\n",
        "        try:\n",
        "            # 加载并预处理图像\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # 添加批次维度并移动到设备\n",
        "\n",
        "            # 禁用梯度计算，提高效率\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # 编码图像\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化特征向量\n",
        "\n",
        "            # 将特征移动到 CPU 并添加到列表中\n",
        "            image_features_list.append(image_features.cpu())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, './selected_imgs_vit_commercial.pt')  # 可选：保存选定图像的特征\n",
        "        print(f\"选定图像的特征已提取并保存。\")\n",
        "        return image_features\n",
        "    else:\n",
        "        print(f\"未找到有效的选定图像。\")\n",
        "        return None\n",
        "\n",
        "# 计算特征的均值\n",
        "def compute_feature_mean(features):\n",
        "    if features is None:\n",
        "        print(\"没有有效的特征可用于计算均值。\")\n",
        "        return None\n",
        "    feature_mean = features.mean(dim=0)  # 计算所有图像特征的均值\n",
        "    return feature_mean\n",
        "\n",
        "# 计算余弦相似度\n",
        "def compute_cosine_similarity(feature_mean, all_features):\n",
        "    # 计算特征均值和所有嵌入的余弦相似度\n",
        "    cosine_similarities = torch.matmul(all_features, feature_mean)  # 点积（余弦相似度，假设已经归一化）\n",
        "    return cosine_similarities\n",
        "\n",
        "# 主流程\n",
        "def main():\n",
        "    # 定义图像文件夹和输出文件路径\n",
        "    image_folder = './Data/transportation'\n",
        "    feature_output = './imgs_vit_commercial.pt'\n",
        "    csv_output = './cosine_similarity_matrix_commercial.csv'\n",
        "    mean_output = './commercial.txt'  # 保存均值大于 0.8 的列名\n",
        "    high_similarity_file = mean_output  # 与 mean_output 相同\n",
        "    feature_mean_output = './transportation.pt'\n",
        "\n",
        "    # 输出文件夹路径\n",
        "    output_dirs = [\n",
        "        os.path.dirname(feature_output),\n",
        "        os.path.dirname(csv_output),\n",
        "        os.path.dirname(mean_output),\n",
        "        os.path.dirname(feature_mean_output)\n",
        "    ]\n",
        "\n",
        "    # 确保输出目录存在\n",
        "    for dir_path in output_dirs:\n",
        "        if dir_path:  # 避免空字符串\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    # 提取所有图像的特征\n",
        "    features, filenames = extract_features(image_folder, feature_output)\n",
        "\n",
        "    # 计算余弦相似度并保存为 CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output)\n",
        "\n",
        "    # 加载高相似度图像文件名\n",
        "    selected_filenames = load_high_similarity_images(high_similarity_file)\n",
        "\n",
        "    if not selected_filenames:\n",
        "        print(\"没有高相似度的图像文件名可处理。\")\n",
        "        return\n",
        "\n",
        "    # 提取选定图像的特征\n",
        "    selected_features = extract_selected_features(image_folder, selected_filenames)\n",
        "\n",
        "    # 计算特征均值\n",
        "    feature_mean = compute_feature_mean(selected_features)\n",
        "\n",
        "    if feature_mean is not None:\n",
        "        print(f\"计算得到的特征均值：{feature_mean}\")\n",
        "\n",
        "        # Save feature_mean to a .pt file\n",
        "        torch.save(feature_mean, feature_mean_output)\n",
        "        print(f\"Feature mean saved to {feature_mean_output}\")\n",
        "\n",
        "        # 加载 imgs_vit_commercial.pt 中保存的所有特征\n",
        "        if not os.path.exists(feature_output):\n",
        "            print(f\"特征文件 {feature_output} 不存在。无法加载所有图像的特征。\")\n",
        "            return\n",
        "        all_features = torch.load(feature_output)\n",
        "        print(f\"加载所有图像的特征，形状为: {all_features.shape}\")\n",
        "\n",
        "        # 确保所有特征都是归一化的\n",
        "        all_features = all_features / all_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # 计算余弦相似度\n",
        "        cosine_similarities = compute_cosine_similarity(feature_mean, all_features)\n",
        "\n",
        "        # 将相似度转换为 DataFrame 并保存为 CSV\n",
        "        similarity_df = pd.DataFrame({\n",
        "            \"Image Filename\": filenames,\n",
        "            \"Cosine Similarity\": cosine_similarities.numpy()\n",
        "        })\n",
        "\n",
        "        # 按相似度排序并保存到 CSV\n",
        "        similarity_df = similarity_df.sort_values(by=\"Cosine Similarity\", ascending=False)\n",
        "        similarity_df.to_csv('./cosine_similarity_with_mean.csv', index=False)\n",
        "\n",
        "        print(\"余弦相似度计算完成，结果已保存到 cosine_similarity_with_mean.csv\")\n",
        "    else:\n",
        "        print(\"没有有效的图像特征可用于计算均值。\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZrvi5oKLBUe",
        "outputId": "1db95ec5-f82c-404d-f5ef-14e205e6959c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP 模型加载完成。\n",
            "在文件夹 ./Data/transportation 中找到 47 张图像。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/transportation: 100%|██████████| 47/47 [00:01<00:00, 36.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征已保存到 ./imgs_vit_commercial.pt\n",
            "计算余弦相似度矩阵...\n",
            "相似度矩阵大小: (47, 47)\n",
            "余弦相似度矩阵已保存到 ./cosine_similarity_matrix_commercial.csv\n",
            "均值大于 0.8 的列名已保存到 ./commercial.txt\n",
            "从 ./commercial.txt 加载了 1 个高相似度图像文件名。\n",
            "提取选定图像的特征，共 1 张图像。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing selected images: 100%|██████████| 1/1 [00:00<00:00, 36.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "选定图像的特征已提取并保存。\n",
            "计算得到的特征均值：tensor([ 1.9943e-02,  4.9652e-02,  5.6061e-02,  3.1067e-02, -8.9111e-03,\n",
            "         2.6215e-02,  2.4109e-02, -3.8727e-02,  2.9312e-02, -2.2003e-02,\n",
            "        -4.0054e-04, -1.0071e-02, -1.3031e-02,  4.1779e-02,  1.3725e-02,\n",
            "         4.1595e-02, -1.5419e-02,  5.6458e-04,  6.9580e-02,  4.0092e-03,\n",
            "         1.2901e-02,  6.3362e-03, -1.8021e-02,  2.9663e-02, -1.4961e-02,\n",
            "        -1.5472e-02,  5.4443e-02,  8.7357e-03, -1.7670e-02,  5.3177e-03,\n",
            "        -1.0201e-02,  2.8854e-02,  1.1971e-02, -4.0924e-02, -9.9335e-03,\n",
            "         3.5187e-02, -4.5563e-02, -2.2156e-02,  9.3002e-03, -3.8177e-02,\n",
            "        -1.3840e-02,  1.4877e-02,  1.5312e-02, -1.9989e-02,  4.3671e-02,\n",
            "         3.7018e-02,  2.4658e-02, -2.4017e-02, -1.4168e-02,  2.4071e-03,\n",
            "         3.1616e-02, -1.5373e-03,  1.0330e-02,  9.2363e-04,  6.1646e-03,\n",
            "        -5.7640e-03,  3.4119e-02, -1.3359e-02, -4.3701e-02, -3.5950e-02,\n",
            "         2.8610e-02, -8.6899e-03,  1.2825e-02,  1.0544e-02,  1.8143e-02,\n",
            "         1.3748e-02,  1.0315e-02,  1.8112e-02,  7.2670e-04, -1.9312e-03,\n",
            "         9.0714e-03, -1.2146e-02,  8.1635e-03, -2.4658e-02,  2.2583e-02,\n",
            "        -1.2291e-02, -2.1133e-02,  4.3365e-02,  7.3624e-03,  1.1055e-02,\n",
            "        -2.2980e-02,  4.3579e-02, -3.0136e-02,  1.0366e-03, -2.9945e-03,\n",
            "        -1.4587e-02, -2.8122e-02,  3.2135e-02, -4.4220e-02,  3.9368e-02,\n",
            "         8.9874e-03,  3.7251e-03, -5.9814e-03, -9.7504e-03,  1.8631e-02,\n",
            "        -1.8864e-03,  5.9700e-03,  1.0559e-02,  6.9084e-03,  3.3245e-03,\n",
            "        -5.6610e-02,  5.1651e-03,  2.3880e-02, -2.1149e-02, -1.0170e-02,\n",
            "        -2.0691e-02,  9.6207e-03, -1.7426e-02, -3.8185e-03,  1.3329e-02,\n",
            "        -5.0011e-03,  4.3304e-02,  2.5986e-02, -6.5575e-03, -3.2013e-02,\n",
            "         3.0731e-02, -4.0771e-02, -1.2436e-02, -7.5378e-02,  4.2191e-03,\n",
            "        -3.9490e-02,  4.7646e-03, -5.3177e-03, -4.9858e-03, -1.2230e-02,\n",
            "        -1.9775e-02, -3.3386e-02,  1.3779e-02, -3.5492e-02, -3.3997e-02,\n",
            "        -3.9215e-02,  1.7981e-01,  1.4210e-03, -4.9164e-02,  5.4512e-03,\n",
            "        -6.4514e-02, -5.5122e-03, -8.2016e-03,  3.8834e-03, -3.3051e-02,\n",
            "         3.3340e-03, -1.9730e-02, -2.5162e-02,  4.4322e-04, -4.6173e-02,\n",
            "        -1.5541e-02,  5.1971e-02,  8.8379e-02, -2.5726e-02,  8.8806e-03,\n",
            "        -4.1695e-03, -4.0222e-02, -2.4811e-02,  2.9556e-02,  1.5312e-02,\n",
            "        -1.2581e-02, -4.6814e-02,  3.0426e-02, -3.5400e-02, -1.7471e-02,\n",
            "        -3.9101e-03,  1.4015e-02, -1.3023e-02, -1.3947e-02, -2.3479e-03,\n",
            "        -2.8198e-02, -2.3117e-03,  3.2135e-02, -3.8391e-02,  1.0643e-02,\n",
            "         1.6861e-02,  6.1417e-03,  1.2260e-02,  2.9163e-03, -2.1935e-03,\n",
            "        -4.0771e-02,  1.4740e-02, -4.6967e-02, -7.2327e-03,  4.1260e-02,\n",
            "         5.7037e-02,  2.2817e-04, -3.1494e-02,  2.1759e-02, -2.7199e-03,\n",
            "        -6.4969e-05, -2.4757e-03, -2.2755e-03,  2.9373e-02,  6.0654e-03,\n",
            "         3.4668e-02,  8.3313e-03,  4.8981e-03, -1.8448e-02, -9.4070e-03,\n",
            "        -4.5349e-02, -1.9257e-02,  1.0910e-02, -9.6207e-03, -4.7943e-02,\n",
            "         2.0645e-02, -3.9185e-02, -8.3237e-03,  4.0321e-03, -3.5339e-02,\n",
            "         2.9022e-02, -1.8425e-03,  1.6193e-03,  4.5380e-02, -1.5572e-02,\n",
            "         1.1787e-02,  1.5541e-02,  1.9821e-02, -2.3056e-02,  1.8753e-02,\n",
            "        -8.6451e-04, -2.1042e-02,  1.2779e-02, -5.5313e-03, -5.5122e-03,\n",
            "         3.8147e-04, -2.7496e-02, -2.0828e-02,  4.1107e-02, -2.1469e-02,\n",
            "        -1.6083e-02,  3.4821e-02, -2.4471e-03,  5.9052e-03, -8.1635e-03,\n",
            "        -1.3008e-02, -1.6891e-02,  1.4877e-02,  3.6163e-02, -2.8793e-02,\n",
            "         6.6185e-03, -5.5923e-03,  1.1387e-03,  1.8387e-02,  2.5848e-02,\n",
            "        -9.6970e-03, -8.4000e-03, -2.4521e-02,  1.7365e-02, -1.9058e-02,\n",
            "         4.1321e-02,  1.4931e-02,  2.1988e-02,  3.1250e-02, -3.7628e-02,\n",
            "         3.4046e-03, -1.4496e-02,  5.6381e-03,  6.4011e-03,  1.9653e-02,\n",
            "        -3.8177e-02, -1.6769e-02, -2.6489e-02, -1.5503e-02,  3.3398e-03,\n",
            "        -1.7273e-02, -3.8147e-02,  2.0447e-02, -2.1332e-02, -2.1790e-02,\n",
            "         5.0018e-02,  3.5934e-03,  3.6240e-03,  1.5884e-02, -4.8923e-04,\n",
            "        -3.7048e-02,  5.1849e-02,  1.0498e-02,  1.4084e-02,  6.4659e-03,\n",
            "         1.1208e-02,  3.4771e-03,  4.1595e-02, -8.9264e-03,  5.9166e-03,\n",
            "        -2.5482e-02,  1.4412e-02,  5.5542e-03,  3.6987e-02,  4.2847e-02,\n",
            "        -3.3783e-02,  1.7868e-02, -3.3264e-02, -3.8544e-02, -4.7150e-03,\n",
            "        -4.7798e-03, -6.4163e-03, -2.1851e-02, -2.2797e-02, -1.9928e-02,\n",
            "        -6.9336e-02, -3.7804e-03, -5.1819e-02, -1.0132e-02, -2.1194e-02,\n",
            "         2.8854e-02, -8.2703e-03,  1.8738e-02, -2.4090e-03,  4.6730e-03,\n",
            "         9.5978e-03, -1.1070e-02,  1.1854e-03, -1.6052e-02,  4.9164e-02,\n",
            "        -2.7985e-02, -7.0305e-03,  4.6997e-03, -4.2496e-03,  4.4250e-03,\n",
            "         2.6474e-02, -4.2542e-02,  3.5126e-02, -1.3306e-02,  6.1676e-02,\n",
            "        -1.1528e-02,  3.6072e-02,  1.8860e-02,  2.5024e-02, -1.9012e-02,\n",
            "        -2.3346e-02, -5.0842e-02, -6.8245e-03, -1.1169e-02, -1.7624e-02,\n",
            "        -8.5068e-03, -5.3673e-03,  1.1398e-02, -3.4618e-03, -1.4465e-02,\n",
            "         5.4321e-02, -3.4424e-02, -1.4633e-02, -5.9845e-02,  4.1771e-03,\n",
            "         1.9760e-02, -3.8314e-04,  4.5204e-03, -3.0731e-02, -5.8319e-02,\n",
            "        -1.1742e-02, -2.1210e-03, -3.8422e-02, -4.1771e-03,  8.1406e-03,\n",
            "        -1.4565e-02,  4.1466e-03,  1.2108e-02,  1.9464e-03, -1.6052e-02,\n",
            "        -1.1345e-02,  2.4963e-02,  7.9956e-03, -1.4206e-02, -1.9806e-02,\n",
            "        -6.2523e-03,  1.0284e-02,  3.4790e-02,  3.7689e-02, -3.5553e-03,\n",
            "         2.3895e-02,  6.8726e-02,  4.5586e-03,  3.3600e-02,  5.3062e-03,\n",
            "        -4.8218e-02,  2.9968e-02,  1.3840e-02,  1.7761e-02,  2.1149e-02,\n",
            "        -2.0340e-02,  1.1406e-02,  2.9449e-02, -2.9892e-02, -6.0822e-02,\n",
            "        -7.1259e-03,  1.1597e-02,  1.6427e-04, -2.1652e-02, -4.4586e-02,\n",
            "        -2.2766e-02, -2.8336e-02,  4.1809e-02, -1.5312e-02,  7.2136e-03,\n",
            "         3.4485e-02,  6.4516e-04, -1.4328e-02,  4.1199e-02, -1.4359e-02,\n",
            "         7.9041e-03, -1.2611e-02, -2.0142e-02,  2.4750e-02,  1.7441e-02,\n",
            "         2.5101e-02, -1.5854e-02, -1.4931e-02,  5.0659e-03, -4.2510e-04,\n",
            "        -4.2542e-02, -2.6749e-02,  3.6652e-02,  1.2955e-02, -1.6434e-02,\n",
            "         4.2076e-03, -3.4119e-02, -8.9493e-03, -4.2456e-01, -4.7913e-03,\n",
            "        -3.1036e-02, -1.2985e-02, -8.0338e-03,  2.6794e-02,  1.6693e-02,\n",
            "         4.5441e-02, -2.4918e-02,  6.2904e-03, -1.6785e-02, -6.2332e-03,\n",
            "        -2.5009e-02, -8.3542e-03,  2.9205e-02,  6.3362e-03,  1.0330e-02,\n",
            "         1.5869e-02,  2.0386e-02, -2.3560e-02,  1.9989e-02,  6.8283e-03,\n",
            "         3.4698e-02,  2.0096e-02, -1.8478e-02,  1.6571e-02, -3.0727e-03,\n",
            "         3.7201e-02,  4.7836e-03,  4.7363e-02, -2.7878e-02,  2.2552e-02,\n",
            "         1.1528e-02, -6.1188e-03,  2.8122e-02,  3.3142e-02, -2.1973e-02,\n",
            "         2.5654e-03, -2.4918e-02,  6.1890e-02,  3.7415e-02,  2.6016e-02,\n",
            "        -8.3237e-03, -1.4824e-02,  4.3983e-03,  1.5259e-02, -2.2339e-02,\n",
            "        -4.2419e-02,  2.5696e-02, -1.9165e-02, -6.2683e-02, -5.8960e-02,\n",
            "         4.4594e-03,  1.5541e-02,  5.8807e-02,  8.0643e-03, -7.8487e-04,\n",
            "        -9.7733e-03,  3.0861e-03,  5.3120e-04, -7.8964e-03,  1.5434e-02,\n",
            "         2.9697e-03, -2.3819e-02,  3.4515e-02, -2.6932e-02, -1.1806e-03,\n",
            "        -7.4997e-03,  1.8707e-02,  1.4057e-03, -6.4575e-02,  5.5084e-02,\n",
            "         9.5901e-03, -1.1986e-02,  4.5943e-04, -2.6138e-02, -8.9550e-04,\n",
            "         2.6749e-02, -2.7695e-02,  1.7914e-02,  3.9795e-02, -2.5883e-03,\n",
            "        -3.3966e-02, -3.5152e-03,  4.4769e-02, -3.4142e-03,  3.8648e-04,\n",
            "         2.7100e-02, -1.8219e-02,  9.5215e-03, -6.6900e-04,  4.0293e-04,\n",
            "        -1.4084e-02,  1.6953e-02,  9.8343e-03, -4.1290e-02,  2.2034e-02,\n",
            "        -2.2415e-02, -2.5543e-02,  3.4668e-02, -4.6356e-02, -9.3536e-03,\n",
            "        -8.1635e-03,  3.9093e-02,  6.6299e-03, -1.5541e-02,  2.7496e-02,\n",
            "         8.0566e-03, -1.6953e-02,  4.8920e-02,  5.1193e-03, -3.2379e-02,\n",
            "        -1.7654e-02,  2.0721e-02, -1.2527e-02, -1.5063e-01, -1.8823e-04,\n",
            "         6.2675e-03, -2.4429e-02,  1.7090e-02,  1.7349e-02, -2.1027e-02,\n",
            "        -9.9869e-03,  5.9662e-02,  1.7349e-02, -4.2419e-02,  1.1726e-02,\n",
            "        -1.7715e-02, -9.5901e-03,  2.6932e-02, -1.0176e-03, -1.3618e-02,\n",
            "        -1.0643e-02, -2.0798e-02,  2.3941e-02,  2.1667e-02, -2.5009e-02,\n",
            "        -2.2751e-02, -4.4830e-02, -2.7298e-02,  5.7648e-02,  2.6718e-02,\n",
            "        -6.8521e-04, -1.4819e-01, -2.0767e-02,  1.5396e-02, -1.4847e-02,\n",
            "        -4.1779e-02, -1.1108e-02, -2.6398e-02,  3.2604e-05, -9.3750e-02,\n",
            "        -2.8824e-02,  4.1107e-02, -2.2781e-02,  1.0994e-02, -4.6600e-02,\n",
            "         3.3722e-02,  4.0222e-02, -1.1726e-02,  1.7120e-02, -5.9509e-03,\n",
            "        -2.8229e-02,  2.5120e-03,  1.4915e-02, -2.7817e-02, -7.6714e-03,\n",
            "         1.0811e-02, -1.7288e-02, -3.7628e-02, -3.6255e-02,  2.2842e-02,\n",
            "        -7.4577e-03,  5.5695e-02,  3.5431e-02, -5.5511e-02, -4.2458e-03,\n",
            "        -2.1973e-02, -9.4528e-03, -5.7770e-02,  1.1520e-02, -2.1439e-02,\n",
            "        -1.7776e-02,  1.7853e-02, -1.0529e-03, -2.5223e-02, -1.9272e-02,\n",
            "        -3.4546e-02, -4.6539e-02, -1.7120e-02,  2.9266e-02,  7.7667e-03,\n",
            "        -1.5366e-02, -3.3142e-02,  2.4979e-02,  2.4368e-02, -3.9062e-02,\n",
            "        -1.1795e-02,  1.2642e-02,  1.1009e-02,  1.2802e-02,  2.9404e-02,\n",
            "        -4.6387e-02, -6.7749e-03, -5.9570e-02, -2.3529e-02,  1.8280e-02,\n",
            "        -2.6169e-02, -5.6076e-03,  2.9617e-02,  1.5053e-02, -7.1899e-02,\n",
            "         4.5738e-03, -4.6349e-03,  2.7985e-02,  1.7960e-02,  5.4283e-03,\n",
            "        -2.4673e-02,  6.6719e-03, -4.9400e-03,  6.2439e-02, -2.1088e-02,\n",
            "         1.5839e-02, -5.0201e-03,  4.3671e-02, -1.0658e-02, -2.0813e-02,\n",
            "         2.0569e-02, -1.3199e-03,  2.5330e-02, -1.8631e-02,  4.5776e-01,\n",
            "         7.6065e-03,  1.3618e-02,  1.1185e-02,  1.1467e-02, -1.4847e-02,\n",
            "         2.4185e-02,  1.7578e-02,  1.1078e-02,  1.8799e-02,  3.9139e-03,\n",
            "         4.0680e-02,  2.2629e-02, -2.1698e-02, -1.3794e-02,  1.2805e-01,\n",
            "         4.2542e-02,  2.4963e-02,  9.8801e-03, -2.0142e-02,  2.1988e-02,\n",
            "         3.5553e-03,  1.4099e-02, -3.1982e-02,  5.6305e-03,  6.8481e-02,\n",
            "         3.1967e-03, -7.4654e-03,  5.2309e-04,  3.2715e-02, -2.2736e-02,\n",
            "        -1.0803e-02,  1.3992e-02, -2.9011e-03,  1.8677e-02,  4.8614e-04,\n",
            "         2.1500e-02,  2.1271e-02, -3.5645e-02,  2.1194e-02, -3.3844e-02,\n",
            "         5.7098e-02,  3.5400e-02, -1.0345e-02,  2.5040e-02,  1.2245e-03,\n",
            "         1.6769e-02, -1.8799e-02,  5.5023e-02, -1.6251e-02, -2.4994e-02,\n",
            "         1.4633e-02, -3.1708e-02, -2.0111e-02,  2.3407e-02,  1.8448e-02,\n",
            "         3.4392e-05,  1.2604e-02,  2.0294e-02,  2.0294e-02,  3.6373e-03,\n",
            "        -1.2779e-02, -7.1259e-03, -3.4271e-02, -1.1169e-02,  2.4384e-02,\n",
            "        -2.3148e-02, -1.1909e-02, -1.4900e-02,  1.2192e-02,  4.5319e-03,\n",
            "        -3.9825e-02, -1.2650e-02, -1.8723e-02, -2.1935e-03, -2.1805e-02,\n",
            "        -4.9934e-03, -4.5197e-02,  2.8473e-02, -1.3391e-01,  3.9864e-03,\n",
            "         6.7810e-02, -6.9275e-03, -2.1042e-02,  8.9111e-03,  1.0567e-02,\n",
            "         8.5449e-03, -2.6093e-02, -1.5747e-02, -4.9973e-03,  4.5319e-02,\n",
            "        -3.5919e-02, -1.7090e-02, -6.3095e-03, -3.9024e-03,  8.0948e-03,\n",
            "         5.0664e-05, -1.3290e-02,  1.4618e-02, -2.0615e-02,  1.1528e-02,\n",
            "         2.0325e-02,  2.6260e-02, -1.4275e-02, -1.7700e-02, -4.9225e-02,\n",
            "         1.5450e-03, -4.9515e-03, -2.3842e-03, -2.8717e-02,  4.6265e-02,\n",
            "         7.1602e-03,  5.9471e-03, -5.5733e-03, -7.0915e-03,  8.0032e-03,\n",
            "        -1.8711e-03, -2.2858e-02, -8.7967e-03,  1.7227e-02,  1.4778e-02,\n",
            "        -8.7967e-03,  2.4918e-02,  5.3673e-03], dtype=torch.float16)\n",
            "Feature mean saved to ./transportation.pt\n",
            "加载所有图像的特征，形状为: torch.Size([47, 768])\n",
            "余弦相似度计算完成，结果已保存到 cosine_similarity_with_mean.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-19-20053843678c>:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  all_features = torch.load(feature_output)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure you have installed the CLIP library. If not, install it using:\n",
        "# pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the pre-trained CLIP model and preprocessing function\n",
        "model_name = \"ViT-L/14@336px\"  # Ensure this model name is available in the CLIP library\n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "print(\"CLIP model loaded successfully.\")\n",
        "\n",
        "# Define the feature extraction function\n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # Get and sort image paths. Adjust sorting if filenames are not purely numeric.\n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: os.path.splitext(os.path.basename(x))[0]  # Sort by filename without extension\n",
        "    )\n",
        "\n",
        "    print(f\"Found {len(image_paths)} images in folder: {image_folder}\")\n",
        "\n",
        "    # Process each image\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {os.path.basename(image_folder)}\"):\n",
        "        try:\n",
        "            # Load and preprocess image\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "            # Disable gradient calculation for efficiency\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)  # Encode image\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # Normalize feature vector\n",
        "\n",
        "            # Move features to CPU and append to list\n",
        "            image_features_list.append(image_features.cpu())\n",
        "            image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    # Concatenate all features into a single tensor\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # Shape: [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"Features saved to {output_file}\")\n",
        "    else:\n",
        "        print(f\"No valid images found in {image_folder}\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "# Define the function to compute and save cosine similarity matrix (optional)\n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output, mean_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"Features or filenames are empty. Cannot compute cosine similarity.\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculating cosine similarity matrix...\")\n",
        "\n",
        "    # Cosine similarity via dot product (features are already normalized)\n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # Shape: [num_images, num_images]\n",
        "\n",
        "    print(f\"Similarity matrix size: {similarity_matrix.shape}\")\n",
        "\n",
        "    # Convert similarity matrix to DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # Calculate mean of each column and add as the last row\n",
        "    column_means = df.mean(axis=0)  # Mean of each column\n",
        "    df.loc['Mean', :] = column_means  # Add mean as the last row\n",
        "\n",
        "    # Save the similarity matrix to CSV\n",
        "    df.to_csv(csv_output)\n",
        "    print(f\"Cosine similarity matrix saved to {csv_output}\")\n",
        "\n",
        "    # Identify and save column names with mean similarity > 0.8\n",
        "    high_similarity_columns = column_means[column_means > 0.8].index.tolist()\n",
        "    with open(mean_output, 'w') as f:\n",
        "        for col in high_similarity_columns:\n",
        "            f.write(f\"{col}\\n\")\n",
        "    print(f\"Column names with mean similarity > 0.8 saved to {mean_output}\")\n",
        "\n",
        "# Define the function to compute the mean feature\n",
        "def compute_feature_mean(features):\n",
        "    if features is None:\n",
        "        print(\"No valid features available to compute mean.\")\n",
        "        return None\n",
        "    feature_mean = features.mean(dim=0)  # Compute mean across all image features\n",
        "    return feature_mean\n",
        "\n",
        "# Main processing function\n",
        "def main():\n",
        "    # Define the root data directory\n",
        "    data_root = './Data'\n",
        "\n",
        "    # Define the list of folders to process\n",
        "    folders_to_process = [\n",
        "        'civic, governmental and cultural',\n",
        "        'education',\n",
        "        'industrial',\n",
        "        'sports and recreation',\n",
        "        'commercial',\n",
        "        'health care',\n",
        "        'outdoors and natural',\n",
        "        'transportation',\n",
        "        'hotel',\n",
        "        'residential'\n",
        "    ]\n",
        "\n",
        "    # Define directories to save features and mean features\n",
        "    features_dir = './features'\n",
        "    mean_features_dir = './mean_features'\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(features_dir, exist_ok=True)\n",
        "    os.makedirs(mean_features_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate over each folder and process\n",
        "    for folder in folders_to_process:\n",
        "        folder_path = os.path.join(data_root, folder)\n",
        "\n",
        "        # Check if the folder exists\n",
        "        if not os.path.isdir(folder_path):\n",
        "            print(f\"Folder {folder_path} does not exist. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing folder: {folder}\")\n",
        "\n",
        "        # Define output file paths\n",
        "        feature_output = os.path.join(features_dir, f\"{folder.replace(' ', '_')}_features.pt\")\n",
        "        mean_output = os.path.join(mean_features_dir, f\"{folder.replace(' ', '_')}_mean.pt\")\n",
        "\n",
        "        # Extract features\n",
        "        features, filenames = extract_features(folder_path, feature_output)\n",
        "\n",
        "        if features is None:\n",
        "            print(f\"Skipping mean computation for {folder} due to no features.\")\n",
        "            continue\n",
        "\n",
        "        # Compute mean feature\n",
        "        feature_mean = compute_feature_mean(features)\n",
        "\n",
        "        if feature_mean is not None:\n",
        "            # Save the mean feature\n",
        "            torch.save(feature_mean, mean_output)\n",
        "            print(f\"Mean feature saved to {mean_output}\")\n",
        "        else:\n",
        "            print(f\"Failed to compute mean feature for {folder}.\")\n",
        "\n",
        "        # Optional: Compute and save cosine similarity matrix\n",
        "        # Uncomment the following lines if you want to compute similarity matrices\n",
        "        \"\"\"\n",
        "        csv_output = os.path.join(features_dir, f\"{folder.replace(' ', '_')}_cosine_similarity.csv\")\n",
        "        high_similarity_output = os.path.join(features_dir, f\"{folder.replace(' ', '_')}_high_similarity.txt\")\n",
        "        compute_and_save_cosine_similarity(features, filenames, csv_output, high_similarity_output)\n",
        "        \"\"\"\n",
        "\n",
        "    print(\"\\nAll specified folders have been processed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-35cPWfpOf-P",
        "outputId": "6c91eee4-c0eb-4216-8b67-ef5cf02a9725"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n",
            "CLIP model loaded successfully.\n",
            "\n",
            "Processing folder: civic, governmental and cultural\n",
            "Found 36 images in folder: ./Data/civic, governmental and cultural\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing civic, governmental and cultural: 100%|██████████| 36/36 [00:01<00:00, 33.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/civic,_governmental_and_cultural_features.pt\n",
            "Mean feature saved to ./mean_features/civic,_governmental_and_cultural_mean.pt\n",
            "\n",
            "Processing folder: education\n",
            "Found 99 images in folder: ./Data/education\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing education: 100%|██████████| 99/99 [00:02<00:00, 36.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/education_features.pt\n",
            "Mean feature saved to ./mean_features/education_mean.pt\n",
            "\n",
            "Processing folder: industrial\n",
            "Found 145 images in folder: ./Data/industrial\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing industrial: 100%|██████████| 145/145 [00:03<00:00, 36.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/industrial_features.pt\n",
            "Mean feature saved to ./mean_features/industrial_mean.pt\n",
            "\n",
            "Processing folder: sports and recreation\n",
            "Found 28 images in folder: ./Data/sports and recreation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing sports and recreation: 100%|██████████| 28/28 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/sports_and_recreation_features.pt\n",
            "Mean feature saved to ./mean_features/sports_and_recreation_mean.pt\n",
            "\n",
            "Processing folder: commercial\n",
            "Found 208 images in folder: ./Data/commercial\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing commercial: 100%|██████████| 208/208 [00:05<00:00, 36.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/commercial_features.pt\n",
            "Mean feature saved to ./mean_features/commercial_mean.pt\n",
            "\n",
            "Processing folder: health care\n",
            "Found 27 images in folder: ./Data/health care\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing health care: 100%|██████████| 27/27 [00:00<00:00, 35.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/health_care_features.pt\n",
            "Mean feature saved to ./mean_features/health_care_mean.pt\n",
            "\n",
            "Processing folder: outdoors and natural\n",
            "Found 38 images in folder: ./Data/outdoors and natural\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing outdoors and natural: 100%|██████████| 38/38 [00:01<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/outdoors_and_natural_features.pt\n",
            "Mean feature saved to ./mean_features/outdoors_and_natural_mean.pt\n",
            "\n",
            "Processing folder: transportation\n",
            "Found 47 images in folder: ./Data/transportation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing transportation: 100%|██████████| 47/47 [00:01<00:00, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/transportation_features.pt\n",
            "Mean feature saved to ./mean_features/transportation_mean.pt\n",
            "\n",
            "Processing folder: hotel\n",
            "Found 30 images in folder: ./Data/hotel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing hotel: 100%|██████████| 30/30 [00:00<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/hotel_features.pt\n",
            "Mean feature saved to ./mean_features/hotel_mean.pt\n",
            "\n",
            "Processing folder: residential\n",
            "Found 335 images in folder: ./Data/residential\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing residential: 100%|██████████| 335/335 [00:09<00:00, 35.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to ./features/residential_features.pt\n",
            "Mean feature saved to ./mean_features/residential_mean.pt\n",
            "\n",
            "All specified folders have been processed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加载预训练的 CLIP 模型和预处理函数\n",
        "model_name = \"ViT-L/14@336px\"  # 确保该模型名称在 CLIP 库中可用\n",
        "print(f\"Loading CLIP model: {model_name}...\")\n",
        "model, preprocess = clip.load(model_name, device=device)\n",
        "model.eval()  # 设置模型为评估模式\n",
        "print(\"CLIP 模型加载完成。\")\n",
        "\n",
        "# 定义特征提取函数\n",
        "def extract_features(image_folders, output_file, num_images=10):\n",
        "    image_features_list = []\n",
        "    image_filenames = []\n",
        "\n",
        "    # 处理每个文件夹\n",
        "    for image_folder in image_folders:\n",
        "        # 获取图像路径并按文件名中的数字顺序排序\n",
        "        image_paths = sorted(\n",
        "            [\n",
        "                os.path.join(image_folder, img)\n",
        "                for img in os.listdir(image_folder)\n",
        "                if img.lower().endswith(('.jpg', '.png'))\n",
        "            ],\n",
        "            key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "        )\n",
        "\n",
        "        # 如果图像数量不足 num_images, 选取所有图像\n",
        "        if len(image_paths) > num_images:\n",
        "            image_paths = random.sample(image_paths, num_images)  # 随机选择 num_images 张图像\n",
        "\n",
        "        print(f\"从文件夹 {image_folder} 中选择 {len(image_paths)} 张图像。\")\n",
        "\n",
        "        # 处理每一张图像\n",
        "        for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "            try:\n",
        "                # 加载并预处理图像\n",
        "                image = Image.open(image_path).convert(\"RGB\")\n",
        "                image_input = preprocess(image).unsqueeze(0).to(device)  # 添加批次维度并移动到设备\n",
        "\n",
        "                # 禁用梯度计算，提高效率\n",
        "                with torch.no_grad():\n",
        "                    image_features = model.encode_image(image_input)  # 编码图像\n",
        "                    image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化特征向量\n",
        "\n",
        "                # 将特征移动到 CPU 并添加到列表中\n",
        "                image_features_list.append(image_features.cpu())\n",
        "                image_filenames.append(os.path.basename(image_path))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # [num_images, feature_dim]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"特征已保存到 {output_file}\")\n",
        "    else:\n",
        "        print(f\"未找到有效的图像\")\n",
        "        return None, None\n",
        "\n",
        "    return image_features, image_filenames\n",
        "\n",
        "# 定义计算余弦相似度并保存为 CSV 的函数\n",
        "def compute_and_save_cosine_similarity(features, filenames, csv_output):\n",
        "    if features is None or filenames is None:\n",
        "        print(\"特征或文件名为空，无法计算余弦相似度。\")\n",
        "        return\n",
        "\n",
        "    print(\"计算余弦相似度矩阵...\")\n",
        "\n",
        "    # 余弦相似度可以通过特征矩阵与其转置的点积计算（假设特征已经归一化）\n",
        "    similarity_matrix = torch.mm(features, features.t()).numpy()  # [num_images, num_images]\n",
        "\n",
        "    print(f\"相似度矩阵大小: {similarity_matrix.shape}\")\n",
        "\n",
        "    # 将相似度矩阵转换为 DataFrame\n",
        "    df = pd.DataFrame(similarity_matrix, index=filenames, columns=filenames)\n",
        "\n",
        "    # 保存为 CSV 文件\n",
        "    df.to_csv(csv_output)\n",
        "    print(f\"余弦相似度矩阵已保存到 {csv_output}\")\n",
        "\n",
        "# 主流程\n",
        "if __name__ == \"__main__\":\n",
        "    # 定义文件夹路径和输出文件路径\n",
        "    image_folders = ['./Data/commercial', './Data/residential', './Data/industrial']  # 可添加更多文件夹\n",
        "    feature_output = './features/combined_features.pt'\n",
        "    csv_output = './cosine_similarity_combined.csv'\n",
        "\n",
        "    # 确保输出目录存在\n",
        "    os.makedirs(os.path.dirname(feature_output), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(csv_output), exist_ok=True)\n",
        "\n",
        "    # 提取特征\n",
        "    features, filenames = extract_features(image_folders, feature_output, num_images=10)\n",
        "\n",
        "    # 计算余弦相似度并保存为 CSV\n",
        "    compute_and_save_cosine_similarity(features, filenames, csv_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0m8I9s0LLB",
        "outputId": "f8729266-3b5f-4d10-d1b6-8eaa011f8154"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CLIP model: ViT-L/14@336px...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 891M/891M [01:41<00:00, 9.19MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP 模型加载完成。\n",
            "从文件夹 ./Data/commercial 中选择 10 张图像。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/commercial: 100%|██████████| 10/10 [00:01<00:00,  7.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "从文件夹 ./Data/residential 中选择 10 张图像。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/residential: 100%|██████████| 10/10 [00:00<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "从文件夹 ./Data/industrial 中选择 10 张图像。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Data/industrial: 100%|██████████| 10/10 [00:00<00:00, 35.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征已保存到 ./features/combined_features.pt\n",
            "计算余弦相似度矩阵...\n",
            "相似度矩阵大小: (30, 30)\n",
            "余弦相似度矩阵已保存到 ./cosine_similarity_combined.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}