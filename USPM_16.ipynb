{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOvrdNYkIQRrKwpQW94rVu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/USPM_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "03H5Z8DMhwLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdfad53-7ada-478a-c0b8-14ac7e866db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ounC9wqocge-",
        "outputId": "7376c76b-d376-400a-b745-2dfdcef1bd4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.6.15)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import collections\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, \\\n",
        "    top_k_accuracy_score, \\\n",
        "    mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from transformers import AutoModel\n",
        "from torch_geometric.nn import GATConv, GCNConv\n",
        "from collections import Counter\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "\n",
        "class SVFeatureBlock(nn.Module):\n",
        "    def __init__(self, input_size=512, hidden_size=512, mode='mean'):\n",
        "        super(SVFeatureBlock, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        if mode == 'lstm':\n",
        "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "            nn.init.orthogonal_(self.lstm.weight_ih_l0)\n",
        "            nn.init.orthogonal_(self.lstm.weight_hh_l0)\n",
        "        elif mode == 'bi-lstm':\n",
        "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True,\n",
        "                                bidirectional=True)\n",
        "        elif self.mode == \"gru\":\n",
        "            self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "        elif mode == 'rnn':\n",
        "            self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "\n",
        "    def forward(self, sv):\n",
        "        sv_list = []\n",
        "        for x_tmp in sv:\n",
        "            if self.mode == \"mean\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.mean(x_tmp, dim=0)\n",
        "            elif self.mode == \"sum\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.sum(x_tmp, dim=0)\n",
        "            elif self.mode == \"max\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.max(x_tmp, dim=0).values\n",
        "            elif self.mode == \"lstm\":\n",
        "                out_put, (h_n, c_n) = self.lstm(x_tmp.view(1, -1, self.input_size))\n",
        "                out_put = out_put[:, -1, :]\n",
        "                out_put = torch.squeeze(out_put)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            sv_list.append(out_put)\n",
        "        x = torch.stack(sv_list)  # 拼接,(batch,512)\n",
        "        return x\n",
        "\n",
        "def weights_init_1(m):\n",
        "    seed = 20\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "\n",
        "def weights_init_2(m):\n",
        "    seed = 20\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "    torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "class Attention_Soft(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size=32):\n",
        "        super(Attention_Soft, self).__init__()\n",
        "\n",
        "        self.l1 = torch.nn.Linear(in_size, hidden_size, bias=True)\n",
        "        self.ac = nn.Sigmoid()\n",
        "        self.l2 = torch.nn.Linear(in_size, hidden_size, bias=False)\n",
        "        self.l3 = torch.nn.Linear(int(hidden_size), 1, bias=False)\n",
        "\n",
        "        weights_init_2(self.l1)\n",
        "        weights_init_1(self.l2)\n",
        "        weights_init_1(self.l3)\n",
        "\n",
        "    def forward(self, z):\n",
        "        w1 = self.l1(torch.mean(z, dim=1).unsqueeze(1))\n",
        "        w2 = self.l2(z)\n",
        "        w = self.ac(w1 + w2)\n",
        "        w = self.l3(w)\n",
        "        beta = torch.softmax(w, dim=1)\n",
        "\n",
        "        return (beta * z).sum(1)\n",
        "\n",
        "\n",
        "class SV_GAT(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(SV_GAT, self).__init__()\n",
        "        self.args = args\n",
        "\n",
        "        self.length = list(np.load('/content/drive/MyDrive/USPM_16/data/length.npy'))\n",
        "        pretrain_sv_path = args.pretrain_sv_path\n",
        "        pretrain_scn_path = args.pretrain_scn_path\n",
        "        self.sv_embedding = torch.load(pretrain_sv_path, map_location=torch.device(args.device))\n",
        "        # self.sv_embedding = torch.load(pretrain_sv_path, map_location=torch.device(args.device)).to(torch.float32)\n",
        "        self.scn_embedding = torch.load(pretrain_scn_path, map_location=torch.device(args.device))\n",
        "\n",
        "        self.sv_agg = SVFeatureBlock(input_size=768, hidden_size=768, mode=args.mode)\n",
        "\n",
        "        self.attention_soft = Attention_Soft(in_size=768, )\n",
        "\n",
        "        self.gat = GAT(input_dim=768, hidden_dim=64, output_dim=10, heads=8, args=args, drop=0.6)\n",
        "\n",
        "        self.gat_poi = GAT_P(input_dim=768, hidden_dim=64, output_dim=4, heads=8, args=args)\n",
        "\n",
        "    def forward(self):\n",
        "        sv_features = self.sv_embedding\n",
        "        street_list = list(torch.split(sv_features, self.length, dim=0))\n",
        "\n",
        "        sv_aggre = self.sv_agg(street_list)\n",
        "        sv_embedding = sv_aggre\n",
        "        scn_embedding = self.scn_embedding\n",
        "\n",
        "        street_embedding = self.attention_soft(torch.stack([scn_embedding, sv_embedding], dim=1))\n",
        "\n",
        "        if self.args.downstream == 'poi':\n",
        "            gat_loss, out = self.gat_poi(street_embedding)\n",
        "        else:\n",
        "            gat_loss, s_emb1,out = self.gat(street_embedding)\n",
        "\n",
        "        loss = gat_loss\n",
        "\n",
        "        return loss, out, street_embedding\n",
        "\n",
        "    def test(self, out):\n",
        "        if self.args.downstream == 'poi':\n",
        "            acc, f1_score_test, mrr_test, num, pred_out = self.gat_poi.test(out)\n",
        "            return acc, f1_score_test, mrr_test, 1, 1, 1, num, pred_out\n",
        "        else:\n",
        "            a1, a3, a5, a10, f1, mrr, num, pred_out = self.gat.test(out)\n",
        "            return a1, a3, a5, a10, f1, mrr, num, pred_out\n",
        "\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads, args, drop=0.6):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(0)\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, output_dim, concat=False,\n",
        "                             heads=10, dropout=0.6)\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop1 = nn.Dropout(p=drop, )\n",
        "        self.drop2 = nn.Dropout(p=0.6, )\n",
        "\n",
        "        self.edge_index = torch.load('/content/drive/MyDrive/USPM_16/data/edge_index.pt').t().contiguous().to(args.device)\n",
        "        self.y = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_16/data/function/label_all_function.npy', allow_pickle=True)).long().to(args.device)\n",
        "        self.train_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_16/data/function/label_mask.npy', allow_pickle=True)).to(args.device)\n",
        "\n",
        "        self.mask = torch.load('/content/drive/MyDrive/USPM_16/data/function/test_mask.pt')\n",
        "\n",
        "        self.y_testlabel = np.load('/content/drive/MyDrive/USPM_16/data/function/label_all_function.npy')[self.mask]\n",
        "\n",
        "    def forward(self, street_embedding):\n",
        "        street_embedding = self.drop1(street_embedding)\n",
        "        street_embedding_1 = self.conv1(street_embedding, self.edge_index)\n",
        "        street_embedding_2 = self.elu(street_embedding_1)\n",
        "        street_embedding_2 = self.drop2(street_embedding_2)\n",
        "        street_embedding_2 = self.conv2(street_embedding_2, self.edge_index)\n",
        "\n",
        "        cross_criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss_su = cross_criterion(street_embedding_2[self.train_mask], self.y[self.train_mask])\n",
        "\n",
        "        return loss_su, street_embedding_1, street_embedding_2\n",
        "\n",
        "    def test(self, out):\n",
        "        pred = out.argmax(dim=1)\n",
        "        pred = pd.DataFrame({'Type': torch.Tensor.cpu(pred).numpy()})\n",
        "\n",
        "        predictions_test_dim = torch.Tensor.cpu(out[self.mask]).argmax(dim=1).detach().numpy()\n",
        "        predictions_test = torch.Tensor.cpu(out[self.mask]).detach().numpy()\n",
        "\n",
        "        A1 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=1, labels=range(10))\n",
        "        A3 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=3, labels=range(10))\n",
        "        A5 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=5, labels=range(10))\n",
        "        print(f'A1={A1}\\t A3={A3}\\t A5={A5} ')\n",
        "\n",
        "        precision_score_test = precision_score(self.y_testlabel, predictions_test_dim, average=\"weighted\")\n",
        "        f1_score_test = f1_score(self.y_testlabel, predictions_test_dim, average=\"weighted\")\n",
        "        mrr_test = compute_mrr(self.y_testlabel, predictions_test)\n",
        "        result = Counter(pred['Type'].values.tolist())\n",
        "        num = len(result)\n",
        "        print(\n",
        "            f'precision={precision_score_test}, f1={f1_score_test}, mrr={mrr_test},num={num}')\n",
        "\n",
        "        print(result)\n",
        "        return A1, A3, A5, 1, f1_score_test, mrr_test, num, out\n",
        "\n",
        "\n",
        "class GAT_P(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads, args, drop=0.6):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=drop)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, output_dim, concat=False,\n",
        "                             heads=4, dropout=drop)\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop1 = nn.Dropout(p=drop, )\n",
        "        self.drop2 = nn.Dropout(p=drop, )\n",
        "\n",
        "        self.edge_index = torch.load('/content/drive/MyDrive/USPM_16/data/edge_index.pt').t().contiguous().to(args.device)\n",
        "\n",
        "        self.y = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_16/data/poi/label_all_poi_level.npy', allow_pickle=True)).long().to(args.device)\n",
        "        self.train_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_16/data/poi/label_mask_poi_level.npy', allow_pickle=True)).to(args.device)\n",
        "        self.test_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_16/data/poi/test_mask_poi_level.npy', allow_pickle=True)).to(args.device)\n",
        "\n",
        "        self.mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_16/data/poi/test_mask_poi_level.npy', allow_pickle=True))\n",
        "\n",
        "        self.y_testlabel = np.load('/content/drive/MyDrive/USPM_16/data/poi/label_all_poi_level.npy')[self.mask]\n",
        "\n",
        "    def forward(self, street_embedding):\n",
        "        street_embedding = self.drop1(street_embedding)\n",
        "        street_embedding = self.conv1(street_embedding, self.edge_index)\n",
        "        street_embedding = self.elu(street_embedding)\n",
        "        street_embedding = self.drop2(street_embedding)\n",
        "        street_embedding = self.conv2(street_embedding, self.edge_index)\n",
        "\n",
        "        cross_criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss_su = cross_criterion(street_embedding[self.train_mask], self.y[self.train_mask])\n",
        "\n",
        "        return loss_su, street_embedding\n",
        "\n",
        "    def test(self, out):\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = pred[self.test_mask] == self.y[self.test_mask]\n",
        "        acc = int(correct.sum()) / int(self.test_mask.sum())\n",
        "\n",
        "        pred = pd.DataFrame({'Type': torch.Tensor.cpu(pred).numpy()})\n",
        "\n",
        "        predictions_test_dim = torch.Tensor.cpu(out[self.mask]).argmax(dim=1).detach().numpy()\n",
        "        predictions_test = torch.Tensor.cpu(out[self.mask]).detach().numpy()\n",
        "        f1_score_test = f1_score(self.y_testlabel, predictions_test_dim, average=\"macro\")\n",
        "        mrr_test = compute_mrr(self.y_testlabel, predictions_test)\n",
        "        result = Counter(pred['Type'].values.tolist())\n",
        "        num = len(result)\n",
        "        print(\n",
        "            f'acc={acc}, f1={f1_score_test}, mrr={mrr_test},num={num}')\n",
        "\n",
        "        print(result)\n",
        "        return acc, f1_score_test, mrr_test, num, out\n",
        "\n",
        "\n",
        "\n",
        "def compute_mrr(true_labels, machine_preds):\n",
        "    \"\"\"Compute the MRR \"\"\"\n",
        "    rr_total = 0.0\n",
        "    for i in range(len(true_labels)):\n",
        "        if true_labels[i] == 403:\n",
        "            continue\n",
        "        ranklist = list(np.argsort(machine_preds[i])[::-1])\n",
        "        rank = ranklist.index(true_labels[i]) + 1\n",
        "        rr_total = rr_total + 1.0 / rank\n",
        "    mrr = rr_total / len(true_labels)\n",
        "    return mrr"
      ],
      "metadata": {
        "id": "Tl7BKpbNcq8r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "# from model import SV_GAT\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "parser = argparse.ArgumentParser()\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "\n",
        "parser.add_argument('--device', type=str, default='cuda:0', help='gpu device ids')\n",
        "parser.add_argument('--print_num', type=int, default=2, help='gap of print evaluations')\n",
        "parser.add_argument(\"--print_epoch\", type=int, default=0, help=\"Start print epoch\")\n",
        "parser.add_argument(\"--start_epoch\", type=int, default=0, help=\"Start epoch\")\n",
        "parser.add_argument(\"--current_epoch\", type=int, default=0, help=\"Current epoch\")\n",
        "parser.add_argument(\"--epochs\", type=int, default=150, help=\"Epochs\")\n",
        "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed.\")\n",
        "parser.add_argument(\"--rounds\", type=int, default=5, help=\"number of training rounds\")\n",
        "parser.add_argument(\"--mode\", type=str, default='lstm', help=\"aggression function.\")\n",
        "parser.add_argument(\"--pretrain_scn_path\", type=str, default='/content/drive/MyDrive/USPM_16/embeddings/text_embedding.pt')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args = parser.parse_args([])\n",
        "\n",
        "def trainer(args, model, optimizer1, optimizer2, optimizer3, epoch):\n",
        "    loss_epoch = []\n",
        "    model.train()\n",
        "    optimizer1.zero_grad()\n",
        "    optimizer2.zero_grad()\n",
        "    optimizer3.zero_grad()\n",
        "\n",
        "    gnn_loss, pre_out, street_embedding = model()\n",
        "    loss_epoch.append(gnn_loss.item())\n",
        "    loss = gnn_loss\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer1.step()\n",
        "    optimizer2.step()\n",
        "    optimizer3.step()\n",
        "\n",
        "    if epoch % args.print_num == 0:\n",
        "        print(f\"TrainEpoch [{epoch + 1}/{args.epochs}]\\t loss_epoch_gnn:{np.mean(loss_epoch)}\")\n",
        "    return np.mean(loss_epoch), pre_out, street_embedding\n",
        "\n",
        "def test(args, model, epoch, round_num, result_dir):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        _, out, _ = model()\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        os.makedirs(result_dir, exist_ok=True)\n",
        "        if args.downstream == 'poi':\n",
        "            acc, f1, mrr, _, _, _, num, pred_out = model.test(out)\n",
        "            result = {\n",
        "                'epoch': epoch + 1,\n",
        "                'acc': acc,\n",
        "                'f1': f1,\n",
        "                'mrr': mrr,\n",
        "                'num': num\n",
        "            }\n",
        "            return acc, f1, mrr, 1, 1, 1, num, pred_out, result\n",
        "        else:\n",
        "            a1, a3, a5, a10, f1, mrr, num, pred_out = model.test(out)\n",
        "            result = {\n",
        "                'epoch': epoch + 1,\n",
        "                'a1': a1,\n",
        "                'a3': a3,\n",
        "                'a5': a5,\n",
        "                'a10': a10,\n",
        "                'f1': f1,\n",
        "                'mrr': mrr,\n",
        "                'num': num\n",
        "            }\n",
        "            return a1, a3, a5, a10, f1, mrr, num, pred_out, result\n",
        "\n",
        "def calculate_best_results(result_dir, downstream):\n",
        "    # Collect round files\n",
        "    round_files = [f for f in os.listdir(result_dir) if f.startswith('round_') and f.endswith('.npy')]\n",
        "    if not round_files:\n",
        "        return None\n",
        "\n",
        "    # Load all results and group by epoch\n",
        "    epoch_results = {}\n",
        "    for round_file in round_files:\n",
        "        round_data = np.load(os.path.join(result_dir, round_file), allow_pickle=True).item()\n",
        "        for epoch_data in round_data['epochs']:\n",
        "            epoch = epoch_data['epoch']\n",
        "            if epoch not in epoch_results:\n",
        "                epoch_results[epoch] = []\n",
        "            epoch_results[epoch].append(epoch_data)\n",
        "\n",
        "    # Compute per-epoch averages across rounds\n",
        "    epoch_averages = {}\n",
        "    best_f1 = -1\n",
        "    best_epoch = None\n",
        "\n",
        "    if downstream == 'poi':\n",
        "        all_results = []\n",
        "        for epoch in epoch_results:\n",
        "            accs = [r['acc'] for r in epoch_results[epoch]]\n",
        "            f1s = [r['f1'] for r in epoch_results[epoch]]\n",
        "            mrrs = [r['mrr'] for r in epoch_results[epoch]]\n",
        "            epoch_averages[epoch] = {\n",
        "                'avg_acc': np.mean(accs),\n",
        "                'avg_f1': np.mean(f1s),\n",
        "                'avg_mrr': np.mean(mrrs)\n",
        "            }\n",
        "            all_results.extend(epoch_results[epoch])\n",
        "            if epoch_averages[epoch]['avg_f1'] > best_f1:\n",
        "                best_f1 = epoch_averages[epoch]['avg_f1']\n",
        "                best_epoch = epoch\n",
        "\n",
        "        # Store best epoch results and overall max metrics\n",
        "        best_results = {\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_epoch_avg_acc': epoch_averages[best_epoch]['avg_acc'],\n",
        "            'best_epoch_avg_f1': epoch_averages[best_epoch]['avg_f1'],\n",
        "            'best_epoch_avg_mrr': epoch_averages[best_epoch]['avg_mrr'],\n",
        "            'overall_best_acc': max([r['acc'] for r in all_results]),\n",
        "            'overall_best_f1': max([r['f1'] for r in all_results]),\n",
        "            'overall_best_mrr': max([r['mrr'] for r in all_results])\n",
        "        }\n",
        "    else:\n",
        "        all_results = []\n",
        "        for epoch in epoch_results:\n",
        "            a1s = [r['a1'] for r in epoch_results[epoch]]\n",
        "            a3s = [r['a3'] for r in epoch_results[epoch]]\n",
        "            a5s = [r['a5'] for r in epoch_results[epoch]]\n",
        "            a10s = [r['a10'] for r in epoch_results[epoch]]\n",
        "            f1s = [r['f1'] for r in epoch_results[epoch]]\n",
        "            mrrs = [r['mrr'] for r in epoch_results[epoch]]\n",
        "            epoch_averages[epoch] = {\n",
        "                'avg_a1': np.mean(a1s),\n",
        "                'avg_a3': np.mean(a3s),\n",
        "                'avg_a5': np.mean(a5s),\n",
        "                'avg_a10': np.mean(a10s),\n",
        "                'avg_f1': np.mean(f1s),\n",
        "                'avg_mrr': np.mean(mrrs)\n",
        "            }\n",
        "            all_results.extend(epoch_results[epoch])\n",
        "            if epoch_averages[epoch]['avg_f1'] > best_f1:\n",
        "                best_f1 = epoch_averages[epoch]['avg_f1']\n",
        "                best_epoch = epoch\n",
        "\n",
        "        # Store best epoch results and overall max metrics\n",
        "        best_results = {\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_epoch_avg_a1': epoch_averages[best_epoch]['avg_a1'],\n",
        "            'best_epoch_avg_a3': epoch_averages[best_epoch]['avg_a3'],\n",
        "            'best_epoch_avg_a5': epoch_averages[best_epoch]['avg_a5'],\n",
        "            'best_epoch_avg_a10': epoch_averages[best_epoch]['avg_a10'],\n",
        "            'best_epoch_avg_f1': epoch_averages[best_epoch]['avg_f1'],\n",
        "            'best_epoch_avg_mrr': epoch_averages[best_epoch]['avg_mrr'],\n",
        "            'overall_best_a1': max([r['a1'] for r in all_results]),\n",
        "            'overall_best_a3': max([r['a3'] for r in all_results]),\n",
        "            'overall_best_a5': max([r['a5'] for r in all_results]),\n",
        "            'overall_best_a10': max([r['a10'] for r in all_results]),\n",
        "            # 'overall_best_f1': max([r['f-concept': 'f1'] for r in all_results]),\n",
        "            'overall_best_f1': max([r['f1'] for r in all_results]),\n",
        "            'overall_best_mrr': max([r['mrr'] for r in all_results])\n",
        "        }\n",
        "\n",
        "    # Save per-epoch averages and best results\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    np.save(f'{result_dir}/epoch_averages_{timestamp}.npy', epoch_averages)\n",
        "    np.save(f'{result_dir}/best_results_{timestamp}.npy', best_results)\n",
        "    return best_results\n",
        "\n",
        "def run_training(pretrain_sv_path, result_subdir):\n",
        "    result_dir = f'/content/drive/MyDrive/USPM_16/result/{result_subdir}'\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for downstream in ['function', 'poi']:\n",
        "        print(f\"\\nStarting {downstream} downstream with {pretrain_sv_path}\")\n",
        "        args.downstream = downstream\n",
        "        args.pretrain_sv_path = pretrain_sv_path\n",
        "        args.current_epoch = 0\n",
        "\n",
        "        for round_num in range(args.rounds):\n",
        "            print(f\"Round {round_num + 1}/{args.rounds}\")\n",
        "\n",
        "            np.random.seed(args.seed + round_num)\n",
        "            random.seed(args.seed + round_num + 1)\n",
        "            torch.manual_seed(args.seed + round_num + 2)\n",
        "            torch.cuda.manual_seed(args.seed + round_num + 3)\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "\n",
        "            model = SV_GAT(args)\n",
        "            model = model.to(args.device)\n",
        "\n",
        "            opt1 = torch.optim.Adam(\n",
        "                itertools.chain(model.attention_soft.parameters()),\n",
        "                lr=0.0005, weight_decay=1e-8)\n",
        "            if args.downstream == 'poi':\n",
        "                opt3 = torch.optim.Adam(model.gat_poi.parameters(), lr=0.0005, weight_decay=5e-4)\n",
        "                args.epochs = 200\n",
        "            else:\n",
        "                opt3 = torch.optim.Adam(model.gat.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "                args.epochs = 150\n",
        "\n",
        "            if args.mode != 'mean':\n",
        "                opt2 = torch.optim.SGD(model.sv_agg.parameters(), lr=0.005, weight_decay=1e-4, momentum=0.9)\n",
        "                t = 10\n",
        "                T = 800\n",
        "                n_t = 0.5\n",
        "                lf = lambda epoch: (0.9 * epoch / t + 0.1) if epoch < t else 0.1 if n_t * (\n",
        "                        1 + math.cos(math.pi * (epoch - t) / (T - t))) < 0.1 else n_t * (\n",
        "                        1 + math.cos(math.pi * (epoch - t) / (T - t)))\n",
        "                scheduler = torch.optim.lr_scheduler.LambdaLR(opt2, lr_lambda=lf)\n",
        "\n",
        "            print(model)\n",
        "\n",
        "            # Collect results for this round\n",
        "            round_results = {'round': round_num, 'epochs': []}\n",
        "\n",
        "            for epoch in range(args.start_epoch, args.epochs):\n",
        "                loss_epoch, pred_, street_embedding = trainer(args, model, opt1, opt2, opt3, epoch)\n",
        "                if args.mode != 'mean':\n",
        "                    scheduler.step()\n",
        "                if epoch % args.print_num == 0:\n",
        "                    result_tuple = test(args, model, epoch, round_num, f'{result_dir}/{downstream}')\n",
        "                    # Append result to round_results\n",
        "                    round_results['epochs'].append(result_tuple[-1])  # Last element is the result dict\n",
        "\n",
        "            # Save all results for this round in a single file\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            np.save(f'{result_dir}/{downstream}/round_{round_num}_{timestamp}.npy', round_results)\n",
        "\n",
        "        # Calculate and save average and best results\n",
        "        best_results = calculate_best_results(f'{result_dir}/{downstream}', downstream)\n",
        "        print(f\"Best Results for {downstream}:\", best_results)\n",
        "\n",
        "run_training('/content/drive/MyDrive/USPM_16/embeddings/image_representation_117144_16.pt', 'image_16')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "qsUK3vMUeVyH",
        "outputId": "f6618c54-e52c-473f-d5a6-3d5cea74d6d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting function downstream with /content/drive/MyDrive/USPM_16/embeddings/image_representation_117144_16.pt\n",
            "Round 1/5\n",
            "SV_GAT(\n",
            "  (sv_agg): SVFeatureBlock(\n",
            "    (lstm): LSTM(768, 768, batch_first=True)\n",
            "  )\n",
            "  (attention_soft): Attention_Soft(\n",
            "    (l1): Linear(in_features=768, out_features=32, bias=True)\n",
            "    (ac): Sigmoid()\n",
            "    (l2): Linear(in_features=768, out_features=32, bias=False)\n",
            "    (l3): Linear(in_features=32, out_features=1, bias=False)\n",
            "  )\n",
            "  (gat): GAT(\n",
            "    (conv1): GATConv(768, 64, heads=8)\n",
            "    (conv2): GATConv(512, 10, heads=10)\n",
            "    (elu): ELU(alpha=1.0)\n",
            "    (drop1): Dropout(p=0.6, inplace=False)\n",
            "    (drop2): Dropout(p=0.6, inplace=False)\n",
            "  )\n",
            "  (gat_poi): GAT_P(\n",
            "    (conv1): GATConv(768, 64, heads=8)\n",
            "    (conv2): GATConv(512, 4, heads=4)\n",
            "    (elu): ELU(alpha=1.0)\n",
            "    (drop1): Dropout(p=0.6, inplace=False)\n",
            "    (drop2): Dropout(p=0.6, inplace=False)\n",
            "  )\n",
            ")\n",
            "TrainEpoch [1/150]\t loss_epoch_gnn:2.3555121421813965\n",
            "A1=0.46891342242882045\t A3=0.6963006004261089\t A5=0.7826844857640907 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6134294230314028,num=1\n",
            "Counter({0: 5458})\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3192144258.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best Results for {downstream}:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/USPM_16/embeddings/image_representation_117144_16.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image_16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-11-3192144258.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(pretrain_sv_path, result_subdir)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreet_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-11-3192144258.py\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(args, model, optimizer1, optimizer2, optimizer3, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0moptimizer3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mgnn_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreet_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-1391842656.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mstreet_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msv_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0msv_aggre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msv_agg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreet_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0msv_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msv_aggre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mscn_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscn_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-1391842656.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sv)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lstm\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mout_put\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_put\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_put\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}