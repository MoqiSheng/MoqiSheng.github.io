{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPGGNnqk2RnX5wLY2/RHVz+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/GeometricMedian_add0203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHDSoa3Ju8K9",
        "outputId": "0831a9a5-aa2d-461d-a3e1-05c178e4a973"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/UrbanASIFpro/Anchor_types.zip -d /content/Anchor_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o1-yrC7vFwE",
        "outputId": "c219128e-c03e-4cd3-d5d0-3ae12daa832b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/UrbanASIFpro/Anchor_types.zip\n",
            "replace /content/Anchor_image/civic, governmental and cultural/1162.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# 获取脚本所在的目录路径并切换当前工作目录\n",
        "# abspath = os.path.abspath(__file__)  # 获取脚本文件的绝对路径\n",
        "# dname = os.path.dirname(abspath)     # 提取脚本所在目录的路径\n",
        "# os.chdir(dname)                      # 切换当前工作目录到脚本所在的目录\n",
        "\n",
        "# 加载预训练的 google/vit-base-patch16-224-in21k 模型\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\").to(device)\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "# Weiszfeld 算法实现\n",
        "def compute_weiszfeld_median(vectors):\n",
        "    \"\"\"\n",
        "    使用 Weiszfeld 算法计算加权几何中位数\n",
        "    \"\"\"\n",
        "    vectors = torch.stack(vectors, dim=0)\n",
        "    # 初始化几何中位数为第一个向量\n",
        "    median = vectors[0]\n",
        "\n",
        "    # Weiszfeld算法迭代\n",
        "    epsilon = 1e-6\n",
        "    max_iterations = 1000\n",
        "    for _ in range(max_iterations):\n",
        "        distances = torch.norm(vectors - median, dim=-1)  # 计算到每个向量的距离\n",
        "        weights = 1.0 / (distances + epsilon)  # 防止除以零，加入一个小的偏移量\n",
        "        weighted_vectors = (weights.unsqueeze(-1) * vectors).sum(dim=0)  # 加权平均\n",
        "        new_median = weighted_vectors / weights.sum()  # 更新几何中位数\n",
        "\n",
        "        # 如果变化小于阈值，则停止迭代\n",
        "        if torch.norm(new_median - median) < epsilon:\n",
        "            break\n",
        "        median = new_median\n",
        "\n",
        "    return median\n",
        "\n",
        "# 定义特征提取函数 extract_features\n",
        "def extract_features(image_folder):\n",
        "    image_features_list = []\n",
        "    # 读取 image_folder 中所有扩展名为 .jpg 或 .png 的文件，并将文件名按自然数顺序排序（例如，1.jpg、2.jpg、3.jpg 顺序排列）\n",
        "    image_paths = sorted(\n",
        "        [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.lower().endswith(('.jpg', '.png'))],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 加载并预处理图像\n",
        "            image = Image.open(image_path)\n",
        "            inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)  # 使用 ViTFeatureExtractor 进行预处理\n",
        "\n",
        "            # 获取图像特征\n",
        "            with torch.no_grad():  # 禁用了梯度计算（不需要反向传播）\n",
        "                outputs = model(**inputs)  # 获取模型输出\n",
        "                image_features = outputs.last_hidden_state[:, 0]  # 取 [CLS] token 的特征\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化处理\n",
        "                image_features_list.append(image_features.cpu())  # 将特征向量移动到 CPU ，然后将其追加到列表中\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    return image_features_list\n",
        "\n",
        "# 遍历所有文件夹，计算几何中位数并保存结果\n",
        "def process_folders(base_folder):\n",
        "    for folder_name in os.listdir(base_folder):\n",
        "        folder_path = os.path.join(base_folder, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            print(f\"Processing folder: {folder_name}\")\n",
        "\n",
        "            # 提取该文件夹内所有图片的特征\n",
        "            image_features_list = extract_features(folder_path)\n",
        "\n",
        "            if image_features_list:\n",
        "                # 计算该文件夹的几何中位数\n",
        "                weiszfeld_median = compute_weiszfeld_median(image_features_list)\n",
        "\n",
        "                # 获取文件夹名称的第一个单词\n",
        "                first_word = folder_name.split()[0]\n",
        "\n",
        "                # 保存几何中位数，文件名为文件夹名的第一个单词\n",
        "                output_file = os.path.join(base_folder, f\"{first_word}.pt\")\n",
        "                torch.save(weiszfeld_median, output_file)\n",
        "                print(f\"Geometric median saved to {output_file}\")\n",
        "            else:\n",
        "                print(f\"No valid images found in {folder_path}\")\n",
        "\n",
        "# 调用函数，处理文件夹中的图片\n",
        "process_folders('./Anchor_image')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-L59zzlvsIA",
        "outputId": "e8df7b17-9bbc-4f57-e9e1-6888f535bc34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing folder: civic, governmental and cultural\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/civic, governmental and cultural: 100%|██████████| 10/10 [00:00<00:00, 61.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/civic,.pt\n",
            "Processing folder: transportation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/transportation: 100%|██████████| 6/6 [00:00<00:00, 64.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/transportation.pt\n",
            "Processing folder: hotel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/hotel: 100%|██████████| 6/6 [00:00<00:00, 63.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/hotel.pt\n",
            "Processing folder: sports and recreation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/sports and recreation: 100%|██████████| 5/5 [00:00<00:00, 63.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/sports.pt\n",
            "Processing folder: residential\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/residential: 100%|██████████| 39/39 [00:00<00:00, 63.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/residential.pt\n",
            "Processing folder: health care\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/health care: 100%|██████████| 7/7 [00:00<00:00, 63.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/health.pt\n",
            "Processing folder: industrial\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/industrial: 100%|██████████| 27/27 [00:00<00:00, 64.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/industrial.pt\n",
            "Processing folder: .ipynb_checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/.ipynb_checkpoints: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No valid images found in ./Anchor_image/.ipynb_checkpoints\n",
            "Processing folder: commercial\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/commercial: 100%|██████████| 30/30 [00:00<00:00, 64.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/commercial.pt\n",
            "Processing folder: education\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/education: 100%|██████████| 17/17 [00:00<00:00, 63.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/education.pt\n",
            "Processing folder: outdoors and natural\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing ./Anchor_image/outdoors and natural: 100%|██████████| 5/5 [00:00<00:00, 64.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geometric median saved to ./Anchor_image/outdoors.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/UrbanASIFpro/Anchor.zip -d /content/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E1hd6qcztb2",
        "outputId": "3341e1e8-68de-4df1-d6a1-6162e933e9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/UrbanASIFpro/Anchor.zip\n",
            "  inflating: /content/Data/1007.png  \n",
            "  inflating: /content/Data/1037.png  \n",
            "  inflating: /content/Data/1039.png  \n",
            "  inflating: /content/Data/1052.png  \n",
            "  inflating: /content/Data/1094.png  \n",
            "  inflating: /content/Data/1095.png  \n",
            "  inflating: /content/Data/1097.png  \n",
            "  inflating: /content/Data/1104.png  \n",
            "  inflating: /content/Data/111.png   \n",
            "  inflating: /content/Data/1112.png  \n",
            "  inflating: /content/Data/1117.png  \n",
            "  inflating: /content/Data/1140.png  \n",
            "  inflating: /content/Data/1142.png  \n",
            "  inflating: /content/Data/115.png   \n",
            "  inflating: /content/Data/1162.png  \n",
            "  inflating: /content/Data/1172.png  \n",
            "  inflating: /content/Data/118.png   \n",
            "  inflating: /content/Data/1193.png  \n",
            "  inflating: /content/Data/1194.png  \n",
            "  inflating: /content/Data/1201.png  \n",
            "  inflating: /content/Data/1202.png  \n",
            "  inflating: /content/Data/1206.png  \n",
            "  inflating: /content/Data/1216.png  \n",
            "  inflating: /content/Data/1224.png  \n",
            "  inflating: /content/Data/1271.png  \n",
            "  inflating: /content/Data/1274.png  \n",
            "  inflating: /content/Data/1277.png  \n",
            "  inflating: /content/Data/129.png   \n",
            "  inflating: /content/Data/1290.png  \n",
            "  inflating: /content/Data/1291.png  \n",
            "  inflating: /content/Data/1293.png  \n",
            "  inflating: /content/Data/1300.png  \n",
            "  inflating: /content/Data/1309.png  \n",
            "  inflating: /content/Data/1312.png  \n",
            "  inflating: /content/Data/1332.png  \n",
            "  inflating: /content/Data/1341.png  \n",
            "  inflating: /content/Data/1343.png  \n",
            "  inflating: /content/Data/1370.png  \n",
            "  inflating: /content/Data/1377.png  \n",
            "  inflating: /content/Data/1395.png  \n",
            "  inflating: /content/Data/140.png   \n",
            "  inflating: /content/Data/1400.png  \n",
            "  inflating: /content/Data/1405.png  \n",
            "  inflating: /content/Data/1409.png  \n",
            "  inflating: /content/Data/1412.png  \n",
            "  inflating: /content/Data/1432.png  \n",
            "  inflating: /content/Data/1443.png  \n",
            "  inflating: /content/Data/1466.png  \n",
            "  inflating: /content/Data/1483.png  \n",
            "  inflating: /content/Data/1487.png  \n",
            "  inflating: /content/Data/1493.png  \n",
            "  inflating: /content/Data/1505.png  \n",
            "  inflating: /content/Data/1509.png  \n",
            "  inflating: /content/Data/1510.png  \n",
            "  inflating: /content/Data/158.png   \n",
            "  inflating: /content/Data/164.png   \n",
            "  inflating: /content/Data/165.png   \n",
            "  inflating: /content/Data/171.png   \n",
            "  inflating: /content/Data/174.png   \n",
            "  inflating: /content/Data/176.png   \n",
            "  inflating: /content/Data/195.png   \n",
            "  inflating: /content/Data/197.png   \n",
            "  inflating: /content/Data/198.png   \n",
            "  inflating: /content/Data/200.png   \n",
            "  inflating: /content/Data/209.png   \n",
            "  inflating: /content/Data/215.png   \n",
            "  inflating: /content/Data/225.png   \n",
            "  inflating: /content/Data/241.png   \n",
            "  inflating: /content/Data/246.png   \n",
            "  inflating: /content/Data/250.png   \n",
            "  inflating: /content/Data/253.png   \n",
            "  inflating: /content/Data/255.png   \n",
            "  inflating: /content/Data/259.png   \n",
            "  inflating: /content/Data/268.png   \n",
            "  inflating: /content/Data/277.png   \n",
            "  inflating: /content/Data/280.png   \n",
            "  inflating: /content/Data/289.png   \n",
            "  inflating: /content/Data/297.png   \n",
            "  inflating: /content/Data/32.png    \n",
            "  inflating: /content/Data/34.png    \n",
            "  inflating: /content/Data/345.png   \n",
            "  inflating: /content/Data/35.png    \n",
            "  inflating: /content/Data/363.png   \n",
            "  inflating: /content/Data/374.png   \n",
            "  inflating: /content/Data/376.png   \n",
            "  inflating: /content/Data/389.png   \n",
            "  inflating: /content/Data/425.png   \n",
            "  inflating: /content/Data/430.png   \n",
            "  inflating: /content/Data/442.png   \n",
            "  inflating: /content/Data/453.png   \n",
            "  inflating: /content/Data/46.png    \n",
            "  inflating: /content/Data/461.png   \n",
            "  inflating: /content/Data/464.png   \n",
            "  inflating: /content/Data/467.png   \n",
            "  inflating: /content/Data/508.png   \n",
            "  inflating: /content/Data/531.png   \n",
            "  inflating: /content/Data/538.png   \n",
            "  inflating: /content/Data/544.png   \n",
            "  inflating: /content/Data/548.png   \n",
            "  inflating: /content/Data/561.png   \n",
            "  inflating: /content/Data/585.png   \n",
            "  inflating: /content/Data/601.png   \n",
            "  inflating: /content/Data/606.png   \n",
            "  inflating: /content/Data/616.png   \n",
            "  inflating: /content/Data/618.png   \n",
            "  inflating: /content/Data/621.png   \n",
            "  inflating: /content/Data/629.png   \n",
            "  inflating: /content/Data/644.png   \n",
            "  inflating: /content/Data/645.png   \n",
            "  inflating: /content/Data/65.png    \n",
            "  inflating: /content/Data/666.png   \n",
            "  inflating: /content/Data/670.png   \n",
            "  inflating: /content/Data/674.png   \n",
            "  inflating: /content/Data/676.png   \n",
            "  inflating: /content/Data/678.png   \n",
            "  inflating: /content/Data/690.png   \n",
            "  inflating: /content/Data/704.png   \n",
            "  inflating: /content/Data/712.png   \n",
            "  inflating: /content/Data/715.png   \n",
            "  inflating: /content/Data/717.png   \n",
            "  inflating: /content/Data/747.png   \n",
            "  inflating: /content/Data/758.png   \n",
            "  inflating: /content/Data/76.png    \n",
            "  inflating: /content/Data/769.png   \n",
            "  inflating: /content/Data/77.png    \n",
            "  inflating: /content/Data/774.png   \n",
            "  inflating: /content/Data/78.png    \n",
            "  inflating: /content/Data/79.png    \n",
            "  inflating: /content/Data/793.png   \n",
            "  inflating: /content/Data/825.png   \n",
            "  inflating: /content/Data/826.png   \n",
            "  inflating: /content/Data/827.png   \n",
            "  inflating: /content/Data/830.png   \n",
            "  inflating: /content/Data/840.png   \n",
            "  inflating: /content/Data/849.png   \n",
            "  inflating: /content/Data/850.png   \n",
            "  inflating: /content/Data/851.png   \n",
            "  inflating: /content/Data/87.png    \n",
            "  inflating: /content/Data/871.png   \n",
            "  inflating: /content/Data/885.png   \n",
            "  inflating: /content/Data/890.png   \n",
            "  inflating: /content/Data/910.png   \n",
            "  inflating: /content/Data/912.png   \n",
            "  inflating: /content/Data/914.png   \n",
            "  inflating: /content/Data/932.png   \n",
            "  inflating: /content/Data/936.png   \n",
            "  inflating: /content/Data/947.png   \n",
            "  inflating: /content/Data/960.png   \n",
            "  inflating: /content/Data/972.png   \n",
            "  inflating: /content/Data/989.png   \n",
            "  inflating: /content/Data/991.png   \n",
            "  inflating: /content/Data/992.png   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import re  # 导入正则表达式模块\n",
        "\n",
        "# 加载预训练的 google/vit-base-patch16-224-in21k 模型\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\").to(device)\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "# 加载 anchor.csv 并将其转换为 DataFrame\n",
        "csv_file = './anchor.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "print(f\"Loaded {len(df)} rows from {csv_file}\")\n",
        "\n",
        "# 定义特征提取函数 extract_features\n",
        "def extract_features(image_folder, output_file):\n",
        "    image_features_list = []\n",
        "\n",
        "    # 读取 image_folder 中所有扩展名为 .jpg 或 .png 的文件，并将文件名按自然数顺序排序（例如，1.jpg、2.jpg、3.jpg 顺序排列）\n",
        "    image_paths = sorted(\n",
        "        [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.lower().endswith(('.jpg', '.png'))],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "    print(f\"Found {len(image_paths)} images in {image_folder}\")\n",
        "\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 获取图片ID\n",
        "            image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "            # 从 CSV 文件中获取对应的 primary_function 列的第一个单词\n",
        "            primary_function = df.loc[df['ID'] == int(image_id), 'primary_function'].values\n",
        "            if primary_function.size == 0:\n",
        "                print(f\"Warning: No primary_function found for image ID {image_id}, skipping.\")\n",
        "                continue  # 如果没有找到对应的行，跳过该图片\n",
        "\n",
        "            # 使用正则表达式去除标点符号，提取第一个单词\n",
        "            # 正则表达式 '[^\\w\\s]' 用于去除所有非字母和空格字符\n",
        "            first_word = re.sub(r'[^\\w\\s]', '', primary_function[0]).split()[0]  # 去掉标点符号并取第一个单词\n",
        "            print(f\"Image {image_id}: Primary function is {primary_function[0]}, using {first_word} as the embedding keyword.\")\n",
        "\n",
        "            # 加载并预处理图像\n",
        "            image = Image.open(image_path)\n",
        "            inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)  # 使用 ViTFeatureExtractor 进行预处理\n",
        "\n",
        "            # 获取图像特征\n",
        "            with torch.no_grad():  # 禁用了梯度计算（不需要反向传播）\n",
        "                outputs = model(**inputs)  # 获取模型输出\n",
        "                image_features = outputs.last_hidden_state[:, 0]  # 取 [CLS] token 的特征\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)  # 归一化处理\n",
        "                image_features *= 0.5  # 对图像特征向量进行 0.8 的缩放\n",
        "                print(f\"Image {image_id}: Extracted features and scaled by 0.8\")\n",
        "\n",
        "                # 加载与第一个单词对应的嵌入文件（.pt）\n",
        "                embedding_file = f'./Anchor_image/{first_word}.pt'\n",
        "                if os.path.exists(embedding_file):\n",
        "                    word_embedding = torch.load(embedding_file).to(device)\n",
        "                    image_features += 0.5 * word_embedding  # 加权叠加\n",
        "                    print(f\"Image {image_id}: Added embedding from {first_word}.pt with weight 0.2\")\n",
        "                else:\n",
        "                    print(f\"Warning: Embedding file {embedding_file} not found, skipping embedding addition.\")\n",
        "\n",
        "                image_features_list.append(image_features.cpu())  # 将特征向量移动到 CPU ，然后将其追加到列表中\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    # 将所有图像特征保存为矩阵\n",
        "    if image_features_list:\n",
        "        image_features = torch.cat(image_features_list, dim=0)  # 将存储在 image_features_list 中的所有图像特征向量拼接成一个大的张量\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"Features saved to {output_file}\")\n",
        "    else:\n",
        "        print(f\"No valid images found in {image_folder}\")\n",
        "\n",
        "# 调用特征提取函数，提取并保存每个城市的特征\n",
        "extract_features('./Data', './imgs_anchor')"
      ],
      "metadata": {
        "id": "OQDgzji-z-lo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}