{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPx8FUnBR4dsbK+xhkNrpcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/Untitled76.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2TDsr7VBpfJ",
        "outputId": "db10574b-43d7-4db9-dce1-124713bda55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqAAh9u1CMYc",
        "outputId": "b497b354-47d6-46e8-e114-3ec0367601f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.6.15)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import collections\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, \\\n",
        "    top_k_accuracy_score, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from transformers import AutoModel\n",
        "from torch_geometric.nn import GATConv, GCNConv\n",
        "from collections import Counter\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "\n",
        "class SVFeatureBlock(nn.Module):\n",
        "    def __init__(self, input_size=512, hidden_size=512, mode='mean'):\n",
        "        super(SVFeatureBlock, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        if mode == 'lstm':\n",
        "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "            nn.init.orthogonal_(self.lstm.weight_ih_l0)\n",
        "            nn.init.orthogonal_(self.lstm.weight_hh_l0)\n",
        "        elif mode == 'bi-lstm':\n",
        "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True,\n",
        "                                bidirectional=True)\n",
        "        elif self.mode == \"gru\":\n",
        "            self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "        elif mode == 'rnn':\n",
        "            self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "\n",
        "    def forward(self, sv):\n",
        "        sv_list = []\n",
        "        for x_tmp in sv:\n",
        "            if self.mode == \"mean\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.mean(x_tmp, dim=0)\n",
        "            elif self.mode == \"sum\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.sum(x_tmp, dim=0)\n",
        "            elif self.mode == \"max\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.max(x_tmp, dim=0).values\n",
        "            elif self.mode == \"lstm\":\n",
        "                out_put, (h_n, c_n) = self.lstm(x_tmp.view(1, -1, self.input_size))\n",
        "                out_put = out_put[:, -1, :]\n",
        "                out_put = torch.squeeze(out_put)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            sv_list.append(out_put)\n",
        "        x = torch.stack(sv_list)  # 拼接,(batch,512)\n",
        "        return x\n",
        "\n",
        "\n",
        "def weights_init_1(m):\n",
        "    seed = 20\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "\n",
        "\n",
        "def weights_init_2(m):\n",
        "    seed = 20\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "    torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "class Attention_Soft(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size=32):\n",
        "        super(Attention_Soft, self).__init__()\n",
        "\n",
        "        self.l1 = torch.nn.Linear(in_size, hidden_size, bias=True)\n",
        "        self.ac = nn.Sigmoid()\n",
        "        self.l2 = torch.nn.Linear(in_size, hidden_size, bias=False)\n",
        "        self.l3 = torch.nn.Linear(int(hidden_size), 1, bias=False)\n",
        "\n",
        "        weights_init_2(self.l1)\n",
        "        weights_init_1(self.l2)\n",
        "        weights_init_1(self.l3)\n",
        "\n",
        "    def forward(self, z):\n",
        "        w1 = self.l1(torch.mean(z, dim=1).unsqueeze(1))\n",
        "        w2 = self.l2(z)\n",
        "        w = self.ac(w1 + w2)\n",
        "        w = self.l3(w)\n",
        "        beta = torch.softmax(w, dim=1)\n",
        "\n",
        "        return (beta * z).sum(1)\n",
        "\n",
        "\n",
        "class Text_MLP(nn.Module):\n",
        "    def __init__(self, input_dim=4096, hidden_dim=2048, output_dim=768):\n",
        "        super(Text_MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
        "        # self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "        weights_init_2(self.layer1)\n",
        "        weights_init_2(self.layer2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "def compute_similarity_edges(embeddings, similarity_threshold=0.8):\n",
        "    device = embeddings.device\n",
        "    num_nodes = embeddings.size(0)\n",
        "\n",
        "    # 归一化嵌入向量以计算余弦相似度\n",
        "    normalized_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    # 计算余弦相似度矩阵\n",
        "    similarity_matrix = torch.mm(normalized_embeddings, normalized_embeddings.t())\n",
        "\n",
        "    # 将对角线设为0，避免自连接\n",
        "    similarity_matrix.fill_diagonal_(0)\n",
        "\n",
        "    # 找到所有相似度超过阈值的节点对\n",
        "    # 只保留上三角矩阵，避免重复边\n",
        "    upper_tri_mask = torch.triu(torch.ones(num_nodes, num_nodes, device=device), diagonal=1).bool()\n",
        "    threshold_mask = (similarity_matrix >= similarity_threshold) & upper_tri_mask\n",
        "\n",
        "    # 获取满足条件的边的索引\n",
        "    source_nodes, target_nodes = torch.where(threshold_mask)\n",
        "\n",
        "    num_similarity_edges = len(source_nodes)\n",
        "    print(f\"Similarity threshold: {similarity_threshold:.3f}\")\n",
        "    print(f\"Found {num_similarity_edges} node pairs with similarity >= {similarity_threshold:.3f}\")\n",
        "\n",
        "    if num_similarity_edges > 0:\n",
        "        # 创建边索引\n",
        "        similarity_edges = torch.stack([source_nodes, target_nodes], dim=0)\n",
        "        return similarity_edges\n",
        "    else:\n",
        "        return torch.empty((2, 0), dtype=torch.long, device=device)\n",
        "\n",
        "class SV_GAT(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(SV_GAT, self).__init__()\n",
        "        self.args = args\n",
        "        self.length = list(np.load('/content/drive/MyDrive/USPM_edege_add/data/length.npy'))\n",
        "        pretrain_sv_path = args.pretrain_sv_path\n",
        "        pretrain_scn_path = args.pretrain_scn_path\n",
        "        self.sv_embedding = torch.load(pretrain_sv_path, map_location=torch.device(args.device))\n",
        "        self.scn_embedding = torch.load(pretrain_scn_path, map_location=torch.device(args.device))\n",
        "\n",
        "        self.text_mlp = Text_MLP(input_dim=4096, hidden_dim=2048, output_dim=768)\n",
        "\n",
        "        self.sv_agg = SVFeatureBlock(input_size=768, hidden_size=768, mode=args.mode)\n",
        "\n",
        "        self.attention_soft = Attention_Soft(in_size=768)\n",
        "\n",
        "        # 添加参数控制是否使用相似度连接\n",
        "        self.use_similarity = getattr(args, 'use_similarity', True)\n",
        "        # 为GAT和GAT_P分别设置相似度阈值\n",
        "        self.gat_similarity_threshold = getattr(args, 'gat_similarity_threshold', 0.98)\n",
        "        self.gat_poi_similarity_threshold = getattr(args, 'gat_poi_similarity_threshold', 0.98)\n",
        "\n",
        "        self.gat = GAT(input_dim=768, hidden_dim=64, output_dim=10, heads=8, args=args, drop=0.6)\n",
        "\n",
        "        self.gat_poi = GAT_P(input_dim=768, hidden_dim=64, output_dim=4, heads=8, args=args)\n",
        "\n",
        "    def forward(self):\n",
        "        sv_features = self.sv_embedding\n",
        "        street_list = list(torch.split(sv_features, self.length, dim=0))\n",
        "        sv_aggre = self.sv_agg(street_list)\n",
        "        sv_embedding = sv_aggre\n",
        "\n",
        "        scn_embedding = self.text_mlp(self.scn_embedding)  # Reduce text embedding to 768 dim\n",
        "        street_embedding = self.attention_soft(torch.stack([scn_embedding, sv_embedding], dim=1))\n",
        "\n",
        "        # 根据下游任务选择不同的相似度阈值\n",
        "        if self.use_similarity:\n",
        "            if self.args.downstream == 'poi':\n",
        "                similarity_threshold = self.gat_poi_similarity_threshold\n",
        "            else:\n",
        "                similarity_threshold = self.gat_similarity_threshold\n",
        "\n",
        "            similarity_edges = compute_similarity_edges(street_embedding, similarity_threshold)\n",
        "            similarity_edges = similarity_edges.to(self.args.device)\n",
        "\n",
        "        if self.args.downstream == 'poi':\n",
        "            gat_loss, out = self.gat_poi(street_embedding, similarity_edges)\n",
        "        else:\n",
        "            gat_loss, s_emb1, out = self.gat(street_embedding, similarity_edges)\n",
        "\n",
        "        loss = gat_loss\n",
        "\n",
        "        return loss, out, street_embedding\n",
        "\n",
        "    def test(self, out):\n",
        "        if self.args.downstream == 'poi':\n",
        "            acc, f1_score_test, mrr_test, num, pred_out = self.gat_poi.test(out)\n",
        "            return acc, f1_score_test, mrr_test, 1, 1, 1, num, pred_out\n",
        "        else:\n",
        "            a1, a3, a5, a10, f1, mrr, num, pred_out = self.gat.test(out)\n",
        "            return a1, a3, a5, a10, f1, mrr, num, pred_out\n",
        "\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads, args, drop=0.6):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(0)\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, output_dim, concat=False,\n",
        "                             heads=10, dropout=0.6)\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop1 = nn.Dropout(p=drop)\n",
        "        self.drop2 = nn.Dropout(p=0.6)\n",
        "\n",
        "        # 原始边索引\n",
        "        self.original_edge_index = torch.load('/content/drive/MyDrive/USPM_edege_add/data/edge_index.pt').t().contiguous().to(args.device)\n",
        "\n",
        "        self.y = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/function/label_all_function.npy', allow_pickle=True)).long().to(args.device)\n",
        "        self.train_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/function/label_mask.npy', allow_pickle=True)).to(args.device)\n",
        "        self.mask = torch.load('/content/drive/MyDrive/USPM_edege_add/data/function/test_mask.pt')\n",
        "        self.y_testlabel = np.load('/content/drive/MyDrive/USPM_edege_add/data/function/label_all_function.npy')[self.mask]\n",
        "\n",
        "    def forward(self, street_embedding, similarity_edges=None):\n",
        "        num_original_edges = self.original_edge_index.size(1)\n",
        "\n",
        "        # 合并原始边和相似度边\n",
        "        if similarity_edges is not None and similarity_edges.size(1) > 0:\n",
        "            num_similarity_edges = similarity_edges.size(1)\n",
        "            edge_index = torch.cat([self.original_edge_index, similarity_edges], dim=1)\n",
        "            # 去除重复边\n",
        "            edge_index_before_unique = edge_index.size(1)\n",
        "            edge_index = torch.unique(edge_index, dim=1)\n",
        "            num_final_edges = edge_index.size(1)\n",
        "            num_duplicates = edge_index_before_unique - num_final_edges\n",
        "\n",
        "            print(f\"Final total edges: {num_final_edges} (增加了 {num_final_edges - num_original_edges} 条边)\")\n",
        "\n",
        "        street_embedding = self.drop1(street_embedding)\n",
        "        street_embedding_1 = self.conv1(street_embedding, edge_index)\n",
        "        street_embedding_2 = self.elu(street_embedding_1)\n",
        "        street_embedding_2 = self.drop2(street_embedding_2)\n",
        "        street_embedding_2 = self.conv2(street_embedding_2, edge_index)\n",
        "\n",
        "        cross_criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss_su = cross_criterion(street_embedding_2[self.train_mask], self.y[self.train_mask])\n",
        "\n",
        "        return loss_su, street_embedding_1, street_embedding_2\n",
        "\n",
        "    def test(self, out):\n",
        "        pred = out.argmax(dim=1)\n",
        "        pred = pd.DataFrame({'Type': torch.Tensor.cpu(pred).numpy()})\n",
        "\n",
        "        predictions_test_dim = torch.Tensor.cpu(out[self.mask]).argmax(dim=1).detach().numpy()\n",
        "        predictions_test = torch.Tensor.cpu(out[self.mask]).detach().numpy()\n",
        "\n",
        "        A1 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=1, labels=range(10))\n",
        "        A3 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=3, labels=range(10))\n",
        "        A5 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=5, labels=range(10))\n",
        "        print(f'A1={A1}\\t A3={A3}\\t A5={A5} ')\n",
        "\n",
        "        precision_score_test = precision_score(self.y_testlabel, predictions_test_dim, average=\"weighted\")\n",
        "        f1_score_test = f1_score(self.y_testlabel, predictions_test_dim, average=\"weighted\")\n",
        "        mrr_test = compute_mrr(self.y_testlabel, predictions_test)\n",
        "        result = Counter(pred['Type'].values.tolist())\n",
        "        num = len(result)\n",
        "        print(\n",
        "            f'precision={precision_score_test}, f1={f1_score_test}, mrr={mrr_test},num={num}')\n",
        "\n",
        "        print(result)\n",
        "        return A1, A3, A5, 1, f1_score_test, mrr_test, num, out\n",
        "\n",
        "\n",
        "class GAT_P(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads, args, drop=0.6):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=drop)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, output_dim, concat=False,\n",
        "                             heads=4, dropout=drop)\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop1 = nn.Dropout(p=drop)\n",
        "        self.drop2 = nn.Dropout(p=drop)\n",
        "\n",
        "        # 原始边索引\n",
        "        self.original_edge_index = torch.load('/content/drive/MyDrive/USPM_edege_add/data/edge_index.pt').t().contiguous().to(args.device)\n",
        "\n",
        "        self.y = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/label_all_poi_level.npy', allow_pickle=True)).long().to(args.device)\n",
        "        self.train_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/label_mask_poi_level.npy', allow_pickle=True)).to(args.device)\n",
        "        self.test_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/test_mask_poi_level.npy', allow_pickle=True)).to(args.device)\n",
        "\n",
        "        self.mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/test_mask_poi_level.npy', allow_pickle=True))\n",
        "\n",
        "        self.y_testlabel = np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/label_all_poi_level.npy')[self.mask]\n",
        "\n",
        "    def forward(self, street_embedding, similarity_edges=None):\n",
        "        num_original_edges = self.original_edge_index.size(1)\n",
        "\n",
        "        # 合并原始边和相似度边\n",
        "        if similarity_edges is not None and similarity_edges.size(1) > 0:\n",
        "            num_similarity_edges = similarity_edges.size(1)\n",
        "            edge_index = torch.cat([self.original_edge_index, similarity_edges], dim=1)\n",
        "            # 去除重复边\n",
        "            edge_index_before_unique = edge_index.size(1)\n",
        "            edge_index = torch.unique(edge_index, dim=1)\n",
        "            num_final_edges = edge_index.size(1)\n",
        "            num_duplicates = edge_index_before_unique - num_final_edges\n",
        "\n",
        "            print(f\"Final total edges: {num_final_edges} (增加了 {num_final_edges - num_original_edges} 条边)\")\n",
        "\n",
        "        street_embedding = self.drop1(street_embedding)\n",
        "        street_embedding = self.conv1(street_embedding, edge_index)\n",
        "        street_embedding = self.elu(street_embedding)\n",
        "        street_embedding = self.drop2(street_embedding)\n",
        "        street_embedding = self.conv2(street_embedding, edge_index)\n",
        "\n",
        "        cross_criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss_su = cross_criterion(street_embedding[self.train_mask], self.y[self.train_mask])\n",
        "\n",
        "        return loss_su, street_embedding\n",
        "\n",
        "    def test(self, out):\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = pred[self.test_mask] == self.y[self.test_mask]\n",
        "        acc = int(correct.sum()) / int(self.test_mask.sum())\n",
        "\n",
        "        pred = pd.DataFrame({'Type': torch.Tensor.cpu(pred).numpy()})\n",
        "\n",
        "        predictions_test_dim = torch.Tensor.cpu(out[self.mask]).argmax(dim=1).detach().numpy()\n",
        "        predictions_test = torch.Tensor.cpu(out[self.mask]).detach().numpy()\n",
        "        f1_score_test = f1_score(self.y_testlabel, predictions_test_dim, average=\"macro\")\n",
        "        mrr_test = compute_mrr(self.y_testlabel, predictions_test)\n",
        "        result = Counter(pred['Type'].values.tolist())\n",
        "        num = len(result)\n",
        "        print(\n",
        "            f'acc={acc}, f1={f1_score_test}, mrr={mrr_test},num={num}')\n",
        "\n",
        "        print(result)\n",
        "        return acc, f1_score_test, mrr_test, num, out\n",
        "\n",
        "\n",
        "def compute_mrr(true_labels, machine_preds):\n",
        "    \"\"\"Compute the MRR \"\"\"\n",
        "    rr_total = 0.0\n",
        "    for i in range(len(true_labels)):\n",
        "        if true_labels[i] == 403:\n",
        "            continue\n",
        "        ranklist = list(np.argsort(machine_preds[i])[::-1])\n",
        "        rank = ranklist.index(true_labels[i]) + 1\n",
        "        rr_total = rr_total + 1.0 / rank\n",
        "    mrr = rr_total / len(true_labels)\n",
        "    return mrr"
      ],
      "metadata": {
        "id": "Itecz6Z6Cg4O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "# from model import SV_GAT\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "parser = argparse.ArgumentParser()\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "\n",
        "parser.add_argument('--device', type=str, default='cuda:0', help='gpu device ids')\n",
        "parser.add_argument('--print_num', type=int, default=2, help='gap of print evaluations')\n",
        "parser.add_argument(\"--print_epoch\", type=int, default=0, help=\"Start print epoch\")\n",
        "parser.add_argument(\"--start_epoch\", type=int, default=0, help=\"Start epoch\")\n",
        "parser.add_argument(\"--current_epoch\", type=int, default=0, help=\"Current epoch\")\n",
        "parser.add_argument(\"--epochs\", type=int, default=200, help=\"Epochs\")\n",
        "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed.\")\n",
        "parser.add_argument(\"--rounds\", type=int, default=5, help=\"number of training rounds\")\n",
        "parser.add_argument(\"--mode\", type=str, default='lstm', help=\"aggression function.\")\n",
        "# parser.add_argument(\"--pretrain_scn_path\", type=str, default='', help=\"Path to pretrained scene embeddings\")\n",
        "\n",
        "args = parser.parse_args([])\n",
        "\n",
        "def trainer(args, model, optimizer1, optimizer2, optimizer3, optimizer4, epoch):\n",
        "    loss_epoch = []\n",
        "    model.train()\n",
        "    optimizer1.zero_grad() # attention\n",
        "    optimizer2.zero_grad() # sv_agg(lstm)\n",
        "    optimizer3.zero_grad() # gat\n",
        "    optimizer4.zero_grad() # mlp\n",
        "\n",
        "    gnn_loss, pre_out, street_embedding = model()\n",
        "    loss_epoch.append(gnn_loss.item())\n",
        "    loss = gnn_loss\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer1.step()\n",
        "    optimizer2.step()\n",
        "    optimizer3.step()\n",
        "    optimizer4.step()\n",
        "\n",
        "    if epoch % args.print_num == 0:\n",
        "        print(f\"TrainEpoch [{epoch + 1}/{args.epochs}]\\t loss_epoch_gnn:{np.mean(loss_epoch)}\")\n",
        "    return np.mean(loss_epoch), pre_out, street_embedding\n",
        "\n",
        "def test(args, model, epoch, round_num, result_dir):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        _, out, _ = model()\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        os.makedirs(result_dir, exist_ok=True)\n",
        "        if args.downstream == 'poi':\n",
        "            acc, f1, mrr, _, _, _, num, pred_out = model.test(out)\n",
        "            result = {\n",
        "                'epoch': epoch + 1,\n",
        "                'acc': acc,\n",
        "                'f1': f1,\n",
        "                'mrr': mrr,\n",
        "                'num': num,\n",
        "                'use_similarity': args.use_similarity,\n",
        "                'similarity_top_k': args.similarity_top_k\n",
        "            }\n",
        "            return acc, f1, mrr, 1, 1, 1, num, pred_out, result\n",
        "        else:\n",
        "            a1, a3, a5, a10, f1, mrr, num, pred_out = model.test(out)\n",
        "            result = {\n",
        "                'epoch': epoch + 1,\n",
        "                'a1': a1,\n",
        "                'a3': a3,\n",
        "                'a5': a5,\n",
        "                'a10': a10,\n",
        "                'f1': f1,\n",
        "                'mrr': mrr,\n",
        "                'num': num,\n",
        "                'use_similarity': args.use_similarity,\n",
        "                'similarity_top_k': args.similarity_top_k\n",
        "            }\n",
        "            return a1, a3, a5, a10, f1, mrr, num, pred_out, result\n",
        "\n",
        "def calculate_best_results(result_dir, downstream):\n",
        "    # Collect round files\n",
        "    round_files = [f for f in os.listdir(result_dir) if f.startswith('round_') and f.endswith('.npy')]\n",
        "    if not round_files:\n",
        "        return None\n",
        "\n",
        "    # Load all results and group by epoch\n",
        "    epoch_results = {}\n",
        "    for round_file in round_files:\n",
        "        round_data = np.load(os.path.join(result_dir, round_file), allow_pickle=True).item()\n",
        "        for epoch_data in round_data['epochs']:\n",
        "            epoch = epoch_data['epoch']\n",
        "            if epoch not in epoch_results:\n",
        "                epoch_results[epoch] = []\n",
        "            epoch_results[epoch].append(epoch_data)\n",
        "\n",
        "    # Compute per-epoch averages across rounds\n",
        "    epoch_averages = {}\n",
        "    best_f1 = -1\n",
        "    best_epoch = None\n",
        "\n",
        "    if downstream == 'poi':\n",
        "        all_results = []\n",
        "        for epoch in epoch_results:\n",
        "            accs = [r['acc'] for r in epoch_results[epoch]]\n",
        "            f1s = [r['f1'] for r in epoch_results[epoch]]\n",
        "            mrrs = [r['mrr'] for r in epoch_results[epoch]]\n",
        "            epoch_averages[epoch] = {\n",
        "                'avg_acc': np.mean(accs),\n",
        "                'avg_f1': np.mean(f1s),\n",
        "                'avg_mrr': np.mean(mrrs)\n",
        "            }\n",
        "            all_results.extend(epoch_results[epoch])\n",
        "            if epoch_averages[epoch]['avg_f1'] > best_f1:\n",
        "                best_f1 = epoch_averages[epoch]['avg_f1']\n",
        "                best_epoch = epoch\n",
        "\n",
        "        # Store best epoch results and overall max metrics\n",
        "        best_results = {\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_epoch_avg_acc': epoch_averages[best_epoch]['avg_acc'],\n",
        "            'best_epoch_avg_f1': epoch_averages[best_epoch]['avg_f1'],\n",
        "            'best_epoch_avg_mrr': epoch_averages[best_epoch]['avg_mrr'],\n",
        "            'overall_best_acc': max([r['acc'] for r in all_results]),\n",
        "            'overall_best_f1': max([r['f1'] for r in all_results]),\n",
        "            'overall_best_mrr': max([r['mrr'] for r in all_results])\n",
        "        }\n",
        "    else:\n",
        "        all_results = []\n",
        "        for epoch in epoch_results:\n",
        "            a1s = [r['a1'] for r in epoch_results[epoch]]\n",
        "            a3s = [r['a3'] for r in epoch_results[epoch]]\n",
        "            a5s = [r['a5'] for r in epoch_results[epoch]]\n",
        "            a10s = [r['a10'] for r in epoch_results[epoch]]\n",
        "            f1s = [r['f1'] for r in epoch_results[epoch]]\n",
        "            mrrs = [r['mrr'] for r in epoch_results[epoch]]\n",
        "            epoch_averages[epoch] = {\n",
        "                'avg_a1': np.mean(a1s),\n",
        "                'avg_a3': np.mean(a3s),\n",
        "                'avg_a5': np.mean(a5s),\n",
        "                'avg_a10': np.mean(a10s),\n",
        "                'avg_f1': np.mean(f1s),\n",
        "                'avg_mrr': np.mean(mrrs)\n",
        "            }\n",
        "            all_results.extend(epoch_results[epoch])\n",
        "            if epoch_averages[epoch]['avg_f1'] > best_f1:\n",
        "                best_f1 = epoch_averages[epoch]['avg_f1']\n",
        "                best_epoch = epoch\n",
        "\n",
        "        # Store best epoch results and overall max metrics\n",
        "        best_results = {\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_epoch_avg_a1': epoch_averages[best_epoch]['avg_a1'],\n",
        "            'best_epoch_avg_a3': epoch_averages[best_epoch]['avg_a3'],\n",
        "            'best_epoch_avg_a5': epoch_averages[best_epoch]['avg_a5'],\n",
        "            'best_epoch_avg_a10': epoch_averages[best_epoch]['avg_a10'],\n",
        "            'best_epoch_avg_f1': epoch_averages[best_epoch]['avg_f1'],\n",
        "            'best_epoch_avg_mrr': epoch_averages[best_epoch]['avg_mrr'],\n",
        "            'overall_best_a1': max([r['a1'] for r in all_results]),\n",
        "            'overall_best_a3': max([r['a3'] for r in all_results]),\n",
        "            'overall_best_a5': max([r['a5'] for r in all_results]),\n",
        "            'overall_best_a10': max([r['a10'] for r in all_results]),\n",
        "            'overall_best_f1': max([r['f1'] for r in all_results]),\n",
        "            'overall_best_mrr': max([r['mrr'] for r in all_results])\n",
        "        }\n",
        "\n",
        "    # Save per-epoch averages and best results\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    np.save(f'{result_dir}/epoch_averages_{timestamp}.npy', epoch_averages)\n",
        "    np.save(f'{result_dir}/best_results_{timestamp}.npy', best_results)\n",
        "    return best_results\n",
        "\n",
        "def run_training(pretrain_sv_path, result_subdir):\n",
        "    result_dir = f'/content/drive/MyDrive/USPM_edege_add/result/{result_subdir}'\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for downstream in ['function', 'poi']:\n",
        "        print(f\"\\nStarting {downstream} downstream with {pretrain_sv_path}\")\n",
        "\n",
        "        args.downstream = downstream\n",
        "        args.pretrain_sv_path = pretrain_sv_path\n",
        "        # Set pretrain_scn_path based on downstream task\n",
        "        if downstream == 'function':\n",
        "            args.pretrain_scn_path = '/content/drive/MyDrive/USPM_edege_add/embeddings/qwen_text_embedding_function_72.pt'\n",
        "        else:  # downstream == 'poi'\n",
        "            args.pretrain_scn_path = '/content/drive/MyDrive/USPM_edege_add/embeddings/qwen_text_embedding_poi_72.pt'\n",
        "        args.current_epoch = 0\n",
        "\n",
        "        for round_num in range(args.rounds):\n",
        "            print(f\"Round {round_num + 1}/{args.rounds}\")\n",
        "\n",
        "            np.random.seed(args.seed + round_num)\n",
        "            random.seed(args.seed + round_num + 1)\n",
        "            torch.manual_seed(args.seed + round_num + 2)\n",
        "            torch.cuda.manual_seed(args.seed + round_num + 3)\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "\n",
        "            model = SV_GAT(args)\n",
        "            model = model.to(args.device)\n",
        "\n",
        "            opt1 = torch.optim.Adam(\n",
        "                itertools.chain(model.attention_soft.parameters()),\n",
        "                lr=0.0005, weight_decay=1e-8)\n",
        "            opt4 = torch.optim.Adam(\n",
        "                model.text_mlp.parameters(),\n",
        "                lr=0.0005, weight_decay=1e-8)  # MLP和attention一样的设置\n",
        "            if args.downstream == 'poi':\n",
        "                opt3 = torch.optim.Adam(model.gat_poi.parameters(), lr=0.0005, weight_decay=5e-4)\n",
        "                args.epochs = 250\n",
        "            else:\n",
        "                opt3 = torch.optim.Adam(model.gat.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "                args.epochs = 250\n",
        "\n",
        "            if args.mode != 'mean':\n",
        "                opt2 = torch.optim.SGD(model.sv_agg.parameters(), lr=0.005, weight_decay=1e-4, momentum=0.9)\n",
        "                t = 10\n",
        "                T = 800\n",
        "                n_t = 0.5\n",
        "                lf = lambda epoch: (0.9 * epoch / t + 0.1) if epoch < t else 0.1 if n_t * (\n",
        "                        1 + math.cos(math.pi * (epoch - t) / (T - t))) < 0.1 else n_t * (\n",
        "                        1 + math.cos(math.pi * (epoch - t) / (T - t)))\n",
        "                scheduler = torch.optim.lr_scheduler.LambdaLR(opt2, lr_lambda=lf)\n",
        "            else:\n",
        "                opt2 = torch.optim.SGD(model.sv_agg.parameters(), lr=0.005, weight_decay=1e-4, momentum=0.9)\n",
        "\n",
        "            print(model)\n",
        "\n",
        "            # Collect results for this round\n",
        "            round_results = {'round': round_num, 'epochs': []}\n",
        "\n",
        "            for epoch in range(args.start_epoch, args.epochs):\n",
        "                loss_epoch, pred_, street_embedding = trainer(args, model, opt1, opt2, opt3, opt4, epoch)\n",
        "                if args.mode != 'mean':\n",
        "                    scheduler.step()\n",
        "                if epoch % args.print_num == 0:\n",
        "                    result_tuple = test(args, model, epoch, round_num, f'{result_dir}/{downstream}')\n",
        "                    # Append result to round_results\n",
        "                    round_results['epochs'].append(result_tuple[-1])  # Last element is the result dict\n",
        "\n",
        "            # Save all results for this round in a single file\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            round_filename = f'round_{round_num}_{timestamp}'\n",
        "            np.save(f'{result_dir}/{downstream}/{round_filename}.npy', round_results)\n",
        "\n",
        "        # Calculate and save average and best results\n",
        "        best_results = calculate_best_results(f'{result_dir}/{downstream}', downstream)\n",
        "        print(f\"Best Results for {downstream}:\", best_results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 可以选择运行单个实验或者相似度对比实验\n",
        "\n",
        "    # 选项1: 运行单个实验（使用命令行参数设置）\n",
        "    run_training('/content/drive/MyDrive/USPM_edege_add/embeddings/image_representation_117144_16.pt', 'image16_edege_add')\n",
        "\n",
        "    # 选项2: 运行相似度对比实验（注释掉上面的代码，取消下面的注释）\n",
        "    # run_similarity_experiments()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "38DhyoaFHDOU",
        "outputId": "12534272-c6e7-4c69-bc8b-cabda70012b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting function downstream with /content/drive/MyDrive/USPM_edege_add/embeddings/image_representation_117144_16.pt\n",
            "Round 1/5\n",
            "SV_GAT(\n",
            "  (text_mlp): Text_MLP(\n",
            "    (layer1): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (layer2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "  )\n",
            "  (sv_agg): SVFeatureBlock(\n",
            "    (lstm): LSTM(768, 768, batch_first=True)\n",
            "  )\n",
            "  (attention_soft): Attention_Soft(\n",
            "    (l1): Linear(in_features=768, out_features=32, bias=True)\n",
            "    (ac): Sigmoid()\n",
            "    (l2): Linear(in_features=768, out_features=32, bias=False)\n",
            "    (l3): Linear(in_features=32, out_features=1, bias=False)\n",
            "  )\n",
            "  (gat): GAT(\n",
            "    (conv1): GATConv(768, 64, heads=8)\n",
            "    (conv2): GATConv(512, 10, heads=10)\n",
            "    (elu): ELU(alpha=1.0)\n",
            "    (drop1): Dropout(p=0.6, inplace=False)\n",
            "    (drop2): Dropout(p=0.6, inplace=False)\n",
            "  )\n",
            "  (gat_poi): GAT_P(\n",
            "    (conv1): GATConv(768, 64, heads=8)\n",
            "    (conv2): GATConv(512, 4, heads=4)\n",
            "    (elu): ELU(alpha=1.0)\n",
            "    (drop1): Dropout(p=0.6, inplace=False)\n",
            "    (drop2): Dropout(p=0.6, inplace=False)\n",
            "  )\n",
            ")\n",
            "Similarity threshold: 0.950\n",
            "Found 685113 node pairs with similarity >= 0.950\n",
            "Final total edges: 710015 (增加了 682725 条边)\n",
            "TrainEpoch [1/250]\t loss_epoch_gnn:2.7641780376434326\n",
            "Similarity threshold: 0.950\n",
            "Found 8876932 node pairs with similarity >= 0.950\n",
            "Final total edges: 8894777 (增加了 8867487 条边)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 16.98 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.40 GiB is free. Process 40996 has 31.15 GiB memory in use. Of the allocated memory 19.76 GiB is allocated by PyTorch, and 10.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-844709060.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# 选项1: 运行单个实验（使用命令行参数设置）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/USPM_edege_add/embeddings/image_representation_117144_16.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image16_edege_add'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# 选项2: 运行相似度对比实验（注释掉上面的代码，取消下面的注释）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-11-844709060.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(pretrain_sv_path, result_subdir)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     \u001b[0mresult_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{result_dir}/{downstream}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                     \u001b[0;31m# Append result to round_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0mround_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Last element is the result dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-11-844709060.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(args, model, epoch, round_num, result_dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d_%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-9-3229692646.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mgat_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat_poi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreet_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mgat_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_emb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreet_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgat_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-9-3229692646.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, street_embedding, similarity_edges)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mstreet_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreet_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mstreet_embedding_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreet_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mstreet_embedding_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreet_embedding_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mstreet_embedding_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreet_embedding_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_propagate_b4w_invd.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# End Message Forward Pre Hook #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         out = self.message(\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mx_j\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, alpha)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.98 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.40 GiB is free. Process 40996 has 31.15 GiB memory in use. Of the allocated memory 19.76 GiB is allocated by PyTorch, and 10.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ]
}