{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPGvqJBU8G7yL/rcp47Qpiz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/deeplabv3_1223.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feSXBcBVIHS6",
        "outputId": "1aa47ec9-3c6d-4813-f5a0-08f6516ddd07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pillow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VainF/DeepLabV3Plus-Pytorch.git\n",
        "!cd DeepLabV3Plus-Pytorch\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qbhZEl6ITD2",
        "outputId": "8cfc73c9-e00d-477a-ac8f-5b7156a02547"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepLabV3Plus-Pytorch'...\n",
            "remote: Enumerating objects: 705, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 705 (delta 25), reused 15 (delta 15), pack-reused 668 (from 2)\u001b[K\n",
            "Receiving objects: 100% (705/705), 8.26 MiB | 4.10 MiB/s, done.\n",
            "Resolving deltas: 100% (380/380), done.\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd DeepLabV3Plus-Pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC8fl5kPIx7j",
        "outputId": "fa0273bb-b8c7-4928-cb6d-7dfb2794cb6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepLabV3Plus-Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAQQ2K73JbD7",
        "outputId": "4948fb28-0700-456f-f40a-942792b3e27a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (11.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.8.0)\n",
            "Collecting visdom (from -r requirements.txt (line 8))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 8)) (6.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 8)) (1.33)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 8)) (1.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch->visdom->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->-r requirements.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->-r requirements.txt (line 8)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->-r requirements.txt (line 8)) (2024.12.14)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=c6503e22c03f1cea896a1b897a63d8666e0a4a9e1cbb247bb909de1057ddfd08\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: visdom\n",
            "Successfully installed visdom-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir checkpoints"
      ],
      "metadata": {
        "id": "clOwiAHwLXL_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwWE-UOoLxyo",
        "outputId": "8375a3bb-f9b8-4dfc-da82-ef859cd1e7ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/UrbanASIF/anchor_Shenzhen.zip -d ./datasets/anchore_Shenzhen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwC2aw7DQwmE",
        "outputId": "6b060508-026e-4a35-b6d3-5543c933866e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/UrbanASIF/anchor_Shenzhen.zip\n",
            "  inflating: ./datasets/anchore_Shenzhen/0.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/100.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1021.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/106.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1062.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/107.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1073.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/108.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1087.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1110.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1111.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1166.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1175.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/118.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1180.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/119.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/121.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1219.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1232.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1233.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1246.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/125.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1265.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1286.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1291.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/13.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/130.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1303.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1308.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/132.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1320.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/133.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/135.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1356.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/14.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1428.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/144.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/1461.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/15.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/157.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/159.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/167.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/17.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/174.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/179.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/182.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/185.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/187.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/195.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/196.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/198.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/2.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/200.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/205.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/208.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/21.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/210.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/223.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/228.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/23.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/236.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/237.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/25.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/256.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/26.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/263.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/285.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/293.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/295.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/3.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/301.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/304.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/31.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/316.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/318.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/33.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/334.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/339.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/365.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/377.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/378.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/38.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/392.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/4.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/41.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/411.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/422.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/43.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/454.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/466.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/468.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/474.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/48.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/483.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/506.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/517.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/543.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/55.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/556.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/57.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/571.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/589.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/590.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/593.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/6.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/616.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/621.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/637.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/65.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/652.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/7.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/70.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/702.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/709.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/71.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/717.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/719.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/72.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/722.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/73.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/751.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/752.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/769.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/781.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/8.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/802.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/825.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/858.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/86.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/865.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/87.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/873.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/88.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/890.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/9.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/915.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/946.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/95.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/96.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/98.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/983.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/99.png  \n",
            "  inflating: ./datasets/anchore_Shenzhen/predict_label_primary_correct_unique.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "import network.modeling  # 从 DeepLabV3Plus-Pytorch 导入\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 定义模型参数\n",
        "MODEL_NAME = 'deeplabv3plus_mobilenet'  # 可选: 'deeplabv3plus_resnet50', 'deeplabv3plus_mobilenet', etc.\n",
        "NUM_CLASSES = 19  # Cityscapes 通常有19类\n",
        "OUTPUT_STRIDE = 16  # 输出步幅，通常为 16\n",
        "\n",
        "# 初始化模型\n",
        "model = network.modeling.__dict__[MODEL_NAME](num_classes=NUM_CLASSES, output_stride=OUTPUT_STRIDE)\n",
        "\n",
        "# 加载预训练权重\n",
        "CHECKPOINT_PATH = './checkpoints/best_deeplabv3plus_mobilenet_cityscapes_os16.pth'  # 替换为实际路径\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "# 移动模型到设备并设置为评估模式\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 定义图像预处理\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),  # DeepLabV3+ 常用较大输入尺寸\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet 均值\n",
        "        std=[0.229, 0.224, 0.225]    # ImageNet 方差\n",
        "    )\n",
        "])\n",
        "\n",
        "# 定义全局变量用于存储提取的特征\n",
        "extracted_features = []\n",
        "\n",
        "def hook_fn(module, input, output):\n",
        "    \"\"\"\n",
        "    Hook 函数，将 ASPP 层的输出特征图进行全局平均池化和归一化。\n",
        "\n",
        "    Args:\n",
        "        module: 当前挂载 Hook 的模块\n",
        "        input: 输入张量（未使用）\n",
        "        output: 输出张量，即 ASPP 层的输出特征图 [B, 256, H', W']\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # 全局平均池化，沿 H' 和 W' 维度求平均\n",
        "        features = output.mean(dim=[2, 3])  # [B, 256]\n",
        "        # 归一化\n",
        "        features = features / features.norm(dim=-1, keepdim=True)  # [B, 256]\n",
        "        # 将特征移动到 CPU 并添加到全局列表\n",
        "        extracted_features.append(features.cpu())\n",
        "\n",
        "# 注册 Hook 到 ASPP 层（假设 ASPP 是 classifier[0]）\n",
        "hook = model.classifier[0].register_forward_hook(hook_fn)\n",
        "\n",
        "def extract_features_hooks(image_folder, output_file, model):\n",
        "    global extracted_features\n",
        "    extracted_features = []  # 重置特征列表\n",
        "\n",
        "    # 获取并按文件名中的数字顺序排序图像路径\n",
        "    image_paths = sorted(\n",
        "        [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.png'))\n",
        "        ],\n",
        "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "    )\n",
        "\n",
        "    # 处理每一张图像\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 打开图像并确保是RGB格式\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            # 预处理\n",
        "            inputs = preprocess(image).unsqueeze(0).to(device)  # [1, 3, 512, 512]\n",
        "\n",
        "            # 前向传播获取特征\n",
        "            with torch.no_grad():\n",
        "                model(inputs)\n",
        "                # Hook 已自动将特征添加到 `extracted_features`\n",
        "\n",
        "            # 可选: 检查是否成功提取特征\n",
        "            if len(extracted_features) == 0:\n",
        "                print(f\"No features extracted for {image_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 移除 Hook\n",
        "    hook.remove()\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量并保存\n",
        "    if len(extracted_features) > 0:\n",
        "        image_features = torch.cat(extracted_features, dim=0)  # [N, 256]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"特征已保存到 {output_file}\")\n",
        "    else:\n",
        "        print(f\"在 {image_folder} 中未找到有效的图像\")\n",
        "\n",
        "# 调用特征提取函数\n",
        "extract_features_hooks(\n",
        "    image_folder='./datasets/anchor_Shenzhen',  # 替换为你的图像文件夹路径\n",
        "    output_file='./Anchor/imgs_deeplabv3plus_ASPP_anchor.pt',  # 替换为你想保存的路径\n",
        "    model=model\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "WokZfHD3ShoK",
        "outputId": "75606588-113b-4427-f5a7-ac3ea1886072"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 195MB/s]\n",
            "<ipython-input-20-14c190f986b0>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'DeepLabHeadV3Plus' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-14c190f986b0>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# 注册 Hook 到 ASPP 层（假设 ASPP 是 classifier[0]）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_features_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DeepLabHeadV3Plus' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXpSeSq4WvqZ",
        "outputId": "00397675-9635-4b24-cbde-ae17e44ff596"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepLabV3(\n",
            "  (backbone): IntermediateLayerGetter(\n",
            "    (low_level_features): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (high_level_features): Sequential(\n",
            "      (4): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (7): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (12): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (13): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (14): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (15): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (16): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (17): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): ConvBNReLU(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): ConvBNReLU(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): DeepLabHeadV3Plus(\n",
            "    (project): Sequential(\n",
            "      (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (aspp): ASPP(\n",
            "      (convs): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ASPPConv(\n",
            "          (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ASPPConv(\n",
            "          (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): ASPPConv(\n",
            "          (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): ASPPPooling(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (classifier): Sequential(\n",
            "      (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.classifier.aspp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb5uw-YkX1U-",
        "outputId": "34b2608a-f7fb-49a1-9610-4ad2a42efdee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASPP(\n",
            "  (convs): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): ASPPConv(\n",
            "      (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): ASPPConv(\n",
            "      (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): ASPPConv(\n",
            "      (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): ASPPPooling(\n",
            "      (0): AdaptiveAvgPool2d(output_size=1)\n",
            "      (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (project): Sequential(\n",
            "    (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "import network.modeling  # 从 DeepLabV3Plus-Pytorch 导入\n",
        "\n",
        "# 设置设备为 GPU（如果可用）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 定义模型参数\n",
        "MODEL_NAME = 'deeplabv3plus_mobilenet'  # 可选: 'deeplabv3plus_resnet50', 'deeplabv3plus_resnet101', etc.\n",
        "NUM_CLASSES = 19  # Cityscapes 通常有19类\n",
        "OUTPUT_STRIDE = 16  # 输出步幅，通常为 16\n",
        "\n",
        "# 初始化模型\n",
        "model = network.modeling.__dict__[MODEL_NAME](num_classes=NUM_CLASSES, output_stride=OUTPUT_STRIDE)\n",
        "\n",
        "# 加载预训练权重\n",
        "CHECKPOINT_PATH = './checkpoints/best_deeplabv3plus_mobilenet_cityscapes_os16.pth'  # 替换为实际路径\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "# 加载 state_dict\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "# 移动模型到设备并设置为评估模式\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 定义图像预处理（与训练时保持一致）\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),  # DeepLabV3+ 常用较大输入尺寸\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet 均值\n",
        "        std=[0.229, 0.224, 0.225]    # ImageNet 方差\n",
        "    )\n",
        "])\n",
        "\n",
        "# 定义全局变量用于存储提取的特征\n",
        "extracted_features = []\n",
        "\n",
        "def hook_fn(module, input, output):\n",
        "    \"\"\"\n",
        "    Hook 函数，将 ASPP Project 层的输出特征图进行全局平均池化和归一化。\n",
        "\n",
        "    Args:\n",
        "        module: 当前挂载 Hook 的模块\n",
        "        input: 输入张量（未使用）\n",
        "        output: 输出张量，即 ASPP Project 层的输出特征图 [B, 256, H', W']\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # 全局平均池化，沿 H' 和 W' 维度求平均\n",
        "        features = output.mean(dim=[2, 3])  # [B, 256]\n",
        "        # 归一化\n",
        "        features = features / features.norm(dim=-1, keepdim=True)  # [B, 256]\n",
        "        # 将特征移动到 CPU 并添加到全局列表\n",
        "        extracted_features.append(features.cpu())\n",
        "\n",
        "# 注册 Hook 到 ASPP Project 层\n",
        "# 根据模型结构，ASPP Project 层为 model.classifier.aspp.project\n",
        "hook = model.classifier.aspp.project.register_forward_hook(hook_fn)\n",
        "\n",
        "def extract_features_hooks(image_folder, output_file, model):\n",
        "    global extracted_features\n",
        "    extracted_features = []  # 重置特征列表\n",
        "\n",
        "    # 获取并按文件名中的数字顺序排序图像路径\n",
        "    # 假设文件名为纯数字，如 '1.jpg', '2.png', etc.\n",
        "    try:\n",
        "        image_paths = sorted(\n",
        "            [\n",
        "                os.path.join(image_folder, img)\n",
        "                for img in os.listdir(image_folder)\n",
        "                if img.lower().endswith(('.jpg', '.png'))\n",
        "            ],\n",
        "            key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        "        )\n",
        "    except ValueError:\n",
        "        # 如果文件名包含非数字字符，按字母顺序排序\n",
        "        image_paths = sorted(\n",
        "            [\n",
        "                os.path.join(image_folder, img)\n",
        "                for img in os.listdir(image_folder)\n",
        "                if img.lower().endswith(('.jpg', '.png'))\n",
        "            ]\n",
        "        )\n",
        "        print(\"图像文件名包含非数字字符，已按字母顺序排序。\")\n",
        "\n",
        "    # 处理每一张图像\n",
        "    for image_path in tqdm(image_paths, desc=f\"Processing {image_folder}\"):\n",
        "        try:\n",
        "            # 打开图像并确保是RGB格式\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            # 预处理\n",
        "            inputs = preprocess(image).unsqueeze(0).to(device)  # [1, 3, 512, 512]\n",
        "\n",
        "            # 前向传播获取特征\n",
        "            with torch.no_grad():\n",
        "                model(inputs)\n",
        "                # Hook 已自动将特征添加到 `extracted_features`\n",
        "\n",
        "            # 可选: 检查是否成功提取特征\n",
        "            if len(extracted_features) == 0:\n",
        "                print(f\"No features extracted for {image_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理 {image_path} 时出错: {e}\")\n",
        "\n",
        "    # 移除 Hook\n",
        "    hook.remove()\n",
        "\n",
        "    # 将所有特征拼接成一个大的张量并保存\n",
        "    if len(extracted_features) > 0:\n",
        "        image_features = torch.cat(extracted_features, dim=0)  # [N, 256]\n",
        "        torch.save(image_features, output_file)\n",
        "        print(f\"特征已保存到 {output_file}\")\n",
        "    else:\n",
        "        print(f\"在 {image_folder} 中未找到有效的图像\")\n",
        "\n",
        "# 调用特征提取函数\n",
        "extract_features_hooks(\n",
        "    image_folder='./datasets/anchor_Shenzhen',  # 替换为你的图像文件夹路径\n",
        "    output_file='./imgs_deeplabv3plus_ASPP_anchor.pt',  # 替换为你想保存的路径\n",
        "    model=model\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDL-Yh7zaQlu",
        "outputId": "fadbfa01-4f2f-4188-e5e9-0fb7186c48e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-59f743e796b3>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
            "Processing ./datasets/anchor_Shenzhen: 100%|██████████| 143/143 [00:02<00:00, 49.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征已保存到 ./imgs_deeplabv3plus_ASPP_anchor.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载保存的特征文件\n",
        "image_features = torch.load('./imgs_deeplabv3plus_ASPP_anchor.pt')\n",
        "\n",
        "# 打印特征的形状\n",
        "print(f\"特征的形状: {image_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv2o4KYcgEj4",
        "outputId": "159e5e1b-1b9f-44e6-8ff4-3a4a688ba4ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征的形状: torch.Size([143, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-a601313eabfd>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  image_features = torch.load('./imgs_deeplabv3plus_ASPP_anchor.pt')\n"
          ]
        }
      ]
    }
  ]
}