{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOS0JgAdEqmNegjS5NJkM7R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoqiSheng/MoqiSheng.github.io/blob/main/250714_InfoNCE_256_0_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-7QsT8OIh6-",
        "outputId": "2d069858-95e5-49cb-81af-274b9d356cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVCh_h1ULlop",
        "outputId": "584baaeb-f273-49d1-a124-3831c8d6e753"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.7.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "class InfoNCELoss(nn.Module):\n",
        "    def __init__(self, temperature=0.5):\n",
        "        super(InfoNCELoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, anchor, positive, negatives):\n",
        "        batch_size = anchor.size(0)\n",
        "        device = anchor.device\n",
        "\n",
        "        # 计算相似度\n",
        "        pos_sim = F.cosine_similarity(anchor, positive, dim=1) / self.temperature  # [batch_size]\n",
        "\n",
        "        # 负样本相似度\n",
        "        anchor_expanded = anchor.unsqueeze(1)  # [batch_size, 1, feature_dim]\n",
        "        neg_sim = F.cosine_similarity(anchor_expanded, negatives, dim=2) / self.temperature  # [batch_size, num_negatives]\n",
        "\n",
        "        # 拼接正负样本相似度\n",
        "        logits = torch.cat([pos_sim.unsqueeze(1), neg_sim], dim=1)  # [batch_size, 1+num_negatives]\n",
        "\n",
        "        # 标签：正样本索引为0\n",
        "        labels = torch.zeros(batch_size, dtype=torch.long, device=device)\n",
        "\n",
        "        # 计算交叉熵损失\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "def compute_node_similarities(embeddings, batch_size=1000):\n",
        "    num_nodes = embeddings.shape[0]\n",
        "    device = embeddings.device\n",
        "\n",
        "    # 转换为numpy进行相似度计算（CPU上更稳定）\n",
        "    embeddings_cpu = embeddings.detach().cpu().numpy()\n",
        "\n",
        "    # 分批计算相似度\n",
        "    similarity_matrix = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "    for i in range(0, num_nodes, batch_size):\n",
        "        end_i = min(i + batch_size, num_nodes)\n",
        "        batch_embeddings = embeddings_cpu[i:end_i]\n",
        "\n",
        "        # 计算当前批次与所有节点的相似度\n",
        "        batch_similarities = cosine_similarity(batch_embeddings, embeddings_cpu)\n",
        "        similarity_matrix[i:end_i] = batch_similarities\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "\n",
        "def find_positive_negative_samples(similarity_matrix,\n",
        "                                 neg_min_sim=0.1, neg_max_sim=0.5, max_negatives=768,\n",
        "                                 pos_min_sim=0.9, max_positives=50, random_seed=42):\n",
        "    \"\"\"\n",
        "    同时计算正样本和负样本索引\n",
        "\n",
        "    Args:\n",
        "        similarity_matrix: 相似度矩阵\n",
        "        neg_min_sim, neg_max_sim: 负样本相似度范围\n",
        "        max_negatives: 最大负样本数量\n",
        "        pos_min_sim: 正样本最小相似度阈值\n",
        "        max_positives: 最大正样本数量\n",
        "        random_seed: 随机种子\n",
        "\n",
        "    Returns:\n",
        "        negative_indices: 负样本索引字典\n",
        "        positive_indices: 正样本索引字典\n",
        "    \"\"\"\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    num_nodes = similarity_matrix.shape[0]\n",
        "    negative_indices = {}\n",
        "    positive_indices = {}\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        sim_row = similarity_matrix[i]\n",
        "\n",
        "        # 找负样本：相似度在[neg_min_sim, neg_max_sim]范围内\n",
        "        neg_mask = (sim_row >= neg_min_sim) & (sim_row <= neg_max_sim)\n",
        "        neg_candidates = np.where(neg_mask)[0]\n",
        "        neg_candidates = neg_candidates[neg_candidates != i]  # 排除自己\n",
        "\n",
        "        if len(neg_candidates) > max_negatives:\n",
        "            neg_candidates = np.random.choice(neg_candidates, max_negatives, replace=False)\n",
        "\n",
        "        negative_indices[i] = neg_candidates.tolist()\n",
        "\n",
        "        # 找正样本：相似度大于pos_min_sim\n",
        "        pos_mask = sim_row > pos_min_sim\n",
        "        pos_candidates = np.where(pos_mask)[0]\n",
        "        pos_candidates = pos_candidates[pos_candidates != i]  # 排除自己\n",
        "\n",
        "        if len(pos_candidates) > max_positives:\n",
        "            pos_candidates = np.random.choice(pos_candidates, max_positives, replace=False)\n",
        "\n",
        "        positive_indices[i] = pos_candidates.tolist()\n",
        "\n",
        "    return negative_indices, positive_indices\n",
        "\n",
        "\n",
        "def get_positive_samples(embeddings, edge_index, node_indices, positive_indices=None, num_extra_positives=3, random_seed=42):\n",
        "    \"\"\"\n",
        "    获取正样本，包括邻居节点和额外的高相似度正样本\n",
        "\n",
        "    Args:\n",
        "        embeddings: 节点嵌入\n",
        "        edge_index: 边索引\n",
        "        node_indices: 节点索引列表\n",
        "        positive_indices: 额外正样本索引字典\n",
        "        num_extra_positives: 额外正样本数量\n",
        "        random_seed: 随机种子\n",
        "    \"\"\"\n",
        "    device = embeddings.device\n",
        "    positive_samples = []\n",
        "\n",
        "    # 设置随机种子\n",
        "    np.random.seed(random_seed)\n",
        "    torch.manual_seed(random_seed)\n",
        "\n",
        "    # 构建邻接列表\n",
        "    num_nodes = embeddings.size(0)\n",
        "    adj_list = {i: [] for i in range(num_nodes)}\n",
        "\n",
        "    for i in range(edge_index.size(1)):\n",
        "        src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
        "        adj_list[src].append(dst)\n",
        "\n",
        "    for node_id in node_indices:\n",
        "        # 获取原始邻居节点\n",
        "        neighbors = adj_list[node_id]\n",
        "        neighbor_embeddings_list = []\n",
        "\n",
        "        if len(neighbors) > 0:\n",
        "            neighbor_embeddings_list.append(embeddings[neighbors])  # [num_neighbors, feature_dim]\n",
        "\n",
        "        # 添加额外的高相似度正样本（如果有的话）\n",
        "        if positive_indices is not None and node_id in positive_indices:\n",
        "            extra_pos_candidates = positive_indices[node_id]\n",
        "\n",
        "            # 从候选中排除已经连接的邻居节点\n",
        "            extra_pos_candidates = [idx for idx in extra_pos_candidates if idx not in neighbors]\n",
        "\n",
        "            if len(extra_pos_candidates) > 0:\n",
        "                # 随机选择额外的正样本\n",
        "                num_to_select = min(num_extra_positives, len(extra_pos_candidates))\n",
        "                selected_extra_pos = np.random.choice(extra_pos_candidates, num_to_select, replace=False)\n",
        "                neighbor_embeddings_list.append(embeddings[selected_extra_pos])\n",
        "\n",
        "        # 计算正样本的平均嵌入\n",
        "        if len(neighbor_embeddings_list) > 0:\n",
        "            all_neighbor_embeddings = torch.cat(neighbor_embeddings_list, dim=0)\n",
        "            positive_sample = torch.mean(all_neighbor_embeddings, dim=0)\n",
        "        else:\n",
        "            # 如果没有邻居和额外正样本，使用自身嵌入\n",
        "            positive_sample = embeddings[node_id]\n",
        "\n",
        "        positive_samples.append(positive_sample)\n",
        "\n",
        "    return torch.stack(positive_samples)  # [len(node_indices), feature_dim]\n",
        "\n",
        "\n",
        "def get_negative_samples(embeddings, negative_indices, node_indices, num_negatives=256, random_seed=42):\n",
        "    \"\"\"获取负样本\"\"\"\n",
        "    np.random.seed(random_seed)\n",
        "    negative_samples = []\n",
        "\n",
        "    for node_id in node_indices:\n",
        "        if node_id in negative_indices and len(negative_indices[node_id]) > 0:\n",
        "            neg_indices = negative_indices[node_id]\n",
        "\n",
        "            # 随机选择负样本\n",
        "            if len(neg_indices) >= num_negatives:\n",
        "                selected_negatives = np.random.choice(neg_indices, num_negatives, replace=False)\n",
        "            else:\n",
        "                selected_negatives = neg_indices + np.random.choice(neg_indices,\n",
        "                                                                  num_negatives - len(neg_indices),\n",
        "                                                                  replace=True).tolist()\n",
        "\n",
        "            neg_embeddings = embeddings[selected_negatives]  # [num_negatives, feature_dim]\n",
        "        else:\n",
        "            # 如果没有负样本，随机选择\n",
        "            num_nodes = embeddings.size(0)\n",
        "            random_indices = np.random.choice(num_nodes, num_negatives, replace=False)\n",
        "            neg_embeddings = embeddings[random_indices]\n",
        "\n",
        "        negative_samples.append(neg_embeddings)\n",
        "\n",
        "    return torch.stack(negative_samples)  # [len(node_indices), num_negatives, feature_dim]\n",
        "\n",
        "\n",
        "def compute_infonce_loss_batch(embeddings, edge_index, negative_indices, positive_indices,\n",
        "                              node_batch, infonce_criterion, num_negatives=256, num_extra_positives=3, epoch=0):\n",
        "    \"\"\"\n",
        "    计算InfoNCE损失（批处理版本）\n",
        "\n",
        "    Args:\n",
        "        embeddings: 节点嵌入\n",
        "        edge_index: 边索引\n",
        "        negative_indices: 负样本索引\n",
        "        positive_indices: 正样本索引\n",
        "        node_batch: 节点批次\n",
        "        infonce_criterion: InfoNCE损失函数\n",
        "        num_negatives: 负样本数量\n",
        "        num_extra_positives: 额外正样本数量\n",
        "        epoch: 当前epoch（用作随机种子的一部分）\n",
        "    \"\"\"\n",
        "    # 使用epoch作为随机种子的一部分，确保可复现性\n",
        "    random_seed = 42 + epoch\n",
        "\n",
        "    # 获取锚点嵌入\n",
        "    anchor_embeddings = embeddings[node_batch]  # [batch_size, feature_dim]\n",
        "\n",
        "    # 获取正样本（包括额外的高相似度正样本）\n",
        "    positive_embeddings = get_positive_samples(embeddings, edge_index, node_batch,\n",
        "                                             positive_indices, num_extra_positives, random_seed)\n",
        "\n",
        "    # 获取负样本\n",
        "    negative_embeddings = get_negative_samples(embeddings, negative_indices,\n",
        "                                             node_batch, num_negatives, random_seed)\n",
        "\n",
        "    # 计算InfoNCE损失\n",
        "    batch_loss = infonce_criterion(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
        "\n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "rsiZgSrqLotJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import collections\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, \\\n",
        "    top_k_accuracy_score, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from transformers import AutoModel\n",
        "from torch_geometric.nn import GATConv, GCNConv\n",
        "from collections import Counter\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "\n",
        "class SVFeatureBlock(nn.Module):\n",
        "    def __init__(self, input_size=512, hidden_size=512, mode='mean'):\n",
        "        super(SVFeatureBlock, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        if mode == 'lstm':\n",
        "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "            nn.init.orthogonal_(self.lstm.weight_ih_l0)\n",
        "            nn.init.orthogonal_(self.lstm.weight_hh_l0)\n",
        "        elif mode == 'bi-lstm':\n",
        "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True,\n",
        "                                bidirectional=True)\n",
        "        elif self.mode == \"gru\":\n",
        "            self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "        elif mode == 'rnn':\n",
        "            self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "\n",
        "    def forward(self, sv):\n",
        "        sv_list = []\n",
        "        for x_tmp in sv:\n",
        "            if self.mode == \"mean\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.mean(x_tmp, dim=0)\n",
        "            elif self.mode == \"sum\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.sum(x_tmp, dim=0)\n",
        "            elif self.mode == \"max\":\n",
        "                if x_tmp.dim() != 1:\n",
        "                    out_put = torch.max(x_tmp, dim=0).values\n",
        "            elif self.mode == \"lstm\":\n",
        "                out_put, (h_n, c_n) = self.lstm(x_tmp.view(1, -1, self.input_size))\n",
        "                out_put = out_put[:, -1, :]\n",
        "                out_put = torch.squeeze(out_put)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            sv_list.append(out_put)\n",
        "        x = torch.stack(sv_list)  # 拼接,(batch,512)\n",
        "        return x\n",
        "\n",
        "\n",
        "def weights_init_1(m):\n",
        "    seed = 20\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "\n",
        "\n",
        "def weights_init_2(m):\n",
        "    seed = 20\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "    torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "class Attention_Soft(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size=32):\n",
        "        super(Attention_Soft, self).__init__()\n",
        "\n",
        "        self.l1 = torch.nn.Linear(in_size, hidden_size, bias=True)\n",
        "        self.ac = nn.Sigmoid()\n",
        "        self.l2 = torch.nn.Linear(in_size, hidden_size, bias=False)\n",
        "        self.l3 = torch.nn.Linear(int(hidden_size), 1, bias=False)\n",
        "\n",
        "        weights_init_2(self.l1)\n",
        "        weights_init_1(self.l2)\n",
        "        weights_init_1(self.l3)\n",
        "\n",
        "    def forward(self, z):\n",
        "        w1 = self.l1(torch.mean(z, dim=1).unsqueeze(1))\n",
        "        w2 = self.l2(z)\n",
        "        w = self.ac(w1 + w2)\n",
        "        w = self.l3(w)\n",
        "        beta = torch.softmax(w, dim=1)\n",
        "\n",
        "        return (beta * z).sum(1)\n",
        "\n",
        "\n",
        "class Text_MLP(nn.Module):\n",
        "    def __init__(self, input_dim=4096, hidden_dim=2048, output_dim=768):\n",
        "        super(Text_MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
        "        weights_init_2(self.layer1)\n",
        "        weights_init_2(self.layer2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SV_GAT(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(SV_GAT, self).__init__()\n",
        "        self.args = args\n",
        "        self.length = list(np.load('/content/drive/MyDrive/USPM_edege_add/data/length.npy'))\n",
        "        pretrain_sv_path = args.pretrain_sv_path\n",
        "        pretrain_scn_path = args.pretrain_scn_path\n",
        "        self.sv_embedding = torch.load(pretrain_sv_path, map_location=torch.device(args.device))\n",
        "        self.scn_embedding = torch.load(pretrain_scn_path, map_location=torch.device(args.device))\n",
        "\n",
        "        self.text_mlp = Text_MLP(input_dim=4096, hidden_dim=2048, output_dim=768)\n",
        "\n",
        "        self.sv_agg = SVFeatureBlock(input_size=768, hidden_size=768, mode=args.mode)\n",
        "\n",
        "        self.attention_soft = Attention_Soft(in_size=768)\n",
        "\n",
        "        self.gat = GAT(input_dim=768, hidden_dim=64, output_dim=10, heads=8, args=args, drop=0.6)\n",
        "\n",
        "        self.gat_poi = GAT_P(input_dim=768, hidden_dim=64, output_dim=4, heads=8, args=args)\n",
        "\n",
        "    def forward(self, epoch=0, test_results=None):\n",
        "        sv_features = self.sv_embedding\n",
        "        street_list = list(torch.split(sv_features, self.length, dim=0))\n",
        "        sv_aggre = self.sv_agg(street_list)\n",
        "        sv_embedding = sv_aggre\n",
        "        scn_embedding = self.text_mlp(self.scn_embedding)  # Reduce text embedding to 768 dim\n",
        "        street_embedding = self.attention_soft(torch.stack([scn_embedding, sv_embedding], dim=1))\n",
        "\n",
        "        if self.args.downstream == 'poi':\n",
        "            gat_loss, infonce_loss, out = self.gat_poi(street_embedding, epoch, test_results)\n",
        "        else:\n",
        "            gat_loss, infonce_loss, s_emb1, out = self.gat(street_embedding, epoch, test_results)\n",
        "\n",
        "        return gat_loss, infonce_loss, out, street_embedding\n",
        "\n",
        "    def test(self, out):\n",
        "        if self.args.downstream == 'poi':\n",
        "            acc, f1_score_test, mrr_test, num, pred_out = self.gat_poi.test(out)\n",
        "            return acc, f1_score_test, mrr_test, 1, 1, 1, num, pred_out\n",
        "        else:\n",
        "            a1, a3, a5, a10, f1, mrr, num, pred_out = self.gat.test(out)\n",
        "            return a1, a3, a5, a10, f1, mrr, num, pred_out\n",
        "\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads, args, drop=0.6):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(0)\n",
        "        self.args = args\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, output_dim, concat=False, heads=10, dropout=0.6)\n",
        "\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop1 = nn.Dropout(p=drop)\n",
        "        self.drop2 = nn.Dropout(p=0.6)\n",
        "\n",
        "        # InfoNCE相关\n",
        "        self.infonce_criterion = InfoNCELoss(temperature=0.5)\n",
        "        self.negative_indices = None\n",
        "        self.positive_indices = None  # 新增正样本索引\n",
        "        self.infonce_triggered = False\n",
        "        self.similarity_computed = False\n",
        "        self.result_dir = 'infonce_data'\n",
        "\n",
        "        # 触发条件：num=10且f1>=0.44\n",
        "        self.trigger_num_threshold = 10\n",
        "        self.trigger_f1_threshold = 0.44\n",
        "\n",
        "        self.edge_index = torch.load('/content/drive/MyDrive/USPM_edege_add/data/edge_index.pt').t().contiguous().to(args.device)\n",
        "        self.y = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/function/label_all_function.npy', allow_pickle=True)).long().to(args.device)\n",
        "        self.train_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/function/label_mask.npy', allow_pickle=True)).to(args.device)\n",
        "        self.mask = torch.load('/content/drive/MyDrive/USPM_edege_add/data/function/test_mask.pt')\n",
        "        self.y_testlabel = np.load('/content/drive/MyDrive/USPM_edege_add/data/function/label_all_function.npy')[self.mask]\n",
        "\n",
        "    def forward(self, street_embedding, epoch=0, test_results=None):\n",
        "        street_embedding_0 = self.drop1(street_embedding)\n",
        "        street_embedding_1 = self.conv1(street_embedding_0, self.edge_index)\n",
        "        street_embedding_2 = self.elu(street_embedding_1)\n",
        "        street_embedding_2 = self.drop2(street_embedding_2)\n",
        "        street_embedding_2 = self.conv2(street_embedding_2, self.edge_index)\n",
        "\n",
        "        cross_criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss_su = cross_criterion(street_embedding_2[self.train_mask], self.y[self.train_mask])\n",
        "\n",
        "        # InfoNCE损失计算\n",
        "        infonce_loss = torch.tensor(0.0, device=street_embedding.device)\n",
        "\n",
        "        # 检查是否满足触发条件\n",
        "        if test_results and not self.similarity_computed:\n",
        "            num = test_results.get('num', 0)\n",
        "            f1 = test_results.get('f1', 0.0)\n",
        "\n",
        "            if num >= self.trigger_num_threshold and f1 >= self.trigger_f1_threshold:\n",
        "                # 满足条件，计算并保存正负样本索引\n",
        "                print(f\"Triggering InfoNCE for GAT at epoch {epoch}: num={num}, f1={f1:.4f}\")\n",
        "                print(\"Computing positive and negative samples...\")\n",
        "                similarity_matrix = compute_node_similarities(street_embedding, batch_size=500)\n",
        "\n",
        "                # 同时计算正负样本索引\n",
        "                self.negative_indices, self.positive_indices = find_positive_negative_samples(\n",
        "                    similarity_matrix,\n",
        "                    neg_min_sim=0.1, neg_max_sim=0.5, max_negatives=768,\n",
        "                    pos_min_sim=0.9, max_positives=50,\n",
        "                    random_seed=42 + epoch\n",
        "                )\n",
        "\n",
        "                self.similarity_computed = True\n",
        "                self.infonce_triggered = True\n",
        "\n",
        "        if self.infonce_triggered and self.negative_indices is not None and self.positive_indices is not None:\n",
        "            # 已经触发InfoNCE，计算损失\n",
        "            num_nodes = street_embedding_1.size(0)\n",
        "            batch_size = 256  # 分批处理\n",
        "            total_infonce_loss = 0.0\n",
        "            num_batches = 0\n",
        "\n",
        "            for i in range(0, num_nodes, batch_size):\n",
        "                end_idx = min(i + batch_size, num_nodes)\n",
        "                node_batch = list(range(i, end_idx))\n",
        "\n",
        "                try:\n",
        "                    batch_loss = compute_infonce_loss_batch(\n",
        "                        street_embedding_1, self.edge_index,\n",
        "                        self.negative_indices, self.positive_indices,\n",
        "                        node_batch, self.infonce_criterion,\n",
        "                        num_negatives=256, num_extra_positives=3, epoch=epoch\n",
        "                    )\n",
        "                    total_infonce_loss += batch_loss\n",
        "                    num_batches += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in InfoNCE computation for batch {i}-{end_idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if num_batches > 0:\n",
        "                infonce_loss = total_infonce_loss / num_batches\n",
        "\n",
        "        return loss_su, infonce_loss, street_embedding_1, street_embedding_2\n",
        "\n",
        "    def test(self, out):\n",
        "        pred = out.argmax(dim=1)\n",
        "        pred = pd.DataFrame({'Type': torch.Tensor.cpu(pred).numpy()})\n",
        "\n",
        "        predictions_test_dim = torch.Tensor.cpu(out[self.mask]).argmax(dim=1).detach().numpy()\n",
        "        predictions_test = torch.Tensor.cpu(out[self.mask]).detach().numpy()\n",
        "\n",
        "        A1 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=1, labels=range(10))\n",
        "        A3 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=3, labels=range(10))\n",
        "        A5 = top_k_accuracy_score(self.y_testlabel, predictions_test, k=5, labels=range(10))\n",
        "        print(f'A1={A1}\\t A3={A3}\\t A5={A5} ')\n",
        "\n",
        "        precision_score_test = precision_score(self.y_testlabel, predictions_test_dim, average=\"weighted\")\n",
        "        f1_score_test = f1_score(self.y_testlabel, predictions_test_dim, average=\"weighted\")\n",
        "        mrr_test = compute_mrr(self.y_testlabel, predictions_test)\n",
        "        result = Counter(pred['Type'].values.tolist())\n",
        "        num = len(result)\n",
        "        print(\n",
        "            f'precision={precision_score_test}, f1={f1_score_test}, mrr={mrr_test},num={num}')\n",
        "\n",
        "        print(result)\n",
        "        return A1, A3, A5, 1, f1_score_test, mrr_test, num, out\n",
        "\n",
        "\n",
        "class GAT_P(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads, args, drop=0.6):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=drop)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, output_dim, concat=False, heads=4, dropout=drop)\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop1 = nn.Dropout(p=drop)\n",
        "        self.drop2 = nn.Dropout(p=drop)\n",
        "\n",
        "        # InfoNCE相关\n",
        "        self.infonce_criterion = InfoNCELoss(temperature=0.5)\n",
        "        self.negative_indices = None\n",
        "        self.positive_indices = None  # 新增正样本索引\n",
        "        self.infonce_triggered = False\n",
        "        self.similarity_computed = False\n",
        "        self.result_dir = 'infonce_data'\n",
        "\n",
        "        # 触发条件：num=4且f1>=0.38\n",
        "        self.trigger_num_threshold = 4\n",
        "        self.trigger_f1_threshold = 0.38\n",
        "\n",
        "        self.edge_index = torch.load('/content/drive/MyDrive/USPM_edege_add/data/edge_index.pt').t().contiguous().to(args.device)\n",
        "\n",
        "        self.y = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/label_all_poi_level.npy', allow_pickle=True)).long().to(args.device)\n",
        "        self.train_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/label_mask_poi_level.npy', allow_pickle=True)).to(args.device)\n",
        "        self.test_mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/test_mask_poi_level.npy', allow_pickle=True)).to(args.device)\n",
        "\n",
        "        self.mask = torch.from_numpy(np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/test_mask_poi_level.npy', allow_pickle=True))\n",
        "\n",
        "        self.y_testlabel = np.load('/content/drive/MyDrive/USPM_edege_add/data/poi/label_all_poi_level.npy')[self.mask]\n",
        "\n",
        "    def forward(self, street_embedding, epoch=0, test_results=None):\n",
        "        street_embedding_0 = self.drop1(street_embedding)\n",
        "        street_embedding_1 = self.conv1(street_embedding_0, self.edge_index)\n",
        "        street_embedding_2 = self.elu(street_embedding_1)\n",
        "        street_embedding_2 = self.drop2(street_embedding_2)\n",
        "        street_embedding_2 = self.conv2(street_embedding_2, self.edge_index)\n",
        "\n",
        "        cross_criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss_su = cross_criterion(street_embedding_2[self.train_mask], self.y[self.train_mask])\n",
        "\n",
        "        # InfoNCE损失计算\n",
        "        infonce_loss = torch.tensor(0.0, device=street_embedding.device)\n",
        "\n",
        "        # 检查是否满足触发条件\n",
        "        if test_results and not self.similarity_computed:\n",
        "            num = test_results.get('num', 0)\n",
        "            f1 = test_results.get('f1', 0.0)\n",
        "\n",
        "            if num >= self.trigger_num_threshold and f1 >= self.trigger_f1_threshold:\n",
        "                # 满足条件，计算并保存正负样本索引\n",
        "                print(f\"Triggering InfoNCE for GAT_P at epoch {epoch}: num={num}, f1={f1:.4f}\")\n",
        "                print(\"Computing positive and negative samples...\")\n",
        "                similarity_matrix = compute_node_similarities(street_embedding, batch_size=500)\n",
        "\n",
        "                # 同时计算正负样本索引\n",
        "                self.negative_indices, self.positive_indices = find_positive_negative_samples(\n",
        "                    similarity_matrix,\n",
        "                    neg_min_sim=0.1, neg_max_sim=0.5, max_negatives=768,\n",
        "                    pos_min_sim=0.9, max_positives=50,\n",
        "                    random_seed=42 + epoch\n",
        "                )\n",
        "\n",
        "\n",
        "                self.similarity_computed = True\n",
        "                self.infonce_triggered = True\n",
        "\n",
        "        if self.infonce_triggered and self.negative_indices is not None and self.positive_indices is not None:\n",
        "            # 已经触发InfoNCE，计算损失\n",
        "            num_nodes = street_embedding_1.size(0)\n",
        "            batch_size = 256  # 分批处理\n",
        "            total_infonce_loss = 0.0\n",
        "            num_batches = 0\n",
        "\n",
        "            for i in range(0, num_nodes, batch_size):\n",
        "                end_idx = min(i + batch_size, num_nodes)\n",
        "                node_batch = list(range(i, end_idx))\n",
        "\n",
        "                try:\n",
        "                    batch_loss = compute_infonce_loss_batch(\n",
        "                        street_embedding_1, self.edge_index,\n",
        "                        self.negative_indices, self.positive_indices,\n",
        "                        node_batch, self.infonce_criterion,\n",
        "                        num_negatives=256, num_extra_positives=3, epoch=epoch\n",
        "                    )\n",
        "                    total_infonce_loss += batch_loss\n",
        "                    num_batches += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in InfoNCE computation for batch {i}-{end_idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if num_batches > 0:\n",
        "                infonce_loss = total_infonce_loss / num_batches\n",
        "\n",
        "        return loss_su, infonce_loss, street_embedding_2\n",
        "\n",
        "    def test(self, out):\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = pred[self.test_mask] == self.y[self.test_mask]\n",
        "        acc = int(correct.sum()) / int(self.test_mask.sum())\n",
        "\n",
        "        pred = pd.DataFrame({'Type': torch.Tensor.cpu(pred).numpy()})\n",
        "\n",
        "        predictions_test_dim = torch.Tensor.cpu(out[self.mask]).argmax(dim=1).detach().numpy()\n",
        "        predictions_test = torch.Tensor.cpu(out[self.mask]).detach().numpy()\n",
        "        f1_score_test = f1_score(self.y_testlabel, predictions_test_dim, average=\"macro\")\n",
        "        mrr_test = compute_mrr(self.y_testlabel, predictions_test)\n",
        "        result = Counter(pred['Type'].values.tolist())\n",
        "        num = len(result)\n",
        "        print(\n",
        "            f'acc={acc}, f1={f1_score_test}, mrr={mrr_test},num={num}')\n",
        "\n",
        "        print(result)\n",
        "        return acc, f1_score_test, mrr_test, num, out\n",
        "\n",
        "\n",
        "def compute_mrr(true_labels, machine_preds):\n",
        "    \"\"\"Compute the MRR \"\"\"\n",
        "    rr_total = 0.0\n",
        "    for i in range(len(true_labels)):\n",
        "        if true_labels[i] == 403:\n",
        "            continue\n",
        "        ranklist = list(np.argsort(machine_preds[i])[::-1])\n",
        "        rank = ranklist.index(true_labels[i]) + 1\n",
        "        rr_total = rr_total + 1.0 / rank\n",
        "    mrr = rr_total / len(true_labels)\n",
        "    return mrr"
      ],
      "metadata": {
        "id": "0Q5IPf5oLslZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "# from model import SV_GAT\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "parser = argparse.ArgumentParser()\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "\n",
        "parser.add_argument('--device', type=str, default='cuda:0', help='gpu device ids')\n",
        "parser.add_argument('--print_num', type=int, default=1, help='gap of print evaluations')\n",
        "parser.add_argument(\"--print_epoch\", type=int, default=0, help=\"Start print epoch\")\n",
        "parser.add_argument(\"--start_epoch\", type=int, default=0, help=\"Start epoch\")\n",
        "parser.add_argument(\"--current_epoch\", type=int, default=0, help=\"Current epoch\")\n",
        "parser.add_argument(\"--epochs\", type=int, default=200, help=\"Epochs\")\n",
        "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed.\")\n",
        "parser.add_argument(\"--rounds\", type=int, default=5, help=\"number of training rounds\")\n",
        "parser.add_argument(\"--mode\", type=str, default='lstm', help=\"aggression function.\")\n",
        "\n",
        "args = parser.parse_args([])\n",
        "\n",
        "def trainer(args, model, optimizer1, optimizer2, optimizer3, optimizer4, epoch, test_results=None):\n",
        "    loss_epoch = []\n",
        "    loss_su_epoch = []\n",
        "    infonce_loss_epoch = []\n",
        "    total_loss_epoch = []\n",
        "\n",
        "    model.train()\n",
        "    optimizer1.zero_grad() # attention\n",
        "    optimizer2.zero_grad() # sv_agg(lstm)\n",
        "    optimizer3.zero_grad() # gat\n",
        "    optimizer4.zero_grad() # text_mlp\n",
        "\n",
        "    # 传入epoch和test_results参数以便模型检查InfoNCE触发条件\n",
        "    gnn_loss, infonce_loss, pre_out, street_embedding = model(epoch, test_results)\n",
        "\n",
        "    # 记录各种损失\n",
        "    loss_su_epoch.append(gnn_loss.item())\n",
        "    infonce_loss_epoch.append(infonce_loss.item())\n",
        "\n",
        "    # 计算总损失\n",
        "    if args.downstream == 'poi':\n",
        "        infonce_triggered = model.gat_poi.infonce_triggered\n",
        "    else:\n",
        "        infonce_triggered = model.gat.infonce_triggered\n",
        "\n",
        "    if not infonce_triggered:\n",
        "        # InfoNCE未触发前，只使用原始损失\n",
        "        total_loss = gnn_loss\n",
        "    else:\n",
        "        # InfoNCE触发后，使用加权损失\n",
        "        total_loss = 0.99 * gnn_loss + 0.01 * infonce_loss\n",
        "\n",
        "    total_loss_epoch.append(total_loss.item())\n",
        "    loss_epoch.append(total_loss.item())  # 保持兼容性\n",
        "\n",
        "    total_loss.backward()\n",
        "\n",
        "    optimizer1.step()\n",
        "    optimizer2.step()\n",
        "    optimizer3.step()\n",
        "    optimizer4.step()\n",
        "\n",
        "    if epoch % args.print_num == 0:\n",
        "        if not infonce_triggered:\n",
        "            print(f\"TrainEpoch [{epoch + 1}/{args.epochs}]\\t loss_su:{np.mean(loss_su_epoch):.6f}\")\n",
        "        else:\n",
        "            print(f\"TrainEpoch [{epoch + 1}/{args.epochs}]\\t total_loss:{np.mean(total_loss_epoch):.6f}\\t \"\n",
        "                  f\"loss_su:{np.mean(loss_su_epoch):.6f}\\t infonce_loss:{np.mean(infonce_loss_epoch):.6f}\")\n",
        "\n",
        "    return np.mean(loss_epoch), pre_out, street_embedding\n",
        "\n",
        "def test(args, model, epoch, round_num, result_dir):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        _, _, out, _ = model(epoch)  # 测试时不传入test_results\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        os.makedirs(result_dir, exist_ok=True)\n",
        "        if args.downstream == 'poi':\n",
        "            acc, f1, mrr, _, _, _, num, pred_out = model.test(out)\n",
        "            result = {\n",
        "                'epoch': epoch + 1,\n",
        "                'acc': acc,\n",
        "                'f1': f1,\n",
        "                'mrr': mrr,\n",
        "                'num': num\n",
        "            }\n",
        "            return acc, f1, mrr, 1, 1, 1, num, pred_out, result\n",
        "        else:\n",
        "            a1, a3, a5, a10, f1, mrr, num, pred_out = model.test(out)\n",
        "            result = {\n",
        "                'epoch': epoch + 1,\n",
        "                'a1': a1,\n",
        "                'a3': a3,\n",
        "                'a5': a5,\n",
        "                'a10': a10,\n",
        "                'f1': f1,\n",
        "                'mrr': mrr,\n",
        "                'num': num\n",
        "            }\n",
        "            return a1, a3, a5, a10, f1, mrr, num, pred_out, result\n",
        "\n",
        "def calculate_best_results(result_dir, downstream):\n",
        "    # Collect round files\n",
        "    round_files = [f for f in os.listdir(result_dir) if f.startswith('round_') and f.endswith('.npy')]\n",
        "    if not round_files:\n",
        "        return None\n",
        "\n",
        "    # Load all results and group by epoch\n",
        "    epoch_results = {}\n",
        "    for round_file in round_files:\n",
        "        round_data = np.load(os.path.join(result_dir, round_file), allow_pickle=True).item()\n",
        "        for epoch_data in round_data['epochs']:\n",
        "            epoch = epoch_data['epoch']\n",
        "            if epoch not in epoch_results:\n",
        "                epoch_results[epoch] = []\n",
        "            epoch_results[epoch].append(epoch_data)\n",
        "\n",
        "    # Compute per-epoch averages across rounds\n",
        "    epoch_averages = {}\n",
        "    best_f1 = -1\n",
        "    best_epoch = None\n",
        "\n",
        "    if downstream == 'poi':\n",
        "        all_results = []\n",
        "        for epoch in epoch_results:\n",
        "            accs = [r['acc'] for r in epoch_results[epoch]]\n",
        "            f1s = [r['f1'] for r in epoch_results[epoch]]\n",
        "            mrrs = [r['mrr'] for r in epoch_results[epoch]]\n",
        "            epoch_averages[epoch] = {\n",
        "                'avg_acc': np.mean(accs),\n",
        "                'avg_f1': np.mean(f1s),\n",
        "                'avg_mrr': np.mean(mrrs)\n",
        "            }\n",
        "            all_results.extend(epoch_results[epoch])\n",
        "            if epoch_averages[epoch]['avg_f1'] > best_f1:\n",
        "                best_f1 = epoch_averages[epoch]['avg_f1']\n",
        "                best_epoch = epoch\n",
        "\n",
        "        # Store best epoch results and overall max metrics\n",
        "        best_results = {\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_epoch_avg_acc': epoch_averages[best_epoch]['avg_acc'],\n",
        "            'best_epoch_avg_f1': epoch_averages[best_epoch]['avg_f1'],\n",
        "            'best_epoch_avg_mrr': epoch_averages[best_epoch]['avg_mrr'],\n",
        "            'overall_best_acc': max([r['acc'] for r in all_results]),\n",
        "            'overall_best_f1': max([r['f1'] for r in all_results]),\n",
        "            'overall_best_mrr': max([r['mrr'] for r in all_results])\n",
        "        }\n",
        "    else:\n",
        "        all_results = []\n",
        "        for epoch in epoch_results:\n",
        "            a1s = [r['a1'] for r in epoch_results[epoch]]\n",
        "            a3s = [r['a3'] for r in epoch_results[epoch]]\n",
        "            a5s = [r['a5'] for r in epoch_results[epoch]]\n",
        "            a10s = [r['a10'] for r in epoch_results[epoch]]\n",
        "            f1s = [r['f1'] for r in epoch_results[epoch]]\n",
        "            mrrs = [r['mrr'] for r in epoch_results[epoch]]\n",
        "            epoch_averages[epoch] = {\n",
        "                'avg_a1': np.mean(a1s),\n",
        "                'avg_a3': np.mean(a3s),\n",
        "                'avg_a5': np.mean(a5s),\n",
        "                'avg_a10': np.mean(a10s),\n",
        "                'avg_f1': np.mean(f1s),\n",
        "                'avg_mrr': np.mean(mrrs)\n",
        "            }\n",
        "            all_results.extend(epoch_results[epoch])\n",
        "            if epoch_averages[epoch]['avg_f1'] > best_f1:\n",
        "                best_f1 = epoch_averages[epoch]['avg_f1']\n",
        "                best_epoch = epoch\n",
        "\n",
        "        # Store best epoch results and overall max metrics\n",
        "        best_results = {\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_epoch_avg_a1': epoch_averages[best_epoch]['avg_a1'],\n",
        "            'best_epoch_avg_a3': epoch_averages[best_epoch]['avg_a3'],\n",
        "            'best_epoch_avg_a5': epoch_averages[best_epoch]['avg_a5'],\n",
        "            'best_epoch_avg_a10': epoch_averages[best_epoch]['avg_a10'],\n",
        "            'best_epoch_avg_f1': epoch_averages[best_epoch]['avg_f1'],\n",
        "            'best_epoch_avg_mrr': epoch_averages[best_epoch]['avg_mrr'],\n",
        "            'overall_best_a1': max([r['a1'] for r in all_results]),\n",
        "            'overall_best_a3': max([r['a3'] for r in all_results]),\n",
        "            'overall_best_a5': max([r['a5'] for r in all_results]),\n",
        "            'overall_best_a10': max([r['a10'] for r in all_results]),\n",
        "            'overall_best_f1': max([r['f1'] for r in all_results]),\n",
        "            'overall_best_mrr': max([r['mrr'] for r in all_results])\n",
        "        }\n",
        "\n",
        "    # Save per-epoch averages and best results\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    np.save(f'{result_dir}/epoch_averages_{timestamp}.npy', epoch_averages)\n",
        "    np.save(f'{result_dir}/best_results_{timestamp}.npy', best_results)\n",
        "    return best_results\n",
        "\n",
        "def run_training(pretrain_sv_path, result_subdir):\n",
        "    result_dir = f'/content/drive/MyDrive/USPM_edege_add/result/{result_subdir}'\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for downstream in ['function', 'poi']:\n",
        "        print(f\"\\nStarting {downstream} downstream with {pretrain_sv_path}\")\n",
        "        args.downstream = downstream\n",
        "        args.pretrain_sv_path = pretrain_sv_path\n",
        "        # Set pretrain_scn_path based on downstream task\n",
        "        if downstream == 'function':\n",
        "            args.pretrain_scn_path = '/content/drive/MyDrive/USPM_edege_add/embeddings/qwen_text_embedding_function_72.pt'\n",
        "        else:  # downstream == 'poi'\n",
        "            args.pretrain_scn_path = '/content/drive/MyDrive/USPM_edege_add/embeddings/qwen_text_embedding_poi_72.pt'\n",
        "        args.current_epoch = 0\n",
        "\n",
        "        # 打印触发条件信息和正负样本配置\n",
        "        if downstream == 'poi':\n",
        "            print(f\"InfoNCE Configuration:\")\n",
        "            print(f\"  - Trigger: num >= 4 and f1 >= 0.38\")\n",
        "            print(f\"  - Negative samples: similarity ∈ [0.1, 0.5], max_negatives=768\")\n",
        "            print(f\"  - Positive samples: similarity > 0.9, max_positives=50\")\n",
        "            print(f\"  - Extra positives per node: 3 (excluding existing neighbors)\")\n",
        "        else:\n",
        "            print(f\"InfoNCE Configuration:\")\n",
        "            print(f\"  - Trigger: num >= 10 and f1 >= 0.44\")\n",
        "            print(f\"  - Negative samples: similarity ∈ [0.1, 0.5], max_negatives=768\")\n",
        "            print(f\"  - Positive samples: similarity > 0.9, max_positives=50\")\n",
        "            print(f\"  - Extra positives per node: 3 (excluding existing neighbors)\")\n",
        "\n",
        "        for round_num in range(args.rounds):\n",
        "        # for round_num in range(4, 5):\n",
        "            print(f\"\\nRound {round_num + 1}/{args.rounds}\")\n",
        "\n",
        "            # 设置随机种子，确保可复现性\n",
        "            base_seed = args.seed + round_num\n",
        "            np.random.seed(base_seed)\n",
        "            random.seed(base_seed + 1)\n",
        "            torch.manual_seed(base_seed + 2)\n",
        "            torch.cuda.manual_seed(base_seed + 3)\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            print(f\"Random seeds set: numpy={base_seed}, random={base_seed+1}, torch={base_seed+2}, cuda={base_seed+3}\")\n",
        "\n",
        "            model = SV_GAT(args)\n",
        "            model = model.to(args.device)\n",
        "\n",
        "            opt1 = torch.optim.Adam(\n",
        "                itertools.chain(model.attention_soft.parameters()),\n",
        "                lr=0.0005, weight_decay=1e-8)\n",
        "            opt4 = torch.optim.Adam(\n",
        "                model.text_mlp.parameters(),\n",
        "                lr=0.0005, weight_decay=1e-8)  # MLP和attention一样的设置\n",
        "            if args.downstream == 'poi':\n",
        "                opt3 = torch.optim.Adam(model.gat_poi.parameters(), lr=0.0005, weight_decay=5e-4)\n",
        "                args.epochs = 250\n",
        "            else:\n",
        "                opt3 = torch.optim.Adam(model.gat.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "                args.epochs = 250\n",
        "\n",
        "            if args.mode != 'mean':\n",
        "                opt2 = torch.optim.SGD(model.sv_agg.parameters(), lr=0.005, weight_decay=1e-4, momentum=0.9)\n",
        "                t = 10\n",
        "                T = 800\n",
        "                n_t = 0.5\n",
        "                lf = lambda epoch: (0.9 * epoch / t + 0.1) if epoch < t else 0.1 if n_t * (\n",
        "                        1 + math.cos(math.pi * (epoch - t) / (T - t))) < 0.1 else n_t * (\n",
        "                        1 + math.cos(math.pi * (epoch - t) / (T - t)))\n",
        "                scheduler = torch.optim.lr_scheduler.LambdaLR(opt2, lr_lambda=lf)\n",
        "            else:\n",
        "                opt2 = torch.optim.SGD(model.sv_agg.parameters(), lr=0.005, weight_decay=1e-4, momentum=0.9)\n",
        "\n",
        "            print(model)\n",
        "\n",
        "            # Collect results for this round\n",
        "            round_results = {'round': round_num, 'epochs': []}\n",
        "            last_test_result = None  # 保存上一次测试结果\n",
        "\n",
        "            for epoch in range(args.start_epoch, args.epochs):\n",
        "                # 在训练时传入上一次的测试结果，以便检查InfoNCE触发条件\n",
        "                loss_epoch, pred_, street_embedding = trainer(args, model, opt1, opt2, opt3, opt4, epoch, last_test_result)\n",
        "                if args.mode != 'mean':\n",
        "                    scheduler.step()\n",
        "                if epoch % args.print_num == 0:\n",
        "                    result_tuple = test(args, model, epoch, round_num, f'{result_dir}/{downstream}')\n",
        "                    # Append result to round_results\n",
        "                    round_results['epochs'].append(result_tuple[-1])  # Last element is the result dict\n",
        "                    last_test_result = result_tuple[-1]  # 保存当前测试结果\n",
        "\n",
        "            # Save all results for this round in a single file\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            np.save(f'{result_dir}/{downstream}/round_{round_num}_{timestamp}.npy', round_results)\n",
        "\n",
        "        # Calculate and save average and best results\n",
        "        best_results = calculate_best_results(f'{result_dir}/{downstream}', downstream)\n",
        "        print(f\"Best Results for {downstream}:\", best_results)\n",
        "\n",
        "# 运行训练\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Enhanced InfoNCE with Positive and Negative Sampling\")\n",
        "    print(\"=\"*50)\n",
        "    run_training('/content/drive/MyDrive/USPM_edege_add/embeddings/image_representation_117144_16.pt',\n",
        "                 'infonce_pos3_neg_256_0.01')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F87GVrDLxJq",
        "outputId": "f06066b6-b763-480f-e848-c01b4d916ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced InfoNCE with Positive and Negative Sampling\n",
            "==================================================\n",
            "\n",
            "Starting function downstream with /content/drive/MyDrive/USPM_edege_add/embeddings/image_representation_117144_16.pt\n",
            "InfoNCE Configuration:\n",
            "  - Trigger: num >= 10 and f1 >= 0.44\n",
            "  - Negative samples: similarity ∈ [0.1, 0.5], max_negatives=768\n",
            "  - Positive samples: similarity > 0.9, max_positives=50\n",
            "  - Extra positives per node: 3 (excluding existing neighbors)\n",
            "\n",
            "Round 1/5\n",
            "Random seeds set: numpy=42, random=43, torch=44, cuda=45\n",
            "SV_GAT(\n",
            "  (text_mlp): Text_MLP(\n",
            "    (layer1): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (layer2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "  )\n",
            "  (sv_agg): SVFeatureBlock(\n",
            "    (lstm): LSTM(768, 768, batch_first=True)\n",
            "  )\n",
            "  (attention_soft): Attention_Soft(\n",
            "    (l1): Linear(in_features=768, out_features=32, bias=True)\n",
            "    (ac): Sigmoid()\n",
            "    (l2): Linear(in_features=768, out_features=32, bias=False)\n",
            "    (l3): Linear(in_features=32, out_features=1, bias=False)\n",
            "  )\n",
            "  (gat): GAT(\n",
            "    (conv1): GATConv(768, 64, heads=8)\n",
            "    (conv2): GATConv(512, 10, heads=10)\n",
            "    (elu): ELU(alpha=1.0)\n",
            "    (drop1): Dropout(p=0.6, inplace=False)\n",
            "    (drop2): Dropout(p=0.6, inplace=False)\n",
            "    (infonce_criterion): InfoNCELoss()\n",
            "  )\n",
            "  (gat_poi): GAT_P(\n",
            "    (conv1): GATConv(768, 64, heads=8)\n",
            "    (conv2): GATConv(512, 4, heads=4)\n",
            "    (elu): ELU(alpha=1.0)\n",
            "    (drop1): Dropout(p=0.6, inplace=False)\n",
            "    (drop2): Dropout(p=0.6, inplace=False)\n",
            "    (infonce_criterion): InfoNCELoss()\n",
            "  )\n",
            ")\n",
            "TrainEpoch [1/250]\t loss_su:2.831347\n",
            "A1=0.46891342242882045\t A3=0.6649234940925818\t A5=0.7853960875460004 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6053183672590982,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [2/250]\t loss_su:6.461086\n",
            "A1=0.12085996513654852\t A3=0.26573697462715473\t A5=0.3424365678868875 \n",
            "precision=0.014607131172807724, f1=0.026064150076103774, mrr=0.27351276943083064,num=1\n",
            "Counter({6: 5458})\n",
            "TrainEpoch [3/250]\t loss_su:4.964508\n",
            "A1=0.07515010652721286\t A3=0.6132093743947318\t A5=0.7654464458648073 \n",
            "precision=0.005647538511051441, f1=0.010505581456515435, mrr=0.3595762276761652,num=1\n",
            "Counter({3: 5458})\n",
            "TrainEpoch [4/250]\t loss_su:3.490993\n",
            "A1=0.46891342242882045\t A3=0.6143714894441217\t A5=0.800116211504939 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6007206343057561,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [5/250]\t loss_su:3.449163\n",
            "A1=0.46891342242882045\t A3=0.6595002905287624\t A5=0.8762347472399767 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6200208135420193,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [6/250]\t loss_su:2.894248\n",
            "A1=0.03215184969978695\t A3=0.5696300600426109\t A5=0.788688746852605 \n",
            "precision=0.009240607300590422, f1=0.010423420567024784, mrr=0.3015767718411494,num=2\n",
            "Counter({8: 4985, 3: 473})\n",
            "TrainEpoch [7/250]\t loss_su:2.724637\n",
            "A1=0.07515010652721286\t A3=0.6149525469688166\t A5=0.694944799535154 \n",
            "precision=0.005647538511051441, f1=0.010505581456515435, mrr=0.3952128853349085,num=1\n",
            "Counter({3: 5458})\n",
            "TrainEpoch [8/250]\t loss_su:2.538157\n",
            "A1=0.46891342242882045\t A3=0.6137904319194267\t A5=0.7853960875460004 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6058331719284602,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [9/250]\t loss_su:2.301947\n",
            "A1=0.46891342242882045\t A3=0.6591129188456324\t A5=0.8514429595196591 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6077876311606665,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [10/250]\t loss_su:2.264872\n",
            "A1=0.46891342242882045\t A3=0.736974627154755\t A5=0.8518303312027891 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6260009407598073,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [11/250]\t loss_su:2.197070\n",
            "A1=0.46891342242882045\t A3=0.7303893085415456\t A5=0.8597714507069533 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6269317856912338,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [12/250]\t loss_su:2.168230\n",
            "A1=0.46891342242882045\t A3=0.6391632771644393\t A5=0.832268061204726 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.613033827385945,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [13/250]\t loss_su:2.075411\n",
            "A1=0.46891342242882045\t A3=0.5742785202401705\t A5=0.7648653883401123 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.597369023792611,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [14/250]\t loss_su:2.039740\n",
            "A1=0.46891342242882045\t A3=0.620375750532636\t A5=0.7604106139841178 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.604175928231706,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [15/250]\t loss_su:1.973554\n",
            "A1=0.46891342242882045\t A3=0.6711214410226612\t A5=0.7606042998256828 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6129950902176347,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [16/250]\t loss_su:1.924524\n",
            "A1=0.46891342242882045\t A3=0.684098392407515\t A5=0.7607979856672478 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.618208006296326,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [17/250]\t loss_su:1.917128\n",
            "A1=0.46891342242882045\t A3=0.6763509587449158\t A5=0.7625411582413325 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.613871288072334,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [18/250]\t loss_su:1.888515\n",
            "A1=0.46891342242882045\t A3=0.6693782684485764\t A5=0.7813286848731358 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6132616388281709,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [19/250]\t loss_su:1.932210\n",
            "A1=0.46891342242882045\t A3=0.6749951578539609\t A5=0.7873329459616502 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6134594750806287,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [20/250]\t loss_su:1.969259\n",
            "A1=0.46891342242882045\t A3=0.6779004454774356\t A5=0.78888243269417 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.613674835290182,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [21/250]\t loss_su:1.900812\n",
            "A1=0.46891342242882045\t A3=0.6835173348828201\t A5=0.78849506101104 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6166617476611745,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [22/250]\t loss_su:1.934856\n",
            "A1=0.46891342242882045\t A3=0.6988185163664536\t A5=0.7842339724966105 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6225570220340786,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [23/250]\t loss_su:1.883665\n",
            "A1=0.46891342242882045\t A3=0.704822777454968\t A5=0.7615727290335077 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6204067248954009,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [24/250]\t loss_su:1.908650\n",
            "A1=0.46891342242882045\t A3=0.7034669765640131\t A5=0.7611853573503777 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6222385932874019,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [25/250]\t loss_su:1.869880\n",
            "A1=0.46891342242882045\t A3=0.705016463296533\t A5=0.7724191361611467 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6257546061874941,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [26/250]\t loss_su:1.826929\n",
            "A1=0.46891342242882045\t A3=0.7005616889405385\t A5=0.7772612822002711 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6228965871324951,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [27/250]\t loss_su:1.824916\n",
            "A1=0.46891342242882045\t A3=0.6993995738911486\t A5=0.7747433662599263 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6189902818897584,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [28/250]\t loss_su:1.836774\n",
            "A1=0.46891342242882045\t A3=0.6982374588417587\t A5=0.7668022467557621 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6183879342943834,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [29/250]\t loss_su:1.847551\n",
            "A1=0.46891342242882045\t A3=0.6930079411195041\t A5=0.7637032732907224 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6187990555509434,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [30/250]\t loss_su:1.821363\n",
            "A1=0.46891342242882045\t A3=0.6893279101297695\t A5=0.7633159016075924 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6211695550452088,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [31/250]\t loss_su:1.795270\n",
            "A1=0.46891342242882045\t A3=0.6918458260701142\t A5=0.7695138485376719 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6231500696346723,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [32/250]\t loss_su:1.795778\n",
            "A1=0.46891342242882045\t A3=0.6961069145845439\t A5=0.8274259151656014 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6275171473457353,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [33/250]\t loss_su:1.799956\n",
            "A1=0.46891342242882045\t A3=0.7030796048808832\t A5=0.8742978888243269 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.630691366223035,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [34/250]\t loss_su:1.800606\n",
            "A1=0.46891342242882045\t A3=0.705016463296533\t A5=0.8785589773387565 \n",
            "precision=0.21987979773390942, f1=0.2993774777690333, mrr=0.6325849527621769,num=1\n",
            "Counter({0: 5458})\n",
            "TrainEpoch [35/250]\t loss_su:1.806135\n",
            "A1=0.4693007941119504\t A3=0.7061785783459229\t A5=0.8684873135773775 \n",
            "precision=0.2951151124757062, f1=0.3002272186747605, mrr=0.6314433591888582,num=2\n",
            "Counter({0: 5456, 3: 2})\n",
            "TrainEpoch [36/250]\t loss_su:1.778145\n",
            "A1=0.4693007941119504\t A3=0.704435405771838\t A5=0.8686809994189425 \n",
            "precision=0.2951151124757062, f1=0.3002272186747605, mrr=0.6297381551884759,num=2\n",
            "Counter({0: 5455, 3: 3})\n",
            "TrainEpoch [37/250]\t loss_su:1.751512\n",
            "A1=0.4693007941119504\t A3=0.7026922331977532\t A5=0.8679062560526826 \n",
            "precision=0.27010770584375704, f1=0.30026474831170924, mrr=0.6292997488232822,num=2\n",
            "Counter({0: 5454, 3: 4})\n",
            "TrainEpoch [38/250]\t loss_su:1.743107\n",
            "A1=0.46910710827038543\t A3=0.7011427464652334\t A5=0.8675188843695526 \n",
            "precision=0.24513183000952043, f1=0.30062133260602475, mrr=0.6286987078387435,num=2\n",
            "Counter({0: 5448, 3: 10})\n",
            "TrainEpoch [39/250]\t loss_su:1.716789\n",
            "A1=0.4693007941119504\t A3=0.7028859190393182\t A5=0.8657757117954678 \n",
            "precision=0.25018454656107275, f1=0.3010356589070017, mrr=0.6284839625048806,num=2\n",
            "Counter({0: 5446, 3: 12})\n",
            "TrainEpoch [40/250]\t loss_su:1.705182\n",
            "A1=0.4693007941119504\t A3=0.7001743172574085\t A5=0.8607398799147782 \n",
            "precision=0.23810631287918124, f1=0.3012866320529322, mrr=0.6296028056777614,num=2\n",
            "Counter({0: 5438, 3: 20})\n",
            "TrainEpoch [41/250]\t loss_su:1.619325\n",
            "A1=0.4693007941119504\t A3=0.6986248305248887\t A5=0.862289366647298 \n",
            "precision=0.23839709398700976, f1=0.30167415703227535, mrr=0.6302964623127313,num=2\n",
            "Counter({0: 5434, 3: 24})\n",
            "TrainEpoch [42/250]\t loss_su:1.658483\n",
            "A1=0.4694944799535154\t A3=0.6988185163664536\t A5=0.8698431144683324 \n",
            "precision=0.23768171995029672, f1=0.3039162246128588, mrr=0.6313943997122369,num=3\n",
            "Counter({0: 5402, 3: 50, 2: 6})\n",
            "TrainEpoch [43/250]\t loss_su:1.615737\n",
            "A1=0.4694944799535154\t A3=0.704435405771838\t A5=0.8781716056556266 \n",
            "precision=0.2674728862467001, f1=0.30722960741147176, mrr=0.6333361002739273,num=3\n",
            "Counter({0: 5359, 3: 85, 2: 14})\n",
            "TrainEpoch [44/250]\t loss_su:1.646360\n",
            "A1=0.46581444896378077\t A3=0.7278713926012008\t A5=0.8886306411001356 \n",
            "precision=0.4018508253400363, f1=0.3129142633680318, mrr=0.6364639728962812,num=4\n",
            "Counter({0: 5216, 3: 216, 2: 22, 6: 4})\n",
            "TrainEpoch [45/250]\t loss_su:1.634998\n",
            "A1=0.463296533023436\t A3=0.7385241138872748\t A5=0.89540964555491 \n",
            "precision=0.3253354021366303, f1=0.32674344946985695, mrr=0.6374500797801219,num=4\n",
            "Counter({0: 4963, 3: 411, 6: 73, 2: 11})\n",
            "TrainEpoch [46/250]\t loss_su:1.626169\n",
            "A1=0.4578733294596165\t A3=0.7553747821034282\t A5=0.9010265349602944 \n",
            "precision=0.2952438048371402, f1=0.34405888274465857, mrr=0.6365480571465474,num=4\n",
            "Counter({0: 4565, 3: 624, 6: 264, 2: 5})\n",
            "TrainEpoch [47/250]\t loss_su:1.569417\n",
            "A1=0.45729227193492156\t A3=0.7770675963587061\t A5=0.9023823358512493 \n",
            "precision=0.29465937942586684, f1=0.33969666913386193, mrr=0.6385366419794094,num=3\n",
            "Counter({0: 4624, 3: 627, 6: 207})\n",
            "TrainEpoch [48/250]\t loss_su:1.587702\n",
            "A1=0.46271547549874104\t A3=0.78888243269417\t A5=0.8969591322874297 \n",
            "precision=0.29981220440853573, f1=0.3288725055287352, mrr=0.6422707820296455,num=4\n",
            "Counter({0: 4903, 3: 460, 6: 89, 2: 6})\n",
            "TrainEpoch [49/250]\t loss_su:1.546741\n",
            "A1=0.462909161340306\t A3=0.779004454774356\t A5=0.8901801278326554 \n",
            "precision=0.29265371565333687, f1=0.3183355478114242, mrr=0.6415188659232839,num=4\n",
            "Counter({0: 5043, 3: 371, 6: 33, 2: 11})\n",
            "TrainEpoch [50/250]\t loss_su:1.519577\n",
            "A1=0.46387759054813094\t A3=0.7332945961650204\t A5=0.8853379817935308 \n",
            "precision=0.32880673841863606, f1=0.33526912411988447, mrr=0.6368014627892619,num=4\n",
            "Counter({0: 4859, 3: 449, 6: 104, 2: 46})\n",
            "TrainEpoch [51/250]\t loss_su:1.520148\n",
            "A1=0.46600813480534575\t A3=0.7121828394344374\t A5=0.8839821809025761 \n",
            "precision=0.47309000472055, f1=0.3676030141134905, mrr=0.6341528857653205,num=5\n",
            "Counter({0: 4340, 3: 619, 6: 384, 2: 114, 9: 1})\n",
            "TrainEpoch [52/250]\t loss_su:1.459014\n",
            "A1=0.462909161340306\t A3=0.7092775518109626\t A5=0.8830137516947512 \n",
            "precision=0.4784378853352511, f1=0.3792550403941568, mrr=0.6302403549062472,num=5\n",
            "Counter({0: 3939, 3: 734, 6: 654, 2: 130, 9: 1})\n",
            "TrainEpoch [53/250]\t loss_su:1.464910\n",
            "A1=0.46678287817160563\t A3=0.7183807863645167\t A5=0.8847569242688359 \n",
            "precision=0.4771559591445559, f1=0.3757474861716924, mrr=0.6342178320098137,num=5\n",
            "Counter({0: 4115, 3: 662, 6: 580, 2: 100, 9: 1})\n",
            "TrainEpoch [54/250]\t loss_su:1.415230\n",
            "A1=0.47104396668603526\t A3=0.7327135386403254\t A5=0.8899864419910904 \n",
            "precision=0.47858149083616747, f1=0.36788396930904377, mrr=0.6395330480310151,num=5\n",
            "Counter({0: 4405, 3: 567, 6: 422, 2: 63, 9: 1})\n",
            "TrainEpoch [55/250]\t loss_su:1.412556\n",
            "A1=0.4743366259926399\t A3=0.7546000387371683\t A5=0.89502227387178 \n",
            "precision=0.34254149289914604, f1=0.3589885206375387, mrr=0.6447523434449649,num=4\n",
            "Counter({0: 4661, 3: 459, 6: 299, 2: 39})\n",
            "TrainEpoch [56/250]\t loss_su:1.413514\n",
            "A1=0.47298082510168504\t A3=0.7677706759635871\t A5=0.89579701723804 \n",
            "precision=0.48702343884970545, f1=0.3691876767065027, mrr=0.6463505590757194,num=5\n",
            "Counter({0: 4408, 3: 608, 6: 390, 2: 51, 9: 1})\n",
            "TrainEpoch [57/250]\t loss_su:1.354869\n",
            "A1=0.4704629091613403\t A3=0.7741623087352315\t A5=0.895215959713345 \n",
            "precision=0.4190745769749826, f1=0.3803392107289715, mrr=0.6465352523603547,num=5\n",
            "Counter({0: 4077, 3: 794, 6: 502, 2: 80, 9: 5})\n",
            "TrainEpoch [58/250]\t loss_su:1.310174\n",
            "A1=0.46368390470656595\t A3=0.7710633352701918\t A5=0.894828588030215 \n",
            "precision=0.4018160292049189, f1=0.38138738538805733, mrr=0.6426178793552417,num=6\n",
            "Counter({0: 3898, 3: 862, 6: 583, 2: 105, 9: 8, 8: 2})\n",
            "TrainEpoch [59/250]\t loss_su:1.315111\n",
            "A1=0.46891342242882045\t A3=0.7617664148750727\t A5=0.8942475305055201 \n",
            "precision=0.38268542698795055, f1=0.3900223987277438, mrr=0.6446490443294625,num=6\n",
            "Counter({0: 3816, 3: 836, 6: 643, 2: 136, 9: 22, 8: 5})\n",
            "TrainEpoch [60/250]\t loss_su:1.287476\n",
            "A1=0.4716250242107302\t A3=0.7671896184388921\t A5=0.8938601588223901 \n",
            "precision=0.3749757846462877, f1=0.39055286604317513, mrr=0.6461441914230993,num=6\n",
            "Counter({0: 3884, 3: 740, 6: 650, 2: 135, 9: 38, 8: 11})\n",
            "TrainEpoch [61/250]\t loss_su:1.272020\n",
            "A1=0.4768545419329847\t A3=0.778810768932791\t A5=0.8921169862483053 \n",
            "precision=0.39768041405787646, f1=0.3927875007777545, mrr=0.6500414272494466,num=6\n",
            "Counter({0: 4017, 3: 650, 6: 601, 2: 113, 9: 65, 8: 12})\n",
            "TrainEpoch [62/250]\t loss_su:1.255347\n",
            "A1=0.47743559945767966\t A3=0.7774549680418361\t A5=0.8897927561495255 \n",
            "precision=0.39252610017005407, f1=0.3889428050465228, mrr=0.6498586554513346,num=6\n",
            "Counter({0: 4127, 6: 577, 3: 576, 2: 102, 9: 64, 8: 12})\n",
            "TrainEpoch [63/250]\t loss_su:1.226622\n",
            "A1=0.47937245787332944\t A3=0.7722254503195817\t A5=0.8917296145651753 \n",
            "precision=0.39587821246891114, f1=0.3871785439208255, mrr=0.6508620557138866,num=6\n",
            "Counter({0: 4238, 6: 552, 3: 492, 2: 105, 9: 59, 8: 12})\n",
            "TrainEpoch [64/250]\t loss_su:1.185840\n",
            "A1=0.48130931628897927\t A3=0.7640906449738524\t A5=0.8911485570404803 \n",
            "precision=0.38823793266545775, f1=0.39247869686938147, mrr=0.6503962873805991,num=6\n",
            "Counter({0: 4127, 6: 641, 3: 493, 2: 123, 9: 56, 8: 18})\n",
            "TrainEpoch [65/250]\t loss_su:1.199972\n",
            "A1=0.4818903738136742\t A3=0.7571179546775131\t A5=0.8894053844663955 \n",
            "precision=0.3921053262050459, f1=0.39512806620232654, mrr=0.6490328005435508,num=6\n",
            "Counter({0: 4043, 6: 724, 3: 482, 2: 134, 9: 51, 8: 24})\n",
            "TrainEpoch [66/250]\t loss_su:1.165409\n",
            "A1=0.48266511717993416\t A3=0.7553747821034282\t A5=0.8882432694170056 \n",
            "precision=0.4007075285106781, f1=0.39833887911012883, mrr=0.6489145138331656,num=7\n",
            "Counter({0: 3947, 6: 819, 3: 480, 2: 136, 9: 50, 8: 25, 4: 1})\n",
            "TrainEpoch [67/250]\t loss_su:1.181334\n",
            "A1=0.4822777454968042\t A3=0.7640906449738524\t A5=0.8868874685260507 \n",
            "precision=0.39287733786575724, f1=0.399426424149342, mrr=0.6499797859617736,num=7\n",
            "Counter({0: 3916, 6: 836, 3: 472, 2: 140, 9: 65, 8: 27, 4: 2})\n",
            "TrainEpoch [68/250]\t loss_su:1.061437\n",
            "A1=0.4873135773774937\t A3=0.7737749370521015\t A5=0.8890180127832655 \n",
            "precision=0.3947229973595215, f1=0.39779181737923713, mrr=0.6540854646461867,num=7\n",
            "Counter({0: 4105, 6: 724, 3: 417, 2: 130, 9: 58, 8: 22, 4: 2})\n",
            "TrainEpoch [69/250]\t loss_su:1.100230\n",
            "A1=0.48789463490218865\t A3=0.7766802246755762\t A5=0.8899864419910904 \n",
            "precision=0.3925477984603387, f1=0.39484445156143555, mrr=0.6559232512166867,num=8\n",
            "Counter({0: 4253, 6: 605, 3: 384, 2: 133, 9: 60, 8: 20, 4: 2, 5: 1})\n",
            "TrainEpoch [70/250]\t loss_su:1.024196\n",
            "A1=0.4894441216347085\t A3=0.778229711408096\t A5=0.8919233004067403 \n",
            "precision=0.3965643787214785, f1=0.4004406865123861, mrr=0.6571706034082573,num=8\n",
            "Counter({0: 4215, 6: 557, 3: 422, 2: 145, 9: 92, 8: 23, 4: 3, 5: 1})\n",
            "TrainEpoch [71/250]\t loss_su:1.015175\n",
            "A1=0.4871198915359287\t A3=0.7716443927948867\t A5=0.8892116986248305 \n",
            "precision=0.4020187802882375, f1=0.4118976410064959, mrr=0.6555381084579228,num=9\n",
            "Counter({0: 3964, 6: 628, 3: 469, 2: 166, 9: 158, 8: 63, 4: 6, 1: 3, 5: 1})\n",
            "TrainEpoch [72/250]\t loss_su:0.982492\n",
            "A1=0.4818903738136742\t A3=0.7669959325973271\t A5=0.8886306411001356 \n",
            "precision=0.4161702828723803, f1=0.41790587557372066, mrr=0.6521700500201376,num=9\n",
            "Counter({0: 3762, 6: 678, 3: 516, 2: 197, 9: 196, 8: 93, 1: 10, 4: 5, 5: 1})\n",
            "TrainEpoch [73/250]\t loss_su:0.992694\n",
            "A1=0.49215572341661823\t A3=0.7726128220027116\t A5=0.8868874685260507 \n",
            "precision=0.4208821525953252, f1=0.42108805580537545, mrr=0.6585750563379842,num=9\n",
            "Counter({0: 3963, 6: 590, 3: 414, 9: 234, 2: 158, 8: 84, 1: 9, 4: 5, 5: 1})\n",
            "TrainEpoch [74/250]\t loss_su:0.948908\n",
            "A1=0.5049389889599071\t A3=0.7832655432887856\t A5=0.8859190393182258 \n",
            "precision=0.4552760064411455, f1=0.4270245795168949, mrr=0.6671641779573212,num=9\n",
            "Counter({0: 4188, 6: 513, 3: 290, 9: 254, 2: 139, 8: 60, 4: 7, 1: 6, 5: 1})\n",
            "TrainEpoch [75/250]\t loss_su:0.914857\n",
            "A1=0.5033895022273872\t A3=0.7830718574472206\t A5=0.8876622118923106 \n",
            "precision=0.4675653207513505, f1=0.42839177129344885, mrr=0.6665434609507822,num=9\n",
            "Counter({0: 4120, 6: 570, 3: 296, 9: 248, 2: 144, 8: 58, 1: 13, 4: 7, 5: 2})\n",
            "TrainEpoch [76/250]\t loss_su:0.919998\n",
            "A1=0.49951578539608754\t A3=0.7712570211117568\t A5=0.8835948092194461 \n",
            "precision=0.4633050231536088, f1=0.4367902971031121, mrr=0.6619062222345198,num=9\n",
            "Counter({0: 3756, 6: 791, 3: 402, 9: 224, 2: 168, 8: 78, 1: 25, 4: 10, 5: 4})\n",
            "TrainEpoch [77/250]\t loss_su:0.897355\n",
            "A1=0.4958357544063529\t A3=0.7714507069533217\t A5=0.8851442959519659 \n",
            "precision=0.44890217187571485, f1=0.4304296472800479, mrr=0.6598609919789473,num=9\n",
            "Counter({0: 3771, 6: 790, 3: 440, 9: 198, 2: 152, 8: 64, 1: 22, 4: 15, 5: 6})\n",
            "TrainEpoch [78/250]\t loss_su:0.835559\n",
            "A1=0.49312415262444315\t A3=0.7714507069533217\t A5=0.8832074375363161 \n",
            "precision=0.4451193801828591, f1=0.4260596109291471, mrr=0.6586719761182295,num=9\n",
            "Counter({0: 3838, 6: 700, 3: 476, 9: 177, 2: 157, 8: 61, 1: 23, 4: 20, 5: 6})\n",
            "TrainEpoch [79/250]\t loss_su:0.845825\n",
            "A1=0.5049389889599071\t A3=0.7718380786364517\t A5=0.8816579508037963 \n",
            "precision=0.4501082152097123, f1=0.4329976120576059, mrr=0.6644429687427957,num=9\n",
            "Counter({0: 4053, 6: 562, 3: 334, 9: 211, 2: 166, 8: 84, 4: 25, 1: 17, 5: 6})\n",
            "TrainEpoch [80/250]\t loss_su:0.827620\n",
            "A1=0.5101685066821615\t A3=0.7726128220027116\t A5=0.8783652914971916 \n",
            "precision=0.4579052155102642, f1=0.4393201012066673, mrr=0.6662213429499914,num=9\n",
            "Counter({0: 4108, 6: 521, 9: 247, 3: 213, 2: 199, 8: 115, 4: 28, 1: 21, 5: 6})\n",
            "TrainEpoch [81/250]\t loss_su:0.836394\n",
            "A1=0.5010652721286074\t A3=0.7629285299244625\t A5=0.8777842339724966 \n",
            "precision=0.45575327583937314, f1=0.4424866361923041, mrr=0.6589162354850943,num=10\n",
            "Counter({0: 3875, 6: 578, 9: 281, 2: 277, 8: 189, 3: 178, 1: 40, 4: 30, 5: 9, 7: 1})\n",
            "Triggering InfoNCE for GAT at epoch 81: num=10, f1=0.4425\n",
            "Computing positive and negative samples...\n",
            "TrainEpoch [82/250]\t total_loss:0.863501\t loss_su:0.822188\t infonce_loss:4.953504\n",
            "A1=0.4958357544063529\t A3=0.757699012202208\t A5=0.8741042029827619 \n",
            "precision=0.4568679678137685, f1=0.44774253659303326, mrr=0.6554092920013931,num=10\n",
            "Counter({0: 3626, 6: 672, 2: 340, 9: 305, 8: 245, 3: 177, 1: 50, 4: 31, 5: 11, 7: 1})\n",
            "TrainEpoch [83/250]\t total_loss:0.875856\t loss_su:0.834797\t infonce_loss:4.940756\n",
            "A1=0.49815998450513266\t A3=0.7617664148750727\t A5=0.8754600038737168 \n",
            "precision=0.4523364234753559, f1=0.4505732114560729, mrr=0.6575504428642167,num=9\n",
            "Counter({0: 3577, 6: 720, 9: 314, 2: 313, 3: 235, 8: 203, 1: 52, 4: 31, 5: 13})\n",
            "TrainEpoch [84/250]\t total_loss:0.810240\t loss_su:0.768578\t infonce_loss:4.934811\n",
            "A1=0.5049389889599071\t A3=0.7741623087352315\t A5=0.8849506101104009 \n",
            "precision=0.45822341233215486, f1=0.4467279233968979, mrr=0.6647793826033248,num=9\n",
            "Counter({0: 3861, 6: 643, 9: 302, 3: 262, 2: 195, 8: 116, 1: 44, 4: 26, 5: 9})\n",
            "TrainEpoch [85/250]\t total_loss:0.791682\t loss_su:0.749774\t infonce_loss:4.940510\n",
            "A1=0.5126864226225063\t A3=0.7902382335851249\t A5=0.8892116986248305 \n",
            "precision=0.46348261282501263, f1=0.44641104797162007, mrr=0.6721954751298191,num=9\n",
            "Counter({0: 4066, 6: 521, 9: 335, 3: 255, 2: 138, 8: 70, 1: 41, 4: 23, 5: 9})\n",
            "TrainEpoch [86/250]\t total_loss:0.839045\t loss_su:0.797508\t infonce_loss:4.951226\n",
            "A1=0.5014526438117374\t A3=0.7799728839821809\t A5=0.8837884950610111 \n",
            "precision=0.4597826193885896, f1=0.4517063582435688, mrr=0.6638479227962116,num=9\n",
            "Counter({0: 3641, 6: 669, 3: 453, 9: 338, 2: 159, 8: 93, 1: 69, 4: 25, 5: 11})\n",
            "TrainEpoch [87/250]\t total_loss:0.671066\t loss_su:0.628044\t infonce_loss:4.930280\n",
            "A1=0.48053457292271934\t A3=0.7592484989347279\t A5=0.8723610304086771 \n",
            "precision=0.45436440421041796, f1=0.4496093183294855, mrr=0.6459153808078875,num=10\n",
            "Counter({0: 3111, 6: 848, 3: 635, 9: 306, 2: 237, 8: 148, 1: 120, 4: 28, 5: 20, 7: 5})\n",
            "TrainEpoch [88/250]\t total_loss:0.744605\t loss_su:0.702715\t infonce_loss:4.891683\n",
            "A1=0.4787914003486345\t A3=0.7613790431919427\t A5=0.873329459616502 \n",
            "precision=0.4498915024289333, f1=0.4491630909463385, mrr=0.6463006772855723,num=10\n",
            "Counter({0: 3077, 6: 825, 3: 641, 9: 312, 2: 297, 8: 129, 1: 120, 4: 30, 5: 22, 7: 5})\n",
            "TrainEpoch [89/250]\t total_loss:0.737252\t loss_su:0.695361\t infonce_loss:4.884403\n",
            "A1=0.4985473561882626\t A3=0.7811349990315708\t A5=0.8851442959519659 \n",
            "precision=0.4537147116315924, f1=0.45445513873225585, mrr=0.6623504699187471,num=10\n",
            "Counter({0: 3530, 6: 637, 3: 480, 9: 330, 2: 263, 1: 86, 8: 83, 4: 28, 5: 18, 7: 3})\n",
            "TrainEpoch [90/250]\t total_loss:0.633871\t loss_su:0.590878\t infonce_loss:4.890195\n",
            "A1=0.5068758473755568\t A3=0.7952740654658145\t A5=0.8890180127832655 \n",
            "precision=0.4566891232089668, f1=0.44059350700233474, mrr=0.6702111944267696,num=9\n",
            "Counter({0: 4076, 6: 448, 3: 294, 9: 292, 2: 202, 1: 56, 8: 51, 4: 27, 5: 12})\n",
            "TrainEpoch [91/250]\t total_loss:0.694532\t loss_su:0.652018\t infonce_loss:4.903423\n",
            "A1=0.5039705597520822\t A3=0.7915940344760798\t A5=0.8890180127832655 \n",
            "precision=0.4524700163676055, f1=0.4333861430713842, mrr=0.6682148467883531,num=9\n",
            "Counter({0: 4158, 6: 455, 9: 270, 3: 235, 2: 197, 8: 53, 1: 51, 4: 27, 5: 12})\n",
            "TrainEpoch [92/250]\t total_loss:0.712888\t loss_su:0.670547\t infonce_loss:4.904648\n",
            "A1=0.5008715862870424\t A3=0.7702885919039318\t A5=0.8789463490218865 \n",
            "precision=0.4519552033315618, f1=0.4498523492776743, mrr=0.6617866289133016,num=10\n",
            "Counter({0: 3629, 6: 734, 3: 323, 9: 289, 2: 262, 8: 99, 1: 68, 4: 32, 5: 19, 7: 3})\n",
            "TrainEpoch [93/250]\t total_loss:0.591853\t loss_su:0.548477\t infonce_loss:4.886042\n",
            "A1=0.47646717024985474\t A3=0.7509200077474336\t A5=0.8704241719930274 \n",
            "precision=0.4519051469447463, f1=0.44647116063802755, mrr=0.6432535070972046,num=10\n",
            "Counter({0: 3052, 6: 996, 3: 473, 9: 311, 2: 293, 8: 172, 1: 91, 4: 33, 5: 31, 7: 6})\n",
            "TrainEpoch [94/250]\t total_loss:0.618301\t loss_su:0.575349\t infonce_loss:4.870539\n",
            "A1=0.47278713926012006\t A3=0.7453031183420492\t A5=0.8659693976370327 \n",
            "precision=0.4584513415463466, f1=0.4483633519414899, mrr=0.6392302217549191,num=10\n",
            "Counter({0: 2926, 6: 1004, 3: 580, 9: 315, 2: 248, 8: 206, 1: 99, 5: 38, 4: 36, 7: 6})\n",
            "TrainEpoch [95/250]\t total_loss:0.574288\t loss_su:0.530983\t infonce_loss:4.861503\n",
            "A1=0.4925430950997482\t A3=0.7611853573503777\t A5=0.8762347472399767 \n",
            "precision=0.46282476468312117, f1=0.4560947477553419, mrr=0.6555138977277283,num=10\n",
            "Counter({0: 3344, 6: 721, 3: 536, 9: 364, 2: 167, 8: 163, 1: 98, 4: 36, 5: 23, 7: 6})\n",
            "TrainEpoch [96/250]\t total_loss:0.586170\t loss_su:0.542904\t infonce_loss:4.869434\n",
            "A1=0.49641681193104786\t A3=0.778229711408096\t A5=0.8872748402091807 \n",
            "precision=0.44958900107520705, f1=0.43962766935643854, mrr=0.6615009422969929,num=10\n",
            "Counter({0: 3831, 6: 512, 9: 392, 3: 384, 2: 113, 8: 109, 1: 66, 4: 36, 5: 14, 7: 1})\n",
            "TrainEpoch [97/250]\t total_loss:0.617893\t loss_su:0.574859\t infonce_loss:4.878268\n",
            "A1=0.5068758473755568\t A3=0.7828781716056556\t A5=0.8890180127832655 \n",
            "precision=0.45802412739753273, f1=0.44403080444289794, mrr=0.6673236613387704,num=10\n",
            "Counter({0: 3992, 6: 470, 9: 386, 3: 260, 2: 137, 8: 106, 1: 62, 4: 35, 5: 9, 7: 1})\n",
            "TrainEpoch [98/250]\t total_loss:0.577918\t loss_su:0.534467\t infonce_loss:4.879631\n",
            "A1=0.5099748208405965\t A3=0.768158047646717\t A5=0.8845632384272709 \n",
            "precision=0.45909470334274016, f1=0.45935992689473903, mrr=0.6671038432804853,num=10\n",
            "Counter({0: 3713, 6: 617, 9: 387, 3: 248, 2: 245, 8: 120, 1: 71, 4: 36, 5: 15, 7: 6})\n",
            "TrainEpoch [99/250]\t total_loss:0.599134\t loss_su:0.556061\t infonce_loss:4.863348\n",
            "A1=0.5031958163858222\t A3=0.7629285299244625\t A5=0.8777842339724966 \n",
            "precision=0.4584414621267127, f1=0.4608682064270869, mrr=0.6614413762147643,num=10\n",
            "Counter({0: 3392, 6: 825, 9: 383, 2: 361, 3: 206, 8: 144, 1: 83, 4: 38, 5: 23, 7: 3})\n",
            "TrainEpoch [100/250]\t total_loss:0.508185\t loss_su:0.464287\t infonce_loss:4.854099\n",
            "A1=0.4973852411388727\t A3=0.7631222157660275\t A5=0.8775905481309316 \n",
            "precision=0.45812112798406235, f1=0.45701626088772107, mrr=0.6587766587040284,num=9\n",
            "Counter({0: 3282, 6: 947, 2: 391, 9: 374, 3: 182, 8: 132, 1: 86, 4: 38, 5: 26})\n",
            "TrainEpoch [101/250]\t total_loss:0.569193\t loss_su:0.525940\t infonce_loss:4.851216\n",
            "A1=0.5101685066821615\t A3=0.7768739105171412\t A5=0.8868874685260507 \n",
            "precision=0.46232661054376667, f1=0.45891019323220794, mrr=0.6692642858680065,num=9\n",
            "Counter({0: 3646, 6: 784, 9: 351, 2: 290, 3: 162, 8: 90, 1: 80, 4: 38, 5: 17})\n",
            "TrainEpoch [102/250]\t total_loss:0.499445\t loss_su:0.455338\t infonce_loss:4.866042\n",
            "A1=0.5192717412357156\t A3=0.7898508619019949\t A5=0.8940538446639551 \n",
            "precision=0.47046616631752786, f1=0.4594390932922182, mrr=0.6772305384158976,num=9\n",
            "Counter({0: 3916, 6: 623, 9: 352, 2: 228, 3: 155, 1: 67, 8: 66, 4: 36, 5: 15})\n",
            "TrainEpoch [103/250]\t total_loss:0.490857\t loss_su:0.446516\t infonce_loss:4.880596\n",
            "A1=0.5202401704435405\t A3=0.7943056362579896\t A5=0.8965717606042998 \n",
            "precision=0.47232210451966183, f1=0.46046210809442256, mrr=0.6779739231220954,num=9\n",
            "Counter({0: 3952, 6: 563, 9: 352, 2: 215, 3: 193, 1: 72, 8: 56, 4: 37, 5: 18})\n",
            "TrainEpoch [104/250]\t total_loss:0.512517\t loss_su:0.468473\t infonce_loss:4.872859\n",
            "A1=0.5128801084640713\t A3=0.7879140034863451\t A5=0.8926980437730002 \n",
            "precision=0.46613410394525095, f1=0.462575251887434, mrr=0.6723614147059844,num=10\n",
            "Counter({0: 3732, 6: 591, 9: 354, 2: 287, 3: 272, 1: 81, 8: 77, 4: 38, 5: 25, 7: 1})\n",
            "TrainEpoch [105/250]\t total_loss:0.454687\t loss_su:0.410199\t infonce_loss:4.858916\n",
            "A1=0.49951578539608754\t A3=0.778423397249661\t A5=0.8863064110013558 \n",
            "precision=0.46528523338933314, f1=0.46413591703995344, mrr=0.662773350672829,num=10\n",
            "Counter({0: 3358, 6: 683, 3: 415, 2: 354, 9: 345, 1: 104, 8: 103, 5: 45, 4: 39, 7: 12})\n",
            "TrainEpoch [106/250]\t total_loss:0.504367\t loss_su:0.460578\t infonce_loss:4.839505\n",
            "A1=0.49544838272322295\t A3=0.7733875653689716\t A5=0.8837884950610111 \n",
            "precision=0.46751227376362714, f1=0.46220434313628644, mrr=0.6590383651685235,num=10\n",
            "Counter({0: 3301, 6: 708, 3: 464, 2: 358, 9: 311, 8: 114, 1: 106, 5: 46, 4: 39, 7: 11})\n",
            "TrainEpoch [107/250]\t total_loss:0.563486\t loss_su:0.520434\t infonce_loss:4.825637\n",
            "A1=0.5074569049002517\t A3=0.7842339724966105\t A5=0.8903738136742204 \n",
            "precision=0.46971943316999043, f1=0.45462965312590875, mrr=0.6676316371987506,num=10\n",
            "Counter({0: 3803, 6: 548, 3: 338, 9: 275, 2: 255, 8: 91, 1: 78, 4: 37, 5: 30, 7: 3})\n",
            "TrainEpoch [108/250]\t total_loss:0.533334\t loss_su:0.489747\t infonce_loss:4.848395\n",
            "A1=0.5122990509393763\t A3=0.7892698043773\t A5=0.8973465039705597 \n",
            "precision=0.47323807005020435, f1=0.4534302206503182, mrr=0.6722539651795918,num=10\n",
            "Counter({0: 3949, 6: 516, 3: 292, 9: 280, 2: 210, 8: 77, 1: 76, 4: 37, 5: 17, 7: 4})\n",
            "TrainEpoch [109/250]\t total_loss:0.527090\t loss_su:0.483364\t infonce_loss:4.855968\n",
            "A1=0.5153980244044161\t A3=0.778229711408096\t A5=0.8961843889211699 \n",
            "precision=0.4767275253765845, f1=0.4632097129281918, mrr=0.6723696386683036,num=10\n",
            "Counter({0: 3781, 6: 598, 9: 307, 3: 304, 2: 210, 8: 117, 1: 80, 4: 38, 5: 18, 7: 5})\n",
            "TrainEpoch [110/250]\t total_loss:0.453914\t loss_su:0.409572\t infonce_loss:4.843851\n",
            "A1=0.5173348828200659\t A3=0.7656401317063722\t A5=0.8907611853573504 \n",
            "precision=0.482068397076093, f1=0.4711384684368904, mrr=0.670803012275993,num=10\n",
            "Counter({0: 3641, 6: 672, 9: 336, 3: 280, 2: 224, 8: 156, 1: 84, 4: 38, 5: 20, 7: 7})\n",
            "TrainEpoch [111/250]\t total_loss:0.533620\t loss_su:0.490192\t infonce_loss:4.832950\n",
            "A1=0.5221770288591904\t A3=0.7693201626961069\t A5=0.8913422428820453 \n",
            "precision=0.48214615237567343, f1=0.47488911675276746, mrr=0.6741499343620208,num=10\n",
            "Counter({0: 3672, 6: 652, 9: 374, 2: 234, 3: 218, 8: 167, 1: 83, 4: 38, 5: 16, 7: 4})\n",
            "TrainEpoch [112/250]\t total_loss:0.432820\t loss_su:0.388262\t infonce_loss:4.843990\n",
            "A1=0.5138485376718962\t A3=0.7660275033895022\t A5=0.8880495835754406 \n",
            "precision=0.4739157472065117, f1=0.47053926697603277, mrr=0.6686028333471684,num=10\n",
            "Counter({0: 3584, 6: 664, 9: 396, 2: 252, 3: 229, 8: 184, 1: 87, 4: 39, 5: 17, 7: 6})\n",
            "TrainEpoch [113/250]\t total_loss:0.450538\t loss_su:0.406182\t infonce_loss:4.841704\n",
            "A1=0.5072632190586868\t A3=0.7629285299244625\t A5=0.884175866744141 \n",
            "precision=0.4751968420786236, f1=0.4727563983837313, mrr=0.6640230855076878,num=10\n",
            "Counter({0: 3359, 6: 735, 9: 414, 2: 296, 3: 260, 8: 224, 1: 101, 4: 39, 5: 24, 7: 6})\n",
            "TrainEpoch [114/250]\t total_loss:0.439046\t loss_su:0.394773\t infonce_loss:4.822136\n",
            "A1=0.5018400154948673\t A3=0.7633159016075924\t A5=0.8804958357544064 \n",
            "precision=0.4711374795527905, f1=0.47159227891936234, mrr=0.6607165914981152,num=10\n",
            "Counter({0: 3221, 6: 775, 9: 413, 2: 335, 3: 301, 8: 226, 1: 113, 4: 40, 5: 27, 7: 7})\n",
            "TrainEpoch [115/250]\t total_loss:0.408587\t loss_su:0.364086\t infonce_loss:4.814179\n",
            "A1=0.5066821615339918\t A3=0.7722254503195817\t A5=0.8851442959519659 \n",
            "precision=0.4694671561748688, f1=0.4707239462953487, mrr=0.664999661818373,num=10\n",
            "Counter({0: 3366, 6: 744, 9: 390, 2: 311, 3: 306, 8: 157, 1: 108, 4: 41, 5: 28, 7: 7})\n",
            "TrainEpoch [116/250]\t total_loss:0.416537\t loss_su:0.372084\t infonce_loss:4.817378\n",
            "A1=0.5099748208405965\t A3=0.7778423397249661\t A5=0.8859190393182258 \n",
            "precision=0.47425878261854726, f1=0.46941197099205906, mrr=0.6685089879453642,num=10\n",
            "Counter({0: 3513, 6: 697, 9: 366, 3: 309, 2: 283, 1: 103, 8: 103, 4: 42, 5: 33, 7: 9})\n",
            "TrainEpoch [117/250]\t total_loss:0.420144\t loss_su:0.375813\t infonce_loss:4.808910\n",
            "A1=0.5115243075731164\t A3=0.7836529149719156\t A5=0.8870811543676157 \n",
            "precision=0.47447183568286827, f1=0.4699028047666525, mrr=0.6705384620114447,num=10\n",
            "Counter({0: 3556, 6: 679, 9: 372, 3: 321, 2: 258, 1: 95, 8: 83, 5: 42, 4: 42, 7: 10})\n",
            "TrainEpoch [118/250]\t total_loss:0.404161\t loss_su:0.359650\t infonce_loss:4.810783\n",
            "A1=0.5117179934146814\t A3=0.7840402866550455\t A5=0.8882432694170056 \n",
            "precision=0.47401381754523547, f1=0.47094385355314133, mrr=0.6703760579704809,num=10\n",
            "Counter({0: 3545, 6: 667, 9: 395, 3: 334, 2: 242, 1: 95, 8: 82, 5: 47, 4: 41, 7: 10})\n",
            "TrainEpoch [119/250]\t total_loss:0.413142\t loss_su:0.368733\t infonce_loss:4.809604\n",
            "A1=0.5076505907418167\t A3=0.7807476273484408\t A5=0.8853379817935308 \n",
            "precision=0.47106845781839707, f1=0.4716671929109846, mrr=0.6673188960521921,num=10\n",
            "Counter({0: 3410, 6: 728, 9: 430, 3: 323, 2: 261, 8: 101, 1: 101, 5: 50, 4: 43, 7: 11})\n",
            "TrainEpoch [120/250]\t total_loss:0.415545\t loss_su:0.371206\t infonce_loss:4.805048\n",
            "A1=0.49719155529730774\t A3=0.7730001936858416\t A5=0.8762347472399767 \n",
            "precision=0.4672984927711642, f1=0.4700713783819417, mrr=0.6592170634152063,num=10\n",
            "Counter({0: 3164, 6: 802, 9: 448, 3: 355, 2: 318, 8: 136, 1: 107, 5: 62, 4: 44, 7: 22})\n",
            "TrainEpoch [121/250]\t total_loss:0.332350\t loss_su:0.287243\t infonce_loss:4.797938\n",
            "A1=0.495061011040093\t A3=0.7699012202208019\t A5=0.8762347472399767 \n",
            "precision=0.46758101697798066, f1=0.471311349430981, mrr=0.6574393040836982,num=10\n",
            "Counter({0: 3084, 6: 804, 9: 487, 3: 346, 2: 331, 8: 163, 1: 105, 5: 69, 4: 48, 7: 21})\n",
            "TrainEpoch [122/250]\t total_loss:0.412740\t loss_su:0.368499\t infonce_loss:4.792628\n",
            "A1=0.5006779004454774\t A3=0.7708696494286268\t A5=0.8814642649622313 \n",
            "precision=0.46757117982172863, f1=0.470388622365479, mrr=0.6618218305464104,num=10\n",
            "Counter({0: 3290, 6: 694, 9: 528, 2: 305, 3: 278, 8: 161, 1: 93, 5: 51, 4: 47, 7: 11})\n",
            "TrainEpoch [123/250]\t total_loss:0.416890\t loss_su:0.372530\t infonce_loss:4.808509\n",
            "A1=0.5049389889599071\t A3=0.7760991671508812\t A5=0.8849506101104009 \n",
            "precision=0.4671744784465198, f1=0.4675120539213154, mrr=0.6656335986521937,num=10\n",
            "Counter({0: 3480, 6: 636, 9: 496, 2: 274, 3: 243, 8: 152, 1: 85, 5: 45, 4: 41, 7: 6})\n",
            "TrainEpoch [124/250]\t total_loss:0.464238\t loss_su:0.420202\t infonce_loss:4.823779\n",
            "A1=0.5088127057912066\t A3=0.7832655432887856\t A5=0.8892116986248305 \n",
            "precision=0.46903588240199406, f1=0.4634983446830152, mrr=0.6699767730709055,num=10\n",
            "Counter({0: 3656, 6: 625, 9: 470, 2: 233, 3: 198, 8: 123, 1: 72, 4: 40, 5: 39, 7: 2})\n",
            "TrainEpoch [125/250]\t total_loss:0.374261\t loss_su:0.329037\t infonce_loss:4.851408\n",
            "A1=0.4960294402479179\t A3=0.7656401317063722\t A5=0.8779779198140616 \n",
            "precision=0.4669346915892291, f1=0.46424939813544375, mrr=0.6573317776978448,num=10\n",
            "Counter({0: 3238, 6: 850, 9: 374, 2: 327, 3: 294, 8: 184, 1: 91, 5: 53, 4: 41, 7: 6})\n",
            "TrainEpoch [126/250]\t total_loss:0.395320\t loss_su:0.350719\t infonce_loss:4.810885\n",
            "A1=0.4708502808444703\t A3=0.7358125121053651\t A5=0.8665504551617277 \n",
            "precision=0.46932182244113757, f1=0.4519903843441545, mrr=0.6363203225637861,num=10\n",
            "Counter({0: 2833, 6: 1053, 3: 424, 2: 373, 9: 292, 8: 258, 1: 102, 5: 70, 4: 41, 7: 12})\n",
            "TrainEpoch [127/250]\t total_loss:0.375411\t loss_su:0.330884\t infonce_loss:4.783518\n",
            "A1=0.4799535153980244\t A3=0.7431725740848344\t A5=0.8680999418942476 \n",
            "precision=0.46955309708970777, f1=0.4580034931803147, mrr=0.6433108442550639,num=10\n",
            "Counter({0: 2977, 6: 946, 3: 430, 2: 342, 9: 314, 8: 222, 1: 103, 5: 68, 4: 41, 7: 15})\n",
            "TrainEpoch [128/250]\t total_loss:0.400969\t loss_su:0.356737\t infonce_loss:4.779926\n",
            "A1=0.5066821615339918\t A3=0.768545419329847\t A5=0.8814642649622313 \n",
            "precision=0.47722086167825345, f1=0.4736937677156289, mrr=0.6641738837700508,num=10\n",
            "Counter({0: 3374, 6: 721, 9: 406, 3: 323, 2: 258, 8: 173, 1: 99, 5: 53, 4: 41, 7: 10})\n",
            "TrainEpoch [129/250]\t total_loss:0.361242\t loss_su:0.316328\t infonce_loss:4.807725\n",
            "A1=0.5082316482665117\t A3=0.78965717606043\t A5=0.8907611853573504 \n",
            "precision=0.46789054518883155, f1=0.4633652108600836, mrr=0.6709540411167395,num=10\n",
            "Counter({0: 3677, 6: 582, 9: 457, 3: 240, 2: 206, 8: 118, 1: 92, 5: 43, 4: 39, 7: 4})\n",
            "TrainEpoch [130/250]\t total_loss:0.423134\t loss_su:0.378667\t infonce_loss:4.825344\n",
            "A1=0.5105558783652915\t A3=0.78965717606043\t A5=0.8899864419910904 \n",
            "precision=0.4725288846970338, f1=0.47138491550825773, mrr=0.6715075829544181,num=10\n",
            "Counter({0: 3543, 6: 604, 9: 502, 3: 250, 2: 250, 8: 119, 1: 97, 5: 47, 4: 40, 7: 6})\n",
            "TrainEpoch [131/250]\t total_loss:0.394915\t loss_su:0.350200\t infonce_loss:4.821668\n",
            "A1=0.5064884756924268\t A3=0.7708696494286268\t A5=0.8853379817935308 \n",
            "precision=0.4735290738545075, f1=0.47743030762028216, mrr=0.6651812038651095,num=10\n",
            "Counter({0: 3255, 6: 689, 9: 514, 2: 332, 3: 297, 8: 158, 1: 101, 5: 59, 4: 41, 7: 12})\n",
            "TrainEpoch [132/250]\t total_loss:0.336569\t loss_su:0.291516\t infonce_loss:4.796884\n",
            "A1=0.4999031570792175\t A3=0.7658338175479372\t A5=0.8793337207050165 \n",
            "precision=0.4713873214162956, f1=0.47353236268413157, mrr=0.6594031401701379,num=10\n",
            "Counter({0: 3180, 6: 732, 9: 458, 2: 365, 3: 327, 8: 172, 1: 105, 5: 66, 4: 41, 7: 12})\n",
            "TrainEpoch [133/250]\t total_loss:0.310587\t loss_su:0.265396\t infonce_loss:4.784503\n",
            "A1=0.49661049777261285\t A3=0.7664148750726322\t A5=0.8760410613984118 \n",
            "precision=0.46919568556195185, f1=0.46979087777318607, mrr=0.6568355730180275,num=10\n",
            "Counter({0: 3175, 6: 755, 9: 418, 2: 375, 3: 333, 8: 175, 1: 101, 5: 70, 4: 42, 7: 14})\n",
            "TrainEpoch [134/250]\t total_loss:0.312226\t loss_su:0.267014\t infonce_loss:4.788157\n",
            "A1=0.49951578539608754\t A3=0.7693201626961069\t A5=0.8768158047646717 \n",
            "precision=0.46904863762171234, f1=0.4689832344284252, mrr=0.659208532015042,num=10\n",
            "Counter({0: 3258, 6: 770, 9: 391, 2: 360, 3: 310, 8: 142, 1: 101, 5: 70, 4: 42, 7: 14})\n",
            "TrainEpoch [135/250]\t total_loss:0.331884\t loss_su:0.286789\t infonce_loss:4.796380\n",
            "A1=0.5012589579701724\t A3=0.7776486538834011\t A5=0.8779779198140616 \n",
            "precision=0.4668307140879292, f1=0.4655765631140501, mrr=0.6618932329856229,num=10\n",
            "Counter({0: 3407, 6: 737, 9: 379, 2: 327, 3: 264, 8: 124, 1: 99, 5: 64, 4: 42, 7: 15})\n",
            "TrainEpoch [136/250]\t total_loss:0.340399\t loss_su:0.295199\t infonce_loss:4.815244\n",
            "A1=0.5047453031183421\t A3=0.7797791981406159\t A5=0.8777842339724966 \n",
            "precision=0.4686361394613923, f1=0.4665352062312495, mrr=0.6636681485170757,num=10\n",
            "Counter({0: 3441, 6: 768, 9: 366, 2: 312, 3: 246, 8: 113, 1: 93, 5: 61, 4: 41, 7: 17})\n",
            "TrainEpoch [137/250]\t total_loss:0.322782\t loss_su:0.277409\t infonce_loss:4.814672\n",
            "A1=0.5000968429207825\t A3=0.7811349990315708\t A5=0.8789463490218865 \n",
            "precision=0.4656359188557282, f1=0.46298717763745173, mrr=0.6615874860500097,num=10\n",
            "Counter({0: 3380, 6: 823, 9: 371, 2: 326, 3: 235, 8: 118, 1: 95, 5: 55, 4: 41, 7: 14})\n",
            "TrainEpoch [138/250]\t total_loss:0.338338\t loss_su:0.292974\t infonce_loss:4.829349\n",
            "A1=0.49002517915940347\t A3=0.7741623087352315\t A5=0.8770094906062367 \n",
            "precision=0.4610967944091307, f1=0.45794711903804003, mrr=0.6549570509332288,num=10\n",
            "Counter({0: 3218, 6: 878, 2: 385, 9: 372, 3: 256, 8: 138, 1: 97, 5: 55, 4: 45, 7: 14})\n",
            "TrainEpoch [139/250]\t total_loss:0.341255\t loss_su:0.296058\t infonce_loss:4.815672\n",
            "A1=0.5002905287623475\t A3=0.7809413131900058\t A5=0.8803021499128414 \n",
            "precision=0.4667350847531202, f1=0.4644444250633656, mrr=0.661633678586034,num=10\n",
            "Counter({0: 3351, 6: 785, 9: 396, 2: 349, 3: 249, 8: 137, 1: 93, 5: 46, 4: 43, 7: 9})\n",
            "TrainEpoch [140/250]\t total_loss:0.330447\t loss_su:0.285017\t infonce_loss:4.828014\n",
            "A1=0.5037768739105172\t A3=0.7828781716056556\t A5=0.8812705791206663 \n",
            "precision=0.4645233958405342, f1=0.46378903191387505, mrr=0.6635826807965111,num=9\n",
            "Counter({0: 3458, 6: 720, 9: 399, 2: 328, 3: 241, 8: 143, 1: 91, 4: 42, 5: 36})\n",
            "TrainEpoch [141/250]\t total_loss:0.326897\t loss_su:0.281320\t infonce_loss:4.838984\n",
            "A1=0.4863451481696688\t A3=0.7699012202208019\t A5=0.8744915746658919 \n",
            "precision=0.45727855745419865, f1=0.4539817486566954, mrr=0.6511435150598434,num=10\n",
            "Counter({0: 3315, 6: 687, 3: 371, 9: 361, 2: 326, 8: 205, 1: 103, 4: 43, 5: 41, 7: 6})\n",
            "TrainEpoch [142/250]\t total_loss:0.349169\t loss_su:0.303978\t infonce_loss:4.823057\n",
            "A1=0.47356188262638\t A3=0.7559558396281232\t A5=0.8690683711020725 \n",
            "precision=0.45210984917101005, f1=0.44516887514509956, mrr=0.6406379796414656,num=10\n",
            "Counter({0: 3176, 6: 705, 3: 524, 2: 302, 9: 278, 8: 258, 1: 107, 5: 50, 4: 48, 7: 10})\n",
            "TrainEpoch [143/250]\t total_loss:0.340383\t loss_su:0.295248\t infonce_loss:4.808823\n",
            "A1=0.4681386790625605\t A3=0.7524694944799535\t A5=0.8651946542707728 \n",
            "precision=0.4508129651647666, f1=0.4425592043221123, mrr=0.636602934801656,num=10\n",
            "Counter({0: 3088, 6: 718, 3: 584, 2: 317, 8: 264, 9: 252, 1: 114, 5: 57, 4: 48, 7: 16})\n",
            "TrainEpoch [144/250]\t total_loss:0.371867\t loss_su:0.327173\t infonce_loss:4.796511\n",
            "A1=0.47414294015107494\t A3=0.7627348440828975\t A5=0.8698431144683324 \n",
            "precision=0.4495832863600663, f1=0.4437706086066796, mrr=0.6429390750425034,num=10\n",
            "Counter({0: 3198, 6: 728, 3: 523, 2: 310, 9: 266, 8: 212, 1: 110, 5: 51, 4: 46, 7: 14})\n",
            "TrainEpoch [145/250]\t total_loss:0.345084\t loss_su:0.300086\t infonce_loss:4.799895\n",
            "A1=0.4923494092581832\t A3=0.7840402866550455\t A5=0.8839821809025761 \n",
            "precision=0.44961123729775365, f1=0.4490901943129115, mrr=0.6585345514020721,num=10\n",
            "Counter({0: 3524, 6: 696, 3: 346, 9: 333, 2: 259, 8: 124, 1: 100, 5: 37, 4: 35, 7: 4})\n",
            "TrainEpoch [146/250]\t total_loss:0.333888\t loss_su:0.288455\t infonce_loss:4.831780\n",
            "A1=0.49661049777261285\t A3=0.7933372070501646\t A5=0.8905674995157854 \n",
            "precision=0.4505587010734946, f1=0.450799793584895, mrr=0.6634839932486666,num=10\n",
            "Counter({0: 3571, 6: 727, 9: 367, 2: 271, 3: 261, 1: 93, 8: 93, 5: 36, 4: 34, 7: 5})\n",
            "TrainEpoch [147/250]\t total_loss:0.319291\t loss_su:0.273724\t infonce_loss:4.830390\n",
            "A1=0.49447995351539803\t A3=0.7863645167538253\t A5=0.8868874685260507 \n",
            "precision=0.4542472323991073, f1=0.454128595267992, mrr=0.6602127008722036,num=10\n",
            "Counter({0: 3361, 6: 869, 9: 364, 2: 333, 3: 253, 1: 98, 8: 98, 4: 39, 5: 35, 7: 8})\n",
            "TrainEpoch [148/250]\t total_loss:0.327139\t loss_su:0.281799\t infonce_loss:4.815788\n",
            "A1=0.48169668797210924\t A3=0.7795855122990509\t A5=0.8808832074375363 \n",
            "precision=0.45001309756634106, f1=0.4482202671974492, mrr=0.6516839907891636,num=10\n",
            "Counter({0: 3172, 6: 954, 2: 390, 9: 361, 3: 265, 8: 114, 1: 101, 4: 45, 5: 40, 7: 16})\n",
            "TrainEpoch [149/250]\t total_loss:0.307271\t loss_su:0.261916\t infonce_loss:4.797402\n",
            "A1=0.4787914003486345\t A3=0.7728065078442766\t A5=0.8785589773387565 \n",
            "precision=0.4520054954112256, f1=0.44900178720155853, mrr=0.647813963211988,num=10\n",
            "Counter({0: 3084, 6: 992, 2: 387, 9: 354, 3: 283, 8: 126, 1: 109, 4: 52, 5: 51, 7: 20})\n",
            "TrainEpoch [150/250]\t total_loss:0.264741\t loss_su:0.219054\t infonce_loss:4.787807\n",
            "A1=0.4906062366840984\t A3=0.7805539415068758\t A5=0.8855316676350958 \n",
            "precision=0.4618783820153274, f1=0.4587357975889716, mrr=0.6563145427323245,num=10\n",
            "Counter({0: 3194, 6: 947, 9: 382, 2: 320, 3: 261, 8: 127, 1: 106, 5: 51, 4: 51, 7: 19})\n",
            "TrainEpoch [151/250]\t total_loss:0.334530\t loss_su:0.289485\t infonce_loss:4.794048\n",
            "A1=0.5028084447026923\t A3=0.7852024017044354\t A5=0.8870811543676157 \n",
            "precision=0.46772808475479405, f1=0.46598163623483413, mrr=0.6646666297741274,num=10\n",
            "Counter({0: 3393, 6: 792, 9: 424, 2: 262, 3: 246, 8: 126, 1: 102, 4: 48, 5: 47, 7: 18})\n",
            "TrainEpoch [152/250]\t total_loss:0.247049\t loss_su:0.201116\t infonce_loss:4.794395\n",
            "A1=0.5024210730195623\t A3=0.7941119504164246\t A5=0.8847569242688359 \n",
            "precision=0.4640586404140851, f1=0.4619793607729117, mrr=0.665382498793309,num=10\n",
            "Counter({0: 3539, 6: 665, 9: 456, 3: 246, 2: 224, 8: 124, 1: 95, 4: 46, 5: 44, 7: 19})\n",
            "TrainEpoch [153/250]\t total_loss:0.305841\t loss_su:0.260420\t infonce_loss:4.802499\n",
            "A1=0.5006779004454774\t A3=0.7859771450706954\t A5=0.8824326941700562 \n",
            "precision=0.4657621398484988, f1=0.46422512655870607, mrr=0.6627946407435108,num=10\n",
            "Counter({0: 3463, 6: 659, 9: 444, 3: 279, 2: 236, 8: 163, 1: 101, 5: 52, 4: 41, 7: 20})\n",
            "TrainEpoch [154/250]\t total_loss:0.299559\t loss_su:0.254233\t infonce_loss:4.786847\n",
            "A1=0.4894441216347085\t A3=0.7706759635870618\t A5=0.8768158047646717 \n",
            "precision=0.46130551434102285, f1=0.4605252643550215, mrr=0.6532248692620576,num=10\n",
            "Counter({0: 3248, 6: 739, 9: 398, 3: 329, 2: 281, 8: 228, 1: 105, 5: 61, 4: 44, 7: 25})\n",
            "TrainEpoch [155/250]\t total_loss:0.316029\t loss_su:0.271029\t infonce_loss:4.771002\n",
            "A1=0.48034088708115436\t A3=0.7596358706178579\t A5=0.873135773774937 \n",
            "precision=0.45861130791819343, f1=0.45536617258889495, mrr=0.6457483651992663,num=10\n",
            "Counter({0: 3093, 6: 818, 3: 387, 9: 345, 2: 327, 8: 247, 1: 106, 5: 66, 4: 45, 7: 24})\n",
            "TrainEpoch [156/250]\t total_loss:0.306765\t loss_su:0.261771\t infonce_loss:4.761266\n",
            "A1=0.48285880302149914\t A3=0.7621537865582027\t A5=0.8752663180321518 \n",
            "precision=0.45693417154201504, f1=0.4528798671201132, mrr=0.6476071344026031,num=10\n",
            "Counter({0: 3148, 6: 858, 3: 376, 2: 341, 9: 299, 8: 209, 1: 103, 5: 61, 4: 43, 7: 20})\n",
            "TrainEpoch [157/250]\t total_loss:0.252768\t loss_su:0.207178\t infonce_loss:4.766131\n",
            "A1=0.4896378074762735\t A3=0.7730001936858416\t A5=0.8834011233778811 \n",
            "precision=0.4554236831970323, f1=0.45199541367217766, mrr=0.6544615379885576,num=10\n",
            "Counter({0: 3322, 6: 835, 3: 349, 2: 304, 9: 285, 8: 165, 1: 101, 5: 52, 4: 37, 7: 8})\n",
            "TrainEpoch [158/250]\t total_loss:0.269724\t loss_su:0.224075\t infonce_loss:4.789007\n",
            "A1=0.49564206856478793\t A3=0.7811349990315708\t A5=0.8907611853573504 \n",
            "precision=0.45246399854365643, f1=0.44914530446833945, mrr=0.6602419074673593,num=10\n",
            "Counter({0: 3514, 6: 812, 3: 311, 9: 263, 2: 255, 8: 121, 1: 95, 5: 49, 4: 35, 7: 3})\n",
            "TrainEpoch [159/250]\t total_loss:0.277023\t loss_su:0.231391\t infonce_loss:4.794627\n"
          ]
        }
      ]
    }
  ]
}